[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part3.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part3.html",
    "title": "Take-Home Exercise 3 (Part 2)",
    "section": "",
    "text": "The following code plots the aggregate count of armed conflict events in each year. We group armed conflict events by year and generating a total count for each year. Then, we use dygraph() of the dygraphs package to create an interactive plot of this, and dyRangeSelector() to allow users to pan and zoom to various date ranges.\n\ntime_series_overall &lt;- points_study %&gt;%\n  mutate(year = year(dmy(event_date))) %&gt;%\n  group_by(year) %&gt;%\n  summarise(count = n()) %&gt;%\n  dygraph(main = \"Number of armed conflict events in study area by year\") %&gt;%\n  dyRangeSelector(dateWindow = c(\"2015\", \"2024\"))   \n\ntime_series_overall\n\n\n\n\n\nWe can customise this further by creating a function time_series() with arguments that specify criteria for filtering events, namely whether they belong to a given event type, involve a given actor, and result in at least a certain number of fatalities.\n\ntime_series &lt;- function(eventtype, actor, min_fatalities) {      points_study %&gt;% \n    filter(event_type == eventtype & (actor1 == actor | actor2 == actor) & fatalities &gt;= min_fatalities) %&gt;%\n    mutate(year = year(dmy(event_date))) %&gt;%\n    group_by(year) %&gt;%\n    summarise(count = n()) %&gt;%\n    dygraph(main = \"Number of armed conflict events in study area by year\") %&gt;%\n    dyRangeSelector(dateWindow = c(\"2015\", \"2024\")) }                                \n\n\nSuppose that a user is interested only in armed conflict events that are of the type “Violence against civilians”, and involved the TPNPB: West Papua National Liberation Army, whether there were any fatalities or not. They would call time_series() as in the following code chunk.\n\ntime_series(\"Violence against civilians\", \"TPNPB: West Papua National Liberation Army\", 0)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part3.html#time-series-graph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part3.html#time-series-graph",
    "title": "Take-Home Exercise 3 (Part 2)",
    "section": "",
    "text": "The following code plots the aggregate count of armed conflict events in each year. We group armed conflict events by year and generating a total count for each year. Then, we use dygraph() of the dygraphs package to create an interactive plot of this, and dyRangeSelector() to allow users to pan and zoom to various date ranges.\n\ntime_series_overall &lt;- points_study %&gt;%\n  mutate(year = year(dmy(event_date))) %&gt;%\n  group_by(year) %&gt;%\n  summarise(count = n()) %&gt;%\n  dygraph(main = \"Number of armed conflict events in study area by year\") %&gt;%\n  dyRangeSelector(dateWindow = c(\"2015\", \"2024\"))   \n\ntime_series_overall\n\n\n\n\n\nWe can customise this further by creating a function time_series() with arguments that specify criteria for filtering events, namely whether they belong to a given event type, involve a given actor, and result in at least a certain number of fatalities.\n\ntime_series &lt;- function(eventtype, actor, min_fatalities) {      points_study %&gt;% \n    filter(event_type == eventtype & (actor1 == actor | actor2 == actor) & fatalities &gt;= min_fatalities) %&gt;%\n    mutate(year = year(dmy(event_date))) %&gt;%\n    group_by(year) %&gt;%\n    summarise(count = n()) %&gt;%\n    dygraph(main = \"Number of armed conflict events in study area by year\") %&gt;%\n    dyRangeSelector(dateWindow = c(\"2015\", \"2024\")) }                                \n\n\nSuppose that a user is interested only in armed conflict events that are of the type “Violence against civilians”, and involved the TPNPB: West Papua National Liberation Army, whether there were any fatalities or not. They would call time_series() as in the following code chunk.\n\ntime_series(\"Violence against civilians\", \"TPNPB: West Papua National Liberation Army\", 0)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part3.html#ui-design",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part3.html#ui-design",
    "title": "Take-Home Exercise 3 (Part 2)",
    "section": "6.0 UI Design",
    "text": "6.0 UI Design\nIn the following sections, we create prototypes for each shiny module using the designer package.\n\n6.1 Shiny UI for Interactive Point Map\n\n\n\n6.2 Shiny UI for Time Series Graph"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "In this exercise, I prototype the exploratory data analysis module of a Shiny application that allows users to investigate the spatial distribution and temporal trends of armed conflict events in Papua, a region of Indonesia that has been experiencing a protracted military conflict since 1962, between Indonesian security forces and separatist guerrilla groups under the umbrella of the Free Papua Movement.\nThe module includes two components: an interactive point map that will allows users to overlay administrative (province; regency and city) boundaries and to filter event points by various attributes, and an interactive time series graph of the aggregate number of armed conflict events that users will also be able to apply various filters to.\nOur application covers the period from 1 January 2015, shortly after Indonesian President Joko Widodo (“Jokowi”) began his first term, to 30 June 2024, towards the end of Jokowi’s second term. It thus provides insights into how the Papua conflict has evolved over Jokowi’s time in office.\n\n\n\nFor this exercise, the following R packages are used:\n\ntidyverse, a collection of R packages designed for data science, and which provides functions to import, transform, and visualise the data.\nsf, to import, manage and process vector-based geospatial data in R.\ntmap, which provides functions for plotting cartographic quality static point patterns maps or interactive maps.\ndygraphs, which provides rich facilities for charting time-series data in R.\nshiny, which makes it easy to build interactive web applications with R.\ndesigner, a ‘shiny’ application that enables the user to create a prototype UI, being able to drag and drop UI components.\n\nAll of these packages are supported in R CRAN.\np_load() function of pacman package is used to install and load these packages into the R environment.\n\npacman::p_load(tidyverse, sf, tmap, dygraphs, shiny, designer)\n\n\n\n\nFor this exercise, we will need to prepare the following data layers:\n\nA study area layer in sf polygon feature format, at Indonesia’s admin1 (provinsi/province) level.\nA study area layer in sf polygon feature format, at Indonesia’s admin2 (kota & kabupaten/city & regency) level.\nA point events layer in sf point feature format, showing the location, date and other attributes of armed conflict events in the Papua region.\n\n\n\n\n\nImport Batas_Wilayah_KelurahanDesa_10K_AR as a simple features object, which we name admin. This dataset provides information on Indonesia’s admin4 (village/desa and kelurahan) administrative boundaries as of 2023.\n\nadmin &lt;- st_read(dsn = \"data/BATAS WILAYAH KELURAHAN-DESA 10K\", layer = \"Batas_Wilayah_KelurahanDesa_10K_AR\")\n\nadmin\n\nglimpse(admin)\n\nWe also observe that admin is projected in WGS 84.\nSometimes, when importing geospatial data into R, the coordinate system of the source data is wrongly assigned during the importing process. We check the CRS.\n\nst_crs(admin)\n\nThe EPSG code indicated is 4326, which is correct since the data is projected in WGS 84.\n\n\n\nadmin contains 83518 features, each representing a village. However, for our study, we only require the data for villages in the Papua region, which consists of 6 provinces (as of 2023): Papua Selatan (South Papua), Papua Tengah (Central Papua), Papua Pegunungan (Mountains Papua), Papua Barat Daya (South-West Papua), Papua Barat (West Papua), and Papua.\nThe WADMPR field of admin contains the name of the province that each village belongs to.\nAll the provinces in the Papua region have the word “Papua” in their names. In the following code chunk, we extract the rows of admin that contain the word “Papua” in the WADMPR field and save them as a new object admin.\ngrepl() of base R is used to obtain a logical vector indicating whether each element of admin``$WADMPR contains a match to the word “Papua”. Then, filter() of dplyr (part of the tidyverse) is used to retain only the corresponding rows of admin.\n\npapua &lt;- filter(admin, grepl(\"Papua\", admin$WADMPR, fixed = TRUE))  \n\npapua\n\nAs required, papua is a sf polygon data.frame. It has 7374 features.\nWe check whether geometries of all the features in papua are valid.\n\nlength(which(st_is_valid(papua) == TRUE))\n\nAs we can see, the geometries of 7371 features are valid. This means that papua contains 3 features with invalid geometries. Using st_make_valid() of sf, we make the invalid geometries valid. Next, we use mutate() of dplyr to replace the existing geometry column with a new one containing the valid geometries. We save the result as a new sf polygon data.frame, papua_cleaned.\n\npapua_cleaned &lt;- papua %&gt;%\n  mutate(geometry = st_make_valid(geometry))\n\nWe verify that all 7374 geometries in papua_cleaned are valid.\n\nlength(which(st_is_valid(papua_cleaned) == TRUE))\n\n\n\n\npapua_cleaned is projected in WGS 84. In this code chunk, we reproject it in the projected coordinate system in the DGN95 / UTM zone 53S coordinate system, and save the reprojected data as a new object papua_23883.\n\npapua_23883 &lt;- st_transform(papua_cleaned, crs = 23883)\n\nst_geometry(papua_23883)\n\nWe can verify that all the reprojected geometries are still valid.\n\nlength(which(st_is_valid(papua_23883) == TRUE))\n\n\n\n\nNext, we use group_by() of dplyr to group the different villages according to the province they belong in. Then, we use summarise() of dplyr and st_union() of sf to combine the geometries of the different villages within each province and dissolve the boundaries between villages, thus obtaining the admin1 (province) level boundaries.\n\npapua_adm1 &lt;- papua_23883 %&gt;%\n  group_by(WADMPR) %&gt;%\n  summarise(geometry = st_union(geometry))\n\npapua_adm1\n\nWe visualise papua_adm1 using plot().\n\nplot(papua_adm1)\n\nWe can now save the papua_adm1 study area layer using the write_rds() function of readr, part of the tidyverse.\n\nwrite_rds(papua_adm1, \"data/rds/papua_adm1.rds\")\n\n\n\n\n\n\n\nThe WADMKK field of papua_cleaned contains the name of each city/regency that each village belongs to.\nSimilar to earlier, we first use group_by() of dplyr to group the different villages according to the province as well as city/regency they belong in. Then, we use summarise() of dplyr and st_union() of sf to combine the geometries of the different villages within each city/regency and dissolve the boundaries between villages, thus obtaining the admin2 (city/regency) level boundaries.\n\npapua_adm2 &lt;- papua_23883 %&gt;%\n  group_by(WADMPR, WADMKK) %&gt;%\n  summarise(geometry = st_union(geometry))\n\npapua_adm2\n\nWe visualise the admin2 boundaries in papua_adm2 using plot().\n\nplot(papua_adm2[\"WADMKK\"])\n\nWe can now save the papua_adm2 study area layer using write_rds().\n\nwrite_rds(papua_adm2, \"data/rds/papua_adm2.rds\")\n\n\n\n\n\n\n\nLastly, we import 2015-01-01-2024-06-30-Indonesia.csv. This dataset provides location, date, and other attribute information on 6 types of armed conflict events in Indonesia occurring from 1 January 2015 to 30 June 2024. Since it is in csv format, we use the read_csv() function of readr, part of the tidyverse, to import it, and save it as an object named points.\n\npoints &lt;- read_csv(\"data/2015-01-01-2024-06-30-Indonesia.csv\")\n\nglimpse(points)\n\nThe longitude and latitude fields capture the x- and y-coordinates of the data points respectively. They appear to be in the WGS 84 geographic coordinate system (in which latitudes range from -90 to 90 and longitudes range from 0 to 360).\nWe then convert points to an sf object.\n\npoints_sf &lt;- st_as_sf(points, coords = c(\"longitude\",\"latitude\"), crs = 4326)\n\nst_geometry(points_sf)\n\n\n\n\nWe reproject points_sf in the DGN95 / UTM zone 53S coordinate system, and save the reprojected data as a new object points_23883.\n\npoints_23883 &lt;- st_transform(points_sf, crs = 23883)\n\nst_geometry(points_23883)\n\n\n\n\npoints_23883 provides information on armed conflict events throughout Indonesia, and the admin1 field contains the name of the province where each point event took place.\nAs mentioned earlier, our study area is the region of Papua, consisting of 6 provinces. 4 of these, namely Papua Selatan (South Papua), Papua Tengah (Central Papua), Papua Pegunungan (Mountains Papua), Papua Barat Daya (South-West Papua), were only created in 2022, when they were carved out of the original 2 provinces of Papua and Papua Barat.\nWe use the group_by() and summarize() functions of dplyr to find all the provinces that are named in points_23883, and save them as a data.frame provinces .\n\nprovinces &lt;- points_23883 %&gt;% \n  group_by(admin1) %&gt;%\n  summarize()\n\nSince points_23883 contains data from 1 January 2015 to 30 June 2024, the admin1 field of each point event may reflect the original (pre-2022) or the new (post-2022) province names. As we can see in provinces, the 6 current provinces are all named in English (Central Papua, Highland Papua, Papua, South Papua, Southwest Papua and West Papua).\n(Note: In our later analysis, we need to be mindful that 2 of the current provinces have the same names as the original 2 provinces (“Papua” and “West Papua”). This means that when the admin1 field contains either of these values, we cannot be sure whether they are referring to the original or current provinces bearing these names. Hence, we should not use the values in the admin1 field to aggregate our data.)\nWe create a vector containing these province names.\n\nprovincenames &lt;- c(\"Central Papua\", \"Highland Papua\", \"Papua\", \"South Papua\", \"Southwest Papua\", \"West Papua\")\n\nNext, we use filter() to extract only the armed conflict events that take place in these provinces from points_23883. In addition, we use select(), also part of dplyr, to retain only the fields containing the event date, event type, involved parties (actor 1 and actor 2), the province (admin 1) and regency/city (admin2) where the event occurred, the number of fatalities, notes about the event, and the point geometry, for each event.\n\npoints_study &lt;- points_23883 %&gt;%\n  filter(admin1 %in% provincenames) %&gt;%\n  select(event_date, event_type, actor1, actor2, admin1, admin2, fatalities, notes, geometry)\n\npoints_study\n\nThere are 2942 features in the points_study sf point data.frame, corresponding to 2942 armed conflict point events.\nWe verify that the geometries of all the point events are valid.\n\nlength(which(st_is_valid(points_study) == TRUE))\n\nWe can now save the points_study study area layer using write_rds().\n\nwrite_rds(points_study, \"data/rds/points_study.rds\")\n\n\n\n\n\n\nThe interactive point map map allows users to overlay administrative (province; regency and city) boundaries and to filter point events by:\n\nStudy areas (regencies and cities)\nEvent type\nActors involved\nNumber of reported fatalities\nTime period (start date and end date)\n\nIn the following code chunk, we use the select() and distinct() functions of dplyr to identify all the unique event types that occur in the points_study dataset. st_drop_geometry() of sf is used to ensure that the geometry column is ignored, otherwise an event type will be repeated as long as there are multiple points with the same event type but with different geometries.\n\npoints_study %&gt;%\n  select(event_type) %&gt;%\n  st_drop_geometry() %&gt;%\n  distinct()\n\n# A tibble: 6 × 1\n  event_type                \n  &lt;chr&gt;                     \n1 Violence against civilians\n2 Strategic developments    \n3 Battles                   \n4 Protests                  \n5 Riots                     \n6 Explosions/Remote violence\n\n\nAll of the 6 armed conflict event types occur in the dataset.\nSimilarly, we can identify all the unique actor names that occur in the points_study dataset. Since there are two actor columns, actor1 and actor2, and the same actors can occur in either column for different events, we first combine the data from the two columns into a single vector and transform it into a data frame. Next, we use group_by() and summarise() of dplyr to find out the total number of events each group has been involved in, and arrange them in descending order.\n\nc(points_study$actor1, points_study$actor2) %&gt;%\n  data.frame() %&gt;%\n  setNames(\"actor\") %&gt;%\n  group_by(actor) %&gt;%\n  summarize(n = n()) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 33 × 2\n   actor                                                       n\n   &lt;chr&gt;                                                   &lt;int&gt;\n 1 Protesters (Indonesia)                                   1412\n 2 &lt;NA&gt;                                                     1315\n 3 Civilians (Indonesia)                                     842\n 4 Police Forces of Indonesia (2014-)                        691\n 5 TPNPB: West Papua National Liberation Army                682\n 6 Military Forces of Indonesia (2014-)                      427\n 7 Rioters (Indonesia)                                       290\n 8 Unidentified Armed Group (Indonesia)                       84\n 9 Police Forces of Indonesia (2014-) Mobile Brigade Corps    73\n10 Police Forces of Indonesia (2014-) Prison Guards            9\n# ℹ 23 more rows\n\n\nWe can see that the top named actors involved in armed conflicts are civilians, protesters, the Police Forces of Indonesia (2014-), the TPNPB: West Papua National Liberation Army, and the Military Forces of Indonesia (2014-).\nNext, we apply the summary() function of base R to the fatalities column to obtain summary statistics.\n\nsummary(points_study$fatalities)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.2726  0.0000 33.0000 \n\n\nWe can see that the minimum number of fatalities in an event is 0, while the maximum is 33. The mean number of fatalities is less than 1.\n\n\nWe first create a function map_overall(). This plots an interactive map for the entire study area using the three layers we created earlier.\n(Note that when plotting the papua_adm1 layer, I use tmap_options(check.and.fix = TRUE) as a warning appears that papua_adm1 is an invalid shape, despite having cleaned the data earlier and even though using st_is_valid() shows us that all the geometries in it are valid.)\n\nlength(which(st_is_valid(papua_adm1) == TRUE))\n\n[1] 6\n\n\nThe arguments of the functions specify criteria for filtering event points, namely whether they fall into a given date range, belong to a given event type, involve a given actor, and result in at least a certain number of fatalities.\nfilter() of dplyr is used to retain only the point events that meet the criteria, and these are saved as study_events for plotting.\nThe if and else statements ensure that if there are no point events within the specified study area that meet the specified criteria, only the study area layer is plotted.\n\nmap_overall &lt;- function(date_range, eventtype, actor, min_fatalities) {\n  study_events &lt;- points_study %&gt;% filter(dmy(event_date) %within% date_range & event_type == eventtype & (actor1 == actor | actor2 == actor) & fatalities &gt;= min_fatalities)\n  \n  tmap_mode(\"view\")\n  \n  if (nrow(study_events) &gt; 0) {\n    \n    tm_shape(papua_adm1) +\n      tmap_options(check.and.fix = TRUE) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMPR\") +\n      tm_shape(papua_adm2) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMKK\") +\n      tm_shape(study_events) +\n      tm_dots()\n    \n  }\n  \n  else {\n    \n     tm_shape(papua_adm1) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMPR\") +\n      tm_shape(papua_adm2) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMKK\")\n    \n  }\n  \n  tm_shape(papua_adm1) +\n    tm_polygons(col = \"MAP_COLORS\", id = \"WADMPR\") +\n    tm_shape(papua_adm2) +\n    tm_polygons(col = \"MAP_COLORS\", id = \"WADMKK\") +\n    tm_shape(study_events) +\n    tm_dots()\n    \n}\n\nSuppose that a user is interested only in armed conflict events that took place in year 2020, are of the type “Violence against civilians”, involved the TPNPB: West Papua National Liberation Army, and had at least one fatality. They would call map_overall() as in the following code chunk.\n\nint &lt;- interval(ymd(\"2020-01-01\"), ymd(\"2020-12-31\"))\n\nmap_overall(int, \"Violence against civilians\", \"TPNPB: West Papua National Liberation Army\", 1)\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "In this exercise, I prototype the exploratory data analysis module of a Shiny application that allows users to investigate the spatial distribution and temporal trends of armed conflict events in Papua, a region of Indonesia that has been experiencing a protracted military conflict since 1962, between Indonesian security forces and separatist guerrilla groups under the umbrella of the Free Papua Movement.\nThe module includes two components: an interactive point map that will allows users to overlay administrative (province; regency and city) boundaries and to filter event points by various attributes, and an interactive time series graph of the aggregate number of armed conflict events that users will also be able to apply various filters to.\nOur application covers the period from 1 January 2015, shortly after Indonesian President Joko Widodo (“Jokowi”) began his first term, to 30 June 2024, towards the end of Jokowi’s second term. It thus provides insights into how the Papua conflict has evolved over Jokowi’s time in office."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#packages",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "For this exercise, the following R packages are used:\n\ntidyverse, a collection of R packages designed for data science, and which provides functions to import, transform, and visualise the data.\nsf, to import, manage and process vector-based geospatial data in R.\ntmap, which provides functions for plotting cartographic quality static point patterns maps or interactive maps.\ndygraphs, which provides rich facilities for charting time-series data in R.\nshiny, which makes it easy to build interactive web applications with R.\ndesigner, a ‘shiny’ application that enables the user to create a prototype UI, being able to drag and drop UI components.\n\nAll of these packages are supported in R CRAN.\np_load() function of pacman package is used to install and load these packages into the R environment.\n\npacman::p_load(tidyverse, sf, tmap, dygraphs, shiny, designer)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "For this exercise, we will need to prepare the following data layers:\n\nA study area layer in sf polygon feature format, at Indonesia’s admin1 (provinsi/province) level.\nA study area layer in sf polygon feature format, at Indonesia’s admin2 (kota & kabupaten/city & regency) level.\nA point events layer in sf point feature format, showing the location, date and other attributes of armed conflict events in the Papua region.\n\n\n\n\n\nImport Batas_Wilayah_KelurahanDesa_10K_AR as a simple features object, which we name admin. This dataset provides information on Indonesia’s admin4 (village/desa and kelurahan) administrative boundaries as of 2023.\n\nadmin &lt;- st_read(dsn = \"data/BATAS WILAYAH KELURAHAN-DESA 10K\", layer = \"Batas_Wilayah_KelurahanDesa_10K_AR\")\n\nadmin\n\nglimpse(admin)\n\nWe also observe that admin is projected in WGS 84.\nSometimes, when importing geospatial data into R, the coordinate system of the source data is wrongly assigned during the importing process. We check the CRS.\n\nst_crs(admin)\n\nThe EPSG code indicated is 4326, which is correct since the data is projected in WGS 84.\n\n\n\nadmin contains 83518 features, each representing a village. However, for our study, we only require the data for villages in the Papua region, which consists of 6 provinces (as of 2023): Papua Selatan (South Papua), Papua Tengah (Central Papua), Papua Pegunungan (Mountains Papua), Papua Barat Daya (South-West Papua), Papua Barat (West Papua), and Papua.\nThe WADMPR field of admin contains the name of the province that each village belongs to.\nAll the provinces in the Papua region have the word “Papua” in their names. In the following code chunk, we extract the rows of admin that contain the word “Papua” in the WADMPR field and save them as a new object admin.\ngrepl() of base R is used to obtain a logical vector indicating whether each element of admin``$WADMPR contains a match to the word “Papua”. Then, filter() of dplyr (part of the tidyverse) is used to retain only the corresponding rows of admin.\n\npapua &lt;- filter(admin, grepl(\"Papua\", admin$WADMPR, fixed = TRUE))  \n\npapua\n\nAs required, papua is a sf polygon data.frame. It has 7374 features.\nWe check whether geometries of all the features in papua are valid.\n\nlength(which(st_is_valid(papua) == TRUE))\n\nAs we can see, the geometries of 7371 features are valid. This means that papua contains 3 features with invalid geometries. Using st_make_valid() of sf, we make the invalid geometries valid. Next, we use mutate() of dplyr to replace the existing geometry column with a new one containing the valid geometries. We save the result as a new sf polygon data.frame, papua_cleaned.\n\npapua_cleaned &lt;- papua %&gt;%\n  mutate(geometry = st_make_valid(geometry))\n\nWe verify that all 7374 geometries in papua_cleaned are valid.\n\nlength(which(st_is_valid(papua_cleaned) == TRUE))\n\n\n\n\npapua_cleaned is projected in WGS 84. In this code chunk, we reproject it in the projected coordinate system in the DGN95 / UTM zone 53S coordinate system, and save the reprojected data as a new object papua_23883.\n\npapua_23883 &lt;- st_transform(papua_cleaned, crs = 23883)\n\nst_geometry(papua_23883)\n\nWe can verify that all the reprojected geometries are still valid.\n\nlength(which(st_is_valid(papua_23883) == TRUE))\n\n\n\n\nNext, we use group_by() of dplyr to group the different villages according to the province they belong in. Then, we use summarise() of dplyr and st_union() of sf to combine the geometries of the different villages within each province and dissolve the boundaries between villages, thus obtaining the admin1 (province) level boundaries.\n\npapua_adm1 &lt;- papua_23883 %&gt;%\n  group_by(WADMPR) %&gt;%\n  summarise(geometry = st_union(geometry))\n\npapua_adm1\n\nWe visualise papua_adm1 using plot().\n\nplot(papua_adm1)\n\nWe can now save the papua_adm1 study area layer using the write_rds() function of readr, part of the tidyverse.\n\nwrite_rds(papua_adm1, \"data/rds/papua_adm1.rds\")\n\n\n\n\n\n\n\nThe WADMKK field of papua_cleaned contains the name of each city/regency that each village belongs to.\nSimilar to earlier, we first use group_by() of dplyr to group the different villages according to the province as well as city/regency they belong in. Then, we use summarise() of dplyr and st_union() of sf to combine the geometries of the different villages within each city/regency and dissolve the boundaries between villages, thus obtaining the admin2 (city/regency) level boundaries.\n\npapua_adm2 &lt;- papua_23883 %&gt;%\n  group_by(WADMPR, WADMKK) %&gt;%\n  summarise(geometry = st_union(geometry))\n\npapua_adm2\n\nWe visualise the admin2 boundaries in papua_adm2 using plot().\n\nplot(papua_adm2[\"WADMKK\"])\n\nWe can now save the papua_adm2 study area layer using write_rds().\n\nwrite_rds(papua_adm2, \"data/rds/papua_adm2.rds\")\n\n\n\n\n\n\n\nLastly, we import 2015-01-01-2024-06-30-Indonesia.csv. This dataset provides location, date, and other attribute information on 6 types of armed conflict events in Indonesia occurring from 1 January 2015 to 30 June 2024. Since it is in csv format, we use the read_csv() function of readr, part of the tidyverse, to import it, and save it as an object named points.\n\npoints &lt;- read_csv(\"data/2015-01-01-2024-06-30-Indonesia.csv\")\n\nglimpse(points)\n\nThe longitude and latitude fields capture the x- and y-coordinates of the data points respectively. They appear to be in the WGS 84 geographic coordinate system (in which latitudes range from -90 to 90 and longitudes range from 0 to 360).\nWe then convert points to an sf object.\n\npoints_sf &lt;- st_as_sf(points, coords = c(\"longitude\",\"latitude\"), crs = 4326)\n\nst_geometry(points_sf)\n\n\n\n\nWe reproject points_sf in the DGN95 / UTM zone 53S coordinate system, and save the reprojected data as a new object points_23883.\n\npoints_23883 &lt;- st_transform(points_sf, crs = 23883)\n\nst_geometry(points_23883)\n\n\n\n\npoints_23883 provides information on armed conflict events throughout Indonesia, and the admin1 field contains the name of the province where each point event took place.\nAs mentioned earlier, our study area is the region of Papua, consisting of 6 provinces. 4 of these, namely Papua Selatan (South Papua), Papua Tengah (Central Papua), Papua Pegunungan (Mountains Papua), Papua Barat Daya (South-West Papua), were only created in 2022, when they were carved out of the original 2 provinces of Papua and Papua Barat.\nWe use the group_by() and summarize() functions of dplyr to find all the provinces that are named in points_23883, and save them as a data.frame provinces .\n\nprovinces &lt;- points_23883 %&gt;% \n  group_by(admin1) %&gt;%\n  summarize()\n\nSince points_23883 contains data from 1 January 2015 to 30 June 2024, the admin1 field of each point event may reflect the original (pre-2022) or the new (post-2022) province names. As we can see in provinces, the 6 current provinces are all named in English (Central Papua, Highland Papua, Papua, South Papua, Southwest Papua and West Papua).\n(Note: In our later analysis, we need to be mindful that 2 of the current provinces have the same names as the original 2 provinces (“Papua” and “West Papua”). This means that when the admin1 field contains either of these values, we cannot be sure whether they are referring to the original or current provinces bearing these names. Hence, we should not use the values in the admin1 field to aggregate our data.)\nWe create a vector containing these province names.\n\nprovincenames &lt;- c(\"Central Papua\", \"Highland Papua\", \"Papua\", \"South Papua\", \"Southwest Papua\", \"West Papua\")\n\nNext, we use filter() to extract only the armed conflict events that take place in these provinces from points_23883. In addition, we use select(), also part of dplyr, to retain only the fields containing the event date, event type, involved parties (actor 1 and actor 2), the province (admin 1) and regency/city (admin2) where the event occurred, the number of fatalities, notes about the event, and the point geometry, for each event.\n\npoints_study &lt;- points_23883 %&gt;%\n  filter(admin1 %in% provincenames) %&gt;%\n  select(event_date, event_type, actor1, actor2, admin1, admin2, fatalities, notes, geometry)\n\npoints_study\n\nThere are 2942 features in the points_study sf point data.frame, corresponding to 2942 armed conflict point events.\nWe verify that the geometries of all the point events are valid.\n\nlength(which(st_is_valid(points_study) == TRUE))\n\nWe can now save the points_study study area layer using write_rds().\n\nwrite_rds(points_study, \"data/rds/points_study.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#interactive-point-map",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#interactive-point-map",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "The interactive point map map allows users to overlay administrative (province; regency and city) boundaries and to filter point events by:\n\nStudy areas (regencies and cities)\nEvent type\nActors involved\nNumber of reported fatalities\nTime period (start date and end date)\n\nIn the following code chunk, we use the select() and distinct() functions of dplyr to identify all the unique event types that occur in the points_study dataset. st_drop_geometry() of sf is used to ensure that the geometry column is ignored, otherwise an event type will be repeated as long as there are multiple points with the same event type but with different geometries.\n\npoints_study %&gt;%\n  select(event_type) %&gt;%\n  st_drop_geometry() %&gt;%\n  distinct()\n\n# A tibble: 6 × 1\n  event_type                \n  &lt;chr&gt;                     \n1 Violence against civilians\n2 Strategic developments    \n3 Battles                   \n4 Protests                  \n5 Riots                     \n6 Explosions/Remote violence\n\n\nAll of the 6 armed conflict event types occur in the dataset.\nSimilarly, we can identify all the unique actor names that occur in the points_study dataset. Since there are two actor columns, actor1 and actor2, and the same actors can occur in either column for different events, we first combine the data from the two columns into a single vector and transform it into a data frame. Next, we use group_by() and summarise() of dplyr to find out the total number of events each group has been involved in, and arrange them in descending order.\n\nc(points_study$actor1, points_study$actor2) %&gt;%\n  data.frame() %&gt;%\n  setNames(\"actor\") %&gt;%\n  group_by(actor) %&gt;%\n  summarize(n = n()) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 33 × 2\n   actor                                                       n\n   &lt;chr&gt;                                                   &lt;int&gt;\n 1 Protesters (Indonesia)                                   1412\n 2 &lt;NA&gt;                                                     1315\n 3 Civilians (Indonesia)                                     842\n 4 Police Forces of Indonesia (2014-)                        691\n 5 TPNPB: West Papua National Liberation Army                682\n 6 Military Forces of Indonesia (2014-)                      427\n 7 Rioters (Indonesia)                                       290\n 8 Unidentified Armed Group (Indonesia)                       84\n 9 Police Forces of Indonesia (2014-) Mobile Brigade Corps    73\n10 Police Forces of Indonesia (2014-) Prison Guards            9\n# ℹ 23 more rows\n\n\nWe can see that the top named actors involved in armed conflicts are civilians, protesters, the Police Forces of Indonesia (2014-), the TPNPB: West Papua National Liberation Army, and the Military Forces of Indonesia (2014-).\nNext, we apply the summary() function of base R to the fatalities column to obtain summary statistics.\n\nsummary(points_study$fatalities)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.2726  0.0000 33.0000 \n\n\nWe can see that the minimum number of fatalities in an event is 0, while the maximum is 33. The mean number of fatalities is less than 1.\n\n\nWe first create a function map_overall(). This plots an interactive map for the entire study area using the three layers we created earlier.\n(Note that when plotting the papua_adm1 layer, I use tmap_options(check.and.fix = TRUE) as a warning appears that papua_adm1 is an invalid shape, despite having cleaned the data earlier and even though using st_is_valid() shows us that all the geometries in it are valid.)\n\nlength(which(st_is_valid(papua_adm1) == TRUE))\n\n[1] 6\n\n\nThe arguments of the functions specify criteria for filtering event points, namely whether they fall into a given date range, belong to a given event type, involve a given actor, and result in at least a certain number of fatalities.\nfilter() of dplyr is used to retain only the point events that meet the criteria, and these are saved as study_events for plotting.\nThe if and else statements ensure that if there are no point events within the specified study area that meet the specified criteria, only the study area layer is plotted.\n\nmap_overall &lt;- function(date_range, eventtype, actor, min_fatalities) {\n  study_events &lt;- points_study %&gt;% filter(dmy(event_date) %within% date_range & event_type == eventtype & (actor1 == actor | actor2 == actor) & fatalities &gt;= min_fatalities)\n  \n  tmap_mode(\"view\")\n  \n  if (nrow(study_events) &gt; 0) {\n    \n    tm_shape(papua_adm1) +\n      tmap_options(check.and.fix = TRUE) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMPR\") +\n      tm_shape(papua_adm2) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMKK\") +\n      tm_shape(study_events) +\n      tm_dots()\n    \n  }\n  \n  else {\n    \n     tm_shape(papua_adm1) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMPR\") +\n      tm_shape(papua_adm2) +\n      tm_polygons(col = \"MAP_COLORS\", id = \"WADMKK\")\n    \n  }\n  \n  tm_shape(papua_adm1) +\n    tm_polygons(col = \"MAP_COLORS\", id = \"WADMPR\") +\n    tm_shape(papua_adm2) +\n    tm_polygons(col = \"MAP_COLORS\", id = \"WADMKK\") +\n    tm_shape(study_events) +\n    tm_dots()\n    \n}\n\nSuppose that a user is interested only in armed conflict events that took place in year 2020, are of the type “Violence against civilians”, involved the TPNPB: West Papua National Liberation Army, and had at least one fatality. They would call map_overall() as in the following code chunk.\n\nint &lt;- interval(ymd(\"2020-01-01\"), ymd(\"2020-12-31\"))\n\nmap_overall(int, \"Violence against civilians\", \"TPNPB: West Papua National Liberation Army\", 1)\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "title": "Take-Home Exercise 1",
    "section": "1.0 Overview",
    "text": "1.0 Overview\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, we are tasked to apply spatial point patterns analysis methods to discover the spatial and spatio-temporal distribution of armed conflict in Myanmar.\n\n1.1 Objectives\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse packages, import and transform the downloaded armed conflict data and administrative boundary data into sf tibble data.frames.\nUsing the geospatial data sets prepared, derive quarterly KDE layers.\nUsing the geospatial data sets prepared, perform 2nd-Order Spatial Point Patterns Analysis.\nUsing the geospatial data sets prepared, derive quarterly spatio-temporal KDE layers.\nUsing the geospatial data sets prepared, perform 2nd-Order Spatio-temporal Point Patterns Analysis.\nUsing appropriate tmap functions, display the KDE and Spatio-temporal KDE layers on openstreetmap of Myanmar.\nDescribe the spatial patterns revealed by the KDE and Spatio-temporal KDE maps."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take-Home Exercise 1",
    "section": "2.0 The Data",
    "text": "2.0 The Data\nThe following two data sets will be used:\n\n2021-01-01-2024-06-30-Southeast_Asia-Myanmar.csv This csv file provides data on armed conflict events in Myanmar from 1 January 2021 until 30 June 2024, focusing on six event types: Battles, Explosion/Remote violence, Protests, Riots, Strategic developments, and Violence against civilians. It was downloaded from Armed Conflict Location & Event Data (ACLED) on 7 September 2024.\nmmr_polbnda_adm1_250k_mimu_1 This polygon feature data set provides information on Myanmar state and region boundaries (Admin1). It was downloaded in ESRI shapefile format from Myanmar Information Management Unit, MIMU."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setup",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setup",
    "title": "Take-Home Exercise 1",
    "section": "3.0 Setup",
    "text": "3.0 Setup\nFor this exercise, the following R packages are used:\n\ntidyverse, a collection of R packages designed for data science, and which provides functions to import, transform, and visualise the data.\nsf, to import, manage and process vector-based geospatial data in R.\nspatstat, which will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layers.\ntmap, which provides functions for plotting cartographic quality static point patterns maps or interactive maps.\nsparr, which provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported.\nknitr, a transparent engine for dynamic report generation with R.\ngifski, which creates animated GIF images.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this exercise, it will be used to convert image output generated by spatstat into raster format.\n\nInstall and launch these packages.\n\npacman::p_load(tidyverse, sf, spatstat, tmap, sparr, gifski, knitr, raster)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "title": "Take-Home Exercise 1",
    "section": "4.0 Importing the Data",
    "text": "4.0 Importing the Data\n\n4.1 Importing Spatial Data\nImport mmr_polbnda_adm2_250k_mimu.\n\nadminboundaries_sf &lt;- st_read(dsn = \"data\", layer = \"mmr_polbnda_adm1_250k_mimu_1\", as_tibble = TRUE)\n\nadminboundaries_sf has a total of 15 features, and is projected in WGS 84.\nWe save adminboundaries_sf with the write_rds() function.\n\nwrite_rds(adminboundaries_sf, \"data/rds/adminboundaries_sf.rds\")\n\nCheck the class of adminboundaries_sf.\n\nclass(adminboundaries_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nAs required, it is a sf tibble data.frame.\nVerify that all the geometries in adminboundaries_sf are valid.\n\nlength(which(st_is_valid(adminboundaries_sf) == TRUE))\n\n[1] 15\n\n\nSometimes, when importing geospatial data into R, the coordinate system of the source data is wrongly assigned during the importing process. Check the CRS of adminboundaries_sf.\n\nst_crs(adminboundaries_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThe EPSG code indicated is 4326, which is correct since the data is projected in WGS 84.\n\n\n4.2 Importing Aspatial Data\nSince 2021-01-01-2024-06-30-Southeast_Asia-Myanmar.csv is in csv format, we used read_csv() of the readr package to import it.\n\narmedconflict &lt;- read_csv(\"data/2021-01-01-2024-06-30-Southeast_Asia-Myanmar.csv\")\n\nglimpse(armedconflict)\n\nRows: 51,553\nColumns: 31\n$ event_id_cnty      &lt;chr&gt; \"MMR64313\", \"MMR64320\", \"MMR64321\", \"MMR64322\", \"MM…\n$ event_date         &lt;chr&gt; \"30 June 2024\", \"30 June 2024\", \"30 June 2024\", \"30…\n$ year               &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 202…\n$ time_precision     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ disorder_type      &lt;chr&gt; \"Political violence\", \"Political violence\", \"Politi…\n$ event_type         &lt;chr&gt; \"Battles\", \"Battles\", \"Battles\", \"Strategic develop…\n$ sub_event_type     &lt;chr&gt; \"Armed clash\", \"Armed clash\", \"Armed clash\", \"Chang…\n$ actor1             &lt;chr&gt; \"People's Defense Force - Mandalay\", \"People's Defe…\n$ assoc_actor_1      &lt;chr&gt; \"MDA - AGF: Madaya - The Authentic Genes Force; SST…\n$ inter1             &lt;dbl&gt; 3, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 3, 3, 7, 1, …\n$ actor2             &lt;chr&gt; \"Military Forces of Myanmar (2021-)\", \"Military For…\n$ assoc_actor_2      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Uniden…\n$ inter2             &lt;dbl&gt; 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 2, 3, 1, 1, 7, 0, 0, …\n$ interaction        &lt;dbl&gt; 13, 13, 13, 10, 13, 10, 12, 12, 12, 12, 12, 13, 13,…\n$ civilian_targeting &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ iso                &lt;dbl&gt; 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 1…\n$ region             &lt;chr&gt; \"Southeast Asia\", \"Southeast Asia\", \"Southeast Asia…\n$ country            &lt;chr&gt; \"Myanmar\", \"Myanmar\", \"Myanmar\", \"Myanmar\", \"Myanma…\n$ admin1             &lt;chr&gt; \"Mandalay\", \"Mandalay\", \"Mandalay\", \"Sagaing\", \"Sag…\n$ admin2             &lt;chr&gt; \"Mandalay\", \"Pyinoolwin\", \"Pyinoolwin\", \"Shwebo\", \"…\n$ admin3             &lt;chr&gt; \"Patheingyi\", \"Singu\", \"Thabeikkyin\", \"Khin-U\", \"My…\n$ location           &lt;chr&gt; \"Aung Tha Pyay\", \"Pin Lel Gyi\", \"Thabeikkyin\", \"Khi…\n$ latitude           &lt;dbl&gt; 22.1504, 22.5752, 22.8800, 22.7744, 21.9251, 22.083…\n$ longitude          &lt;dbl&gt; 96.2364, 96.0661, 95.9700, 95.6980, 95.5758, 94.902…\n$ geo_precision      &lt;dbl&gt; 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, …\n$ source             &lt;chr&gt; \"Democratic Voice of Burma; Irrawaddy\", \"Irrawaddy\"…\n$ source_scale       &lt;chr&gt; \"National\", \"National\", \"National\", \"Subnational-Na…\n$ notes              &lt;chr&gt; \"On 30 June 2024, near Aung Tha Pyay village (Pathe…\n$ fatalities         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ tags               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ timestamp          &lt;dbl&gt; 1720552468, 1720552468, 1720552468, 1720552468, 172…\n\n\nThe longitude and latitude fields capture the x- and y-coordinates of the data points respectively. They appear to be in the wgs84 Geographic Coordinate System.\nWe then convert armedconflict to an sf object.\n\narmedconflict_sf &lt;- st_as_sf(armedconflict, coords = c(\"longitude\",\"latitude\"), crs = 4326)\n\nst_geometry(armedconflict_sf)\n\nGeometry set for 51553 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 92.1837 ymin: 9.9824 xmax: 100.3576 ymax: 27.5053\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\narmedconflict_sf has a total of 51553 features.\nCheck the class of armedconflict_sf .\n\nclass(armedconflict_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nAs required, it is a sf tibble data.frame.\nVerify that all the geometries in armedconflict_sf are valid.\n\nlength(which(st_is_valid(armedconflict_sf) == TRUE))\n\n[1] 51553\n\n\n\n\n4.3 Transforming the Projection of the Data\nadminboundaries_sf and armedconflict_sf are projected in the WGS 84 geographic coordinate system, which is not appropriate since the analysis will require distance and area measurements. Reproject both data to the Indian 1954 / UTM zone 46N projected coordinate system, which can be used in Myanmar.\n\nadminboundaries_sf_23946 &lt;- st_transform(adminboundaries_sf, crs = 23946)\n\narmedconflict_sf_23946 &lt;- st_transform(armedconflict_sf, crs = 23946)\n\nCheck the content of each data frame.\n\nst_geometry(adminboundaries_sf_23946)\n\nGeometry set for 15 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 414071.5 ymin: 1076012 xmax: 1347630 ymax: 3165918\nProjected CRS: Indian 1954 / UTM zone 46N\nFirst 5 geometries:\n\nst_geometry(armedconflict_sf_23946)\n\nGeometry set for 51553 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 415274.3 ymin: 1108506 xmax: 1265209 ymax: 3051406\nProjected CRS: Indian 1954 / UTM zone 46N\nFirst 5 geometries:\n\n\nAs desired, they have both been reprojected to the Indian 1954 / UTM zone 46N projected coordinate system."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-Home Exercise 1",
    "section": "5.0 Data Wrangling",
    "text": "5.0 Data Wrangling\n\n5.1 Organising point events data by quarter\nTo derive quarterly KDE layers, we must first organise the armed conflict events in armedconflict_sf_23946 by quarter. We use functions from the dplyr and lubridate packages of the tidyverse.\n\narmedconflictquarterly_sf &lt;- armedconflict_sf_23946 %&gt;%\n  mutate(\"quarter\" = quarter(dmy(event_date)))\n\n\nglimpse(armedconflictquarterly_sf)\n\nRows: 51,553\nColumns: 31\n$ event_id_cnty      &lt;chr&gt; \"MMR64313\", \"MMR64320\", \"MMR64321\", \"MMR64322\", \"MM…\n$ event_date         &lt;chr&gt; \"30 June 2024\", \"30 June 2024\", \"30 June 2024\", \"30…\n$ year               &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 202…\n$ time_precision     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ disorder_type      &lt;chr&gt; \"Political violence\", \"Political violence\", \"Politi…\n$ event_type         &lt;chr&gt; \"Battles\", \"Battles\", \"Battles\", \"Strategic develop…\n$ sub_event_type     &lt;chr&gt; \"Armed clash\", \"Armed clash\", \"Armed clash\", \"Chang…\n$ actor1             &lt;chr&gt; \"People's Defense Force - Mandalay\", \"People's Defe…\n$ assoc_actor_1      &lt;chr&gt; \"MDA - AGF: Madaya - The Authentic Genes Force; SST…\n$ inter1             &lt;dbl&gt; 3, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 3, 3, 7, 1, …\n$ actor2             &lt;chr&gt; \"Military Forces of Myanmar (2021-)\", \"Military For…\n$ assoc_actor_2      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Uniden…\n$ inter2             &lt;dbl&gt; 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 2, 3, 1, 1, 7, 0, 0, …\n$ interaction        &lt;dbl&gt; 13, 13, 13, 10, 13, 10, 12, 12, 12, 12, 12, 13, 13,…\n$ civilian_targeting &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ iso                &lt;dbl&gt; 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 1…\n$ region             &lt;chr&gt; \"Southeast Asia\", \"Southeast Asia\", \"Southeast Asia…\n$ country            &lt;chr&gt; \"Myanmar\", \"Myanmar\", \"Myanmar\", \"Myanmar\", \"Myanma…\n$ admin1             &lt;chr&gt; \"Mandalay\", \"Mandalay\", \"Mandalay\", \"Sagaing\", \"Sag…\n$ admin2             &lt;chr&gt; \"Mandalay\", \"Pyinoolwin\", \"Pyinoolwin\", \"Shwebo\", \"…\n$ admin3             &lt;chr&gt; \"Patheingyi\", \"Singu\", \"Thabeikkyin\", \"Khin-U\", \"My…\n$ location           &lt;chr&gt; \"Aung Tha Pyay\", \"Pin Lel Gyi\", \"Thabeikkyin\", \"Khi…\n$ geo_precision      &lt;dbl&gt; 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, …\n$ source             &lt;chr&gt; \"Democratic Voice of Burma; Irrawaddy\", \"Irrawaddy\"…\n$ source_scale       &lt;chr&gt; \"National\", \"National\", \"National\", \"Subnational-Na…\n$ notes              &lt;chr&gt; \"On 30 June 2024, near Aung Tha Pyay village (Pathe…\n$ fatalities         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ tags               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ timestamp          &lt;dbl&gt; 1720552468, 1720552468, 1720552468, 1720552468, 172…\n$ geometry           &lt;POINT [m]&gt; POINT (833792.1 2452830), POINT (815256.3 249…\n$ quarter            &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n\n\narmedconflictquarterly_sf is then broken down into individual data frames for each quarter from 1 January 2021 until 30 June 2024, that is, from Q1 2021 until Q2 2024. Convert each of these data sets to spatstat’s ppp object format.\n\narmedconflictQ121_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 1 & year == 2021) %&gt;%\n  as.ppp(.)\n\narmedconflictQ221_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 2 & year == 2021) %&gt;%\n  as.ppp(.)\n\narmedconflictQ321_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 3 & year == 2021) %&gt;%\n  as.ppp(.)\n\narmedconflictQ421_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 4 & year == 2021) %&gt;%\n  as.ppp(.)\n\narmedconflictQ122_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 1 & year == 2022) %&gt;%\n  as.ppp(.)\n\narmedconflictQ222_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 2 & year == 2022) %&gt;%\n  as.ppp(.)\n\narmedconflictQ322_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 3 & year == 2022) %&gt;%\n  as.ppp(.)\n\narmedconflictQ422_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 4 & year == 2022) %&gt;%\n  as.ppp(.)\n\narmedconflictQ123_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 1 & year == 2023) %&gt;%\n  as.ppp(.)\n\narmedconflictQ223_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 2 & year == 2023) %&gt;%\n  as.ppp(.)\n\narmedconflictQ323_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 3 & year == 2023) %&gt;%\n  as.ppp(.)\n\narmedconflictQ423_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 4 & year == 2023) %&gt;%\n  as.ppp(.)\n\narmedconflictQ124_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 1 & year == 2024) %&gt;%\n  as.ppp(.)\n\narmedconflictQ224_ppp &lt;- armedconflictquarterly_sf %&gt;%\n  filter(quarter == 2 & year == 2024) %&gt;%\n  as.ppp(.)\n\nNext, we verify the number of locations with more than one point event in each quarter.\n\nquarterly &lt;- list(armedconflictQ121_ppp, armedconflictQ221_ppp, armedconflictQ321_ppp, armedconflictQ421_ppp, armedconflictQ122_ppp, armedconflictQ222_ppp, armedconflictQ322_ppp, armedconflictQ422_ppp, armedconflictQ123_ppp, armedconflictQ223_ppp, armedconflictQ323_ppp, armedconflictQ423_ppp, armedconflictQ124_ppp, armedconflictQ224_ppp)\n\n\nfor (i in quarterly) {\n  result = sum(multiplicity(i) &gt; 1)\n  print(result)\n}\n\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n[1] 0\n\n\nThe output shows that there are no duplicated point events in any of the quarterly data frames.\n\n\n5.2 Creating owin object\nThe code chunk below is used to covert adminboundaries_sf_23946 into an owin object of spatstat, allowing the later analysis to be confined to Myanmar’s borders. We confirm that the output is indeed an owin object with the class() function, and then plot the boundaries.\n\nadminboundaries_owin &lt;- as.owin(adminboundaries_sf_23946)\n\nclass(adminboundaries_owin)\n\n[1] \"owin\"\n\nplot(adminboundaries_owin)\n\n\n\n\n\n\n\n\n\n\n5.3 Combining point events objects and owin object\nWe then combine both the point events objects and owin object into a single ppp object for each quarter.\n\narmedconflictQ121mm_ppp &lt;- armedconflictQ121_ppp[adminboundaries_owin]\n\narmedconflictQ221mm_ppp &lt;- armedconflictQ221_ppp[adminboundaries_owin]\n\narmedconflictQ321mm_ppp &lt;- armedconflictQ321_ppp[adminboundaries_owin]\n\narmedconflictQ421mm_ppp &lt;- armedconflictQ421_ppp[adminboundaries_owin]\n\narmedconflictQ122mm_ppp &lt;- armedconflictQ122_ppp[adminboundaries_owin]\n\narmedconflictQ222mm_ppp &lt;- armedconflictQ222_ppp[adminboundaries_owin]\n\narmedconflictQ322mm_ppp &lt;- armedconflictQ322_ppp[adminboundaries_owin]\n\narmedconflictQ422mm_ppp &lt;- armedconflictQ422_ppp[adminboundaries_owin]\n\narmedconflictQ123mm_ppp &lt;- armedconflictQ123_ppp[adminboundaries_owin]\n\narmedconflictQ223mm_ppp &lt;- armedconflictQ223_ppp[adminboundaries_owin]\n\narmedconflictQ323mm_ppp &lt;- armedconflictQ323_ppp[adminboundaries_owin]\n\narmedconflictQ423mm_ppp &lt;- armedconflictQ423_ppp[adminboundaries_owin]\n\narmedconflictQ124mm_ppp &lt;- armedconflictQ124_ppp[adminboundaries_owin]\n\narmedconflictQ224mm_ppp &lt;- armedconflictQ224_ppp[adminboundaries_owin]\n\nWe save each of these ppp objects with the write_rds() function.\n\nwrite_rds(armedconflictQ121mm_ppp, \"data/rds/armedconflictQ121mm_ppp.rds\")\n\nwrite_rds(armedconflictQ221mm_ppp, \"data/rds/armedconflictQ221mm_ppp.rds\")\n\nwrite_rds(armedconflictQ321mm_ppp, \"data/rds/armedconflictQ321mm_ppp.rds\")\n\nwrite_rds(armedconflictQ421mm_ppp, \"data/rds/armedconflictQ421mm_ppp.rds\")\n\nwrite_rds(armedconflictQ122mm_ppp, \"data/rds/armedconflictQ122mm_ppp.rds\")\n\nwrite_rds(armedconflictQ222mm_ppp, \"data/rds/armedconflictQ222mm_ppp.rds\")\n\n\nwrite_rds(armedconflictQ322mm_ppp, \"data/rds/armedconflictQ322mm_ppp.rds\")\n\nwrite_rds(armedconflictQ422mm_ppp, \"data/rds/armedconflictQ422mm_ppp.rds\")\n\nwrite_rds(armedconflictQ123mm_ppp, \"data/rds/armedconflictQ123mm_ppp.rds\")\n\nwrite_rds(armedconflictQ223mm_ppp, \"data/rds/armedconflictQ223mm_ppp.rds\")\n\n\nwrite_rds(armedconflictQ323mm_ppp, \"data/rds/armedconflictQ323mm_ppp.rds\")\n\nwrite_rds(armedconflictQ423mm_ppp, \"data/rds/armedconflictQ423mm_ppp.rds\")\n\nwrite_rds(armedconflictQ124mm_ppp, \"data/rds/armedconflictQ124mm_ppp.rds\")\n\nwrite_rds(armedconflictQ224mm_ppp, \"data/rds/armedconflictQ224mm_ppp.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation",
    "title": "Take-Home Exercise 1",
    "section": "5.1 Kernel Density Estimation",
    "text": "5.1 Kernel Density Estimation\nWe now try deriving the KDE layers for Q1 2021.\n\nkde_armedconflictQ121mm &lt;- density(armedconflictQ121mm_ppp, sigma = bw.diggle, edge = TRUE, kernel = \"quartic\")\n\nplot(kde_armedconflictQ121mm)\n\n\n\n\n\n\n\n\nThe density values of the output are extremely small. This is because the default measurement of the Indian 1954 / UTM zone 46N system is in metres. We convert the unit of measurement to kilometers.\n\narmedconflictQ121mm_ppp_km &lt;- rescale.ppp(armedconflictQ121mm_ppp, 1000, \"km\")\n\nkde_armedconflictQ121mm_km &lt;- density(armedconflictQ121mm_ppp_km, sigma = bw.diggle, edge = TRUE, kernel = \"quartic\")\n\nplot(kde_armedconflictQ121mm_km)\n\n\n\n\n\n\n\n\nThere is another problem. Apart from a few specks, most of Myanmar is dark. We check the bandwidth derived by the diggle method.\n\nbw.diggle(armedconflictQ121mm_ppp_km)\n\n    sigma \n0.2283657 \n\n\nWe may need a larger bandwidth to prevent undersmoothing, particularly given Myanmar’s relatively large land area and the rural nature of most of the country. We try the CvL automatic bandwidth selection method instead.\n\nkde_armedconflictQ121mm_kmCvL &lt;- density(armedconflictQ121mm_ppp_km, sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nplot(kde_armedconflictQ121mm_kmCvL)\n\n\n\n\n\n\n\n\nWe can now clearly identify an area of extremely high intensity in central Myanmar, centered around Yangon Region, Myanmar’s most populous region and home to its largest city. Another area with relatively high intensity stretches from southern Kachin State, through northwestern Shan State, Mandalay Region and Sagaing Region.\nWe repeat the process of rescaling the data and deriving KDE layers for every quarter from 1 January 2021 until 30 June 2024.\n\nkde_armedconflictQ221mm_kmCvL &lt;- armedconflictQ221mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n \nkde_armedconflictQ321mm_kmCvL &lt;- armedconflictQ321mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ421mm_kmCvL &lt;- armedconflictQ421mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ122mm_kmCvL &lt;- armedconflictQ122mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ222mm_kmCvL &lt;- armedconflictQ222mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ322mm_kmCvL &lt;- armedconflictQ322mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ422mm_kmCvL &lt;- armedconflictQ422mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ123mm_kmCvL &lt;- armedconflictQ123mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ223mm_kmCvL &lt;- armedconflictQ223mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ323mm_kmCvL &lt;- armedconflictQ323mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ423mm_kmCvL &lt;- armedconflictQ423mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ124mm_kmCvL &lt;- armedconflictQ124mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nkde_armedconflictQ224mm_kmCvL &lt;- armedconflictQ224mm_ppp %&gt;%\n  rescale.ppp(., 1000, \"km\") %&gt;%\n  density(., sigma = bw.CvL, edge = TRUE, kernel = \"quartic\")\n\nAgain, we save the quarterly KDE layers with write_rds().\n\nwrite_rds(kde_armedconflictQ121mm_kmCvL, file = \"data/rds/kde_armedconflictQ121mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ221mm_kmCvL, file = \"data/rds/kde_armedconflictQ221mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ321mm_kmCvL, file = \"data/rds/kde_armedconflictQ321mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ421mm_kmCvL, file = \"data/rds/kde_armedconflictQ421mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ122mm_kmCvL, file = \"data/rds/kde_armedconflictQ122mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ222mm_kmCvL, file = \"data/rds/kde_armedconflictQ222mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ322mm_kmCvL, file = \"data/rds/kde_armedconflictQ322mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ422mm_kmCvL, file = \"data/rds/kde_armedconflictQ422mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ123mm_kmCvL, file = \"data/rds/kde_armedconflictQ123mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ223mm_kmCvL, file = \"data/rds/kde_armedconflictQ223mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ323mm_kmCvL, file = \"data/rds/kde_armedconflictQ323mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ423mm_kmCvL, file = \"data/rds/kde_armedconflictQ423mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ124mm_kmCvL, file = \"data/rds/kde_armedconflictQ124mm_kmCvL\")\n\nwrite_rds(kde_armedconflictQ224mm_kmCvL, file = \"data/rds/kde_armedconflictQ224mm_kmCvL\")\n\nWe can now plot these quarterly KDE layers.\n\nplot(kde_armedconflictQ121mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ221mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ321mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ421mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ122mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ222mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ322mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ422mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ123mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ223mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ323mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ423mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ124mm_kmCvL)\n\n\n\n\n\n\n\nplot(kde_armedconflictQ224mm_kmCvL)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-spatial-point-patterns-analysis",
    "title": "Take-Home Exercise 1",
    "section": "6.0 2nd Order Spatial Point Patterns Analysis",
    "text": "6.0 2nd Order Spatial Point Patterns Analysis\nNext, we perform 2nd order spatial point patterns analysis, testing whether the event points in each cluster are clustered, randomly distributed, or dispersed. To do this, we would ideally use the L function, which estimates spatial dependence over a wider range of scales than the G and F functions. However, with a total of 51553 event points across all 14 quarters, this would likely be too computationally demanding and take an extremely long amount of time. Hence, we can use the F function instead.\nIn the following code chunks, we generate Monte Carlo simulations of the F function under complete spatial randomness for each quarter, and plot the output against the F function derived from the observed data. Through this, we can perform a test of the null hypothesis that the distribution of armed conflict events is random in each quarter, with alpha = 2.5%.\nWe use the set.seed() function to ensure that the simulation results are reproducible.\n\nset.seed(5)\n\narmedconflictQ121mm_csr &lt;- envelope(armedconflictQ121mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ221mm_csr &lt;- envelope(armedconflictQ221mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ321mm_csr &lt;- envelope(armedconflictQ321mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ421mm_csr &lt;- envelope(armedconflictQ421mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ122mm_csr &lt;- envelope(armedconflictQ122mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ222mm_csr &lt;- envelope(armedconflictQ222mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ322mm_csr &lt;- envelope(armedconflictQ322mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ422mm_csr &lt;- envelope(armedconflictQ422mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ123mm_csr &lt;- envelope(armedconflictQ123mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ223mm_csr &lt;- envelope(armedconflictQ223mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ323mm_csr &lt;- envelope(armedconflictQ323mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ423mm_csr &lt;- envelope(armedconflictQ423mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ124mm_csr &lt;- envelope(armedconflictQ124mm_ppp, Fest, nsim = 39, global = TRUE)\n\narmedconflictQ224mm_csr &lt;- envelope(armedconflictQ224mm_ppp, Fest, nsim = 39, global = TRUE)\n\nWe save each of the simulation outputs with write_rds().\n\nwrite_rds(armedconflictQ121mm_csr, file = \"data/rds/armedconflictQ121mm_csr\")\n\nwrite_rds(armedconflictQ221mm_csr, file = \"data/rds/armedconflictQ221mm_csr\")\n\nwrite_rds(armedconflictQ321mm_csr, file = \"data/rds/armedconflictQ321mm_csr\")\n\nwrite_rds(armedconflictQ421mm_csr, file = \"data/rds/armedconflictQ421mm_csr\")\n\nwrite_rds(armedconflictQ122mm_csr, file = \"data/rds/armedconflictQ122mm_csr\")\n\nwrite_rds(armedconflictQ222mm_csr, file = \"data/rds/armedconflictQ222mm_csr\")\n\nwrite_rds(armedconflictQ322mm_csr, file = \"data/rds/armedconflictQ322mm_csr\")\n\nwrite_rds(armedconflictQ422mm_csr, file = \"data/rds/armedconflictQ422mm_csr\")\n\nwrite_rds(armedconflictQ123mm_csr, file = \"data/rds/armedconflictQ123mm_csr\")\n\nwrite_rds(armedconflictQ223mm_csr, file = \"data/rds/armedconflictQ223mm_csr\")\n\nwrite_rds(armedconflictQ323mm_csr, file = \"data/rds/armedconflictQ323mm_csr\")\n\nwrite_rds(armedconflictQ423mm_csr, file = \"data/rds/armedconflictQ423mm_csr\")\n\nwrite_rds(armedconflictQ124mm_csr, file = \"data/rds/armedconflictQ124mm_csr\")\n\nwrite_rds(armedconflictQ224mm_csr, file = \"data/rds/armedconflictQ224mm_csr\")\n\nWe can now plot the simulation outputs.\n\nplot(armedconflictQ121mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ221mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ321mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ421mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ122mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ222mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ322mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ422mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ123mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ223mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ323mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ423mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ124mm_csr)\n\n\n\n\n\n\n\nplot(armedconflictQ224mm_csr)\n\n\n\n\n\n\n\n\nIn all of the plots, the F function derived from the observed data lies well outside the simulated envelopes. Thus, at alpha = 2.5%, there is sufficient evidence to reject the null hypothesis that the distribution of armed conflict events in Myanmar is random in each quarter. We can conclude that in every quarter studied, the distribution of armed conflict events in Myanmar is non-random.\nMoreover, since the F function lies below the lower envelope, the armed conflict events are distributed in a clustered pattern in every quarter. This makes sense as intuitively, armed conflict events are likely to be concentrated in areas with weak or non-existent levels of governmental control, or in dense population centres (respecially in the case of Protests, Riots, and Violence against civilians).\nIndeed, the longstanding conflict in Myanmar, which has been described as “the world’s longest continuing civil war” (Rieffel, 2019), is one with strong inter-ethnic and inter-regional dimensions, pitting ethnic armed organizations seeking greater regional autonomy such as the Karen National Liberation Army and the Shan State Army against the Tatmadaw, and fighting had been concentrated in border regions up till the 2021 coup (Maizland, 2022). After the 2021 coup, it is not surprising that armed conflict events have continued to be concentrated in certain areas where opposing forces (namely the Tatmadaw, the People’s Defence Force of the anti-junta National Unity Government (NUG), as well as ethnic armed organisations allied to the NUG or aiming to consolidate their hold on their territories) are fighting for control (Maizland, 2022). In addition, we would also expect certain types of armed conflict events such as Protests, Riots and Violence against civilians, to be clustered in densely-populated areas, such as cities and major towns, where mass demonstrations by civilians can be most conveniently organised."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatio-temporal-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatio-temporal-point-patterns-analysis",
    "title": "Take-Home Exercise 1",
    "section": "7.0 Spatio-Temporal Point Patterns Analysis",
    "text": "7.0 Spatio-Temporal Point Patterns Analysis\nFrom the quarterly KDE layers derived above, we notice that the relative intensity of armed conflict events around Yangon was highest in early 2021, immediately after the coup, but declined compared to the rest of Myanmar thereafter. This may reflect how mass demonstrations arose in Myanmar’s largest city in the immediate aftermath of the 2021 coup and in the following months (e.g. Myanmar: more than 100,000 protest in streets against coup, 2021; Robinson & Wallace, 2021; Myanmar protesters paint Yangon red, defying bloody army crackdown, 2021), but gradually lost steam as the Tatmadaw reasserted control.\nThis is an example of a spatio-temporal point process. A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event.\nHence, we conduct spatio-temporal point patterns analysis on the data, this time focusing specifically on Protests and Riots in Yangon Region.\n\n7.1 Extracting the Study Area\nWe extract Yangon Region from adminboundaries_sf_23946, and then plot it.\n\nyangon &lt;- adminboundaries_sf_23946 %&gt;%\n  filter(ST == \"Yangon\")\n\n\nplot(yangon, main = \"Yangon Region\")\n\n\n\n\n\n\n\n\nWe see that Yangon Region includes offshore islands. For the purposes of our analysis, we should remove these islands and focus on mainland Yangon Region, around the city of Yangon itself, which is where most of the population lives.\nWe use st_cast() to split the MULTIPOLYGON into multiple POLYGON features, arrange these features by their land area, and then choose the largest area, which is the mainland (this method was inspired by a previous participant in this course, namely Ho, 2024, as well as an answer on StackExchange).\n\nyangon_mainland &lt;- yangon %&gt;% \n  st_cast(\"POLYGON\") %&gt;%\n  mutate(area = st_area(.)) %&gt;%\n  arrange(desc(area)) %&gt;%\n  slice(1)\n\nPlotting this, we confirm that we have successfully extracted the mainland portion of Yangon Region.\n\nplot(yangon_mainland)\n\n\n\n\n\n\n\n\nWe can now convert this to an owin object and plot it.\n\nyangon_owin &lt;- as.owin(yangon_mainland)\n\nplot(yangon_owin)\n\n\n\n\n\n\n\n\n\n\n7.2 Preparing Protest and Riot Data\narmedconflict_sf_23946 contains data on six types of armed conflict events. However, we are now focusing on two types: Riots and Protests.\n\nriotprotests &lt;- armedconflict_sf_23946 %&gt;%\n  filter(event_type %in% c(\"Protests\", \"Riots\"))\n\nUsing the mutate() function and the quarter() function, we organise the data by quarter. Next, we can remove all the fields except for quarter and geometry.\n\nriotprotests_date &lt;- riotprotests %&gt;% \n  mutate(event_date = as.numeric(dmy(event_date))) %&gt;%\n  dplyr::select(event_date, geometry)\n\n\n\n7.3 Creating ppp object\n\nriotprotests_date_ppp &lt;- as.ppp(riotprotests_date)\n\nriotprotests_date_ppp \n\nMarked planar point pattern: 8945 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [434051.8, 1218927.7] x [1108505.9, 3051406.1] units\n\n\nThe code chunk below is used to check the output is in the correct object class.\n\nsummary(riotprotests_date_ppp)\n\nMarked planar point pattern:  8945 points\nAverage intensity 5.865822e-09 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18633   18696   18783   18919   19077   19904 \n\nWindow: rectangle = [434051.8, 1218927.7] x [1108505.9, 3051406.1] units\n                    (784900 x 1943000 units)\nWindow area = 1.52494e+12 square units\n\n\nWe notice a warning that the pattern contains duplicated (i.e. coincident) points. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\nTo overcome this, we use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\n\nriotprotests_date_ppp_jit &lt;- rjitter(riotprotests_date_ppp,\n                                    retry = TRUE,\n                                    nsim = 1,\n                                    drop = TRUE)\n\n\nany(duplicated(riotprotests_date_ppp_jit))\n\n[1] FALSE\n\n\nThere are no longer any duplicated points.\n\n\n7.4 Combining point events object and owin object\nWe then combine riotprotests_date_ppp_jit and yangon_owin, confining our analysis to the boundaries of mainland Yangon Region, and plot the output.\n\nriotprotests_owin &lt;- riotprotests_date_ppp_jit[yangon_owin]\n\n\nplot(riotprotests_owin)\n\n\n\n\n\n\n\n\n\n\n7.5 Computing Spatio-temporal KDE\nspattemp.density() of sparr package computes the STKDE.\n\nst_kde &lt;- spattemp.density(riotprotests_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 1484.59 (spatial)\n  lambda = 6.7613 (temporal)\n\nNo. of observations\n  1274 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [778189.2, 907883.7] x [1806567, 1970206]\n\nTemporal bound\n  [18638, 19878]\n\nEvaluation\n  128 x 128 x 1241 trivariate lattice\n  Density range: [0, 1.272137e-10]\n\n\n\n\n7.6 Plotting the spatio-temporal KDE object\nIn the code chunk below, plot() of base R is used to plot st_kde, and save_gif() of gifski is used to turn it into an animation. To display the animation, include_graphics() of knitr is then used.\n\ngifski::save_gif(\n  plot(st_kde, fix.range = TRUE),\n  gif_file = \"stkde_animation.gif\",\n  width = 800,\n  height = 600,\n  delay = 0.1,\n  loop = TRUE,\n  progress = TRUE)\n\n\nknitr::include_graphics(\"stkde_animation.gif\")\n\n\n\n\n\n\n\n\nAs we would expect, we can clearly see an initial surge in the intensity of riots and protests around the City of Yangon proper (located at the fork of the Yangon River) when the animation begins, around the time of the coup in 2021, which then gradually peters out as the Tatmadaw reasserted control, with rather low intensity thereafter. In addition, low intensity is observed in most of the rest of Yangon Region throughout the entire period, again confirming our prior knowledge than the City of Yangon itself was the locus of mass demonstrations against the coup."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#display-the-kde-layers-on-openstreetmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#display-the-kde-layers-on-openstreetmap",
    "title": "Take-Home Exercise 1",
    "section": "8.0 Display the KDE layers on openstreetmap",
    "text": "8.0 Display the KDE layers on openstreetmap\n\n8.1 Converting KDE output into grid object.\nFor the remaining analysis, we will focus on events occurring in Q1 2021, when the coup occurred.\nWe first convert the KDE output into grid object so that it is suitable for mapping purposes.\n\ngridded_kde_Q121 &lt;- as(kde_armedconflictQ121mm_kmCvL,  \"SpatialGridDataFrame\")\n\n\n\n8.2 Converting gridded output into raster\nNext, we will convert the gridded kernel density objects into RasterLayer objects by using raster() of raster package.\n\nkde_Q121_raster &lt;- raster(gridded_kde_Q121)\n\n\nkde_Q121_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 7.293429, 16.32739  (x, y)\nextent     : 414.0715, 1347.63, 1076.012, 3165.918  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -5.931695e-18, 0.04771807  (min, max)\n\n\nNotice that the CRS property is NA. The code chunk below will be used to include the CRS information. In addition, recall that the default measurement of the Indian 1954 / UTM zone 46N system is in metres. However, we rescaled the data earlier so that the units of measurement would be in kilometers. We must now account for this. (This method was inspired by a previous participant in this course, namely Khant, 2024).\n\nprojection(kde_Q121_raster) &lt;- CRS(\"+init=EPSG:23946 +units=km\")\n\n\n\n8.3 Visualising the output in tmap\nWe can now display the output on OpenStreetMap of Myanmar using tmap.\n\ntmap_mode(\"view\")\n\ntm_basemap(\"OpenStreetMap\") +\n  tm_shape(kde_Q121_raster) +\n  tm_raster(\"v\", alpha = 0.5, palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-Geospatial",
    "section": "",
    "text": "Welcome to my IS415 Geospatial Analytics and Applications website. In this website, you will find my coursework."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "title": "In-Class Exercise 10",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, gtsummary, sf, tmap, tidyverse, performance, see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#getting-started",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#getting-started",
    "title": "In-Class Exercise 10",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, gtsummary, sf, tmap, tidyverse, performance, see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#importing-the-data",
    "title": "In-Class Exercise 10",
    "section": "Importing the data",
    "text": "Importing the data\n\ncondo_resale &lt;- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\n\ncondo_resale_sf &lt;- read_rds(\"data/rds/condo_resale_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#correlation-analysis---ggstatsplot-methods",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#correlation-analysis---ggstatsplot-methods",
    "title": "In-Class Exercise 10",
    "section": "Correlation Analysis - ggstatsplot methods",
    "text": "Correlation Analysis - ggstatsplot methods\n\nggcorrmat(condo_resale[, 5:23])"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#building-a-hedonic-pricing-model-by-using-mlr-method",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#building-a-hedonic-pricing-model-by-using-mlr-method",
    "title": "In-Class Exercise 10",
    "section": "Building a Hedonic Pricing Model by using MLR Method",
    "text": "Building a Hedonic Pricing Model by using MLR Method\n\ncondo_mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale_sf)\n\nsummary(condo_mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#introducing-olsrr-package",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#introducing-olsrr-package",
    "title": "In-Class Exercise 10",
    "section": "Introducing olsrr package",
    "text": "Introducing olsrr package\nolsrr provides a collection of useful methods for building better multiple linear regression models. We will use it for:\n\ncomprehensive regression output\nvariable selection procedures"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#generating-tidy-linear-regression-report",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#generating-tidy-linear-regression-report",
    "title": "In-Class Exercise 10",
    "section": "Generating tidy linear regression report",
    "text": "Generating tidy linear regression report\n\nolsrr_condo &lt;- ols_regress(condo_mlr)\n\nAlternatively, you can pass the formula directly into ols_regress().\n\nols_regress(SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale_sf)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750799.558 \nR-Squared                    0.652       MSE                571258408962.149 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42970.175 \nMAE                     413425.809       SBC                       43075.567 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515174e+15          18        8.417631e+13    147.352    0.0000 \nResidual      8.094732e+14        1417    571258408962.149                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     481728.405    121441.014                   3.967    0.000     243504.909     719951.900 \n            AREA_SQM      12708.324       369.590        0.580     34.385    0.000      11983.322      13433.326 \n                 AGE     -24440.816      2763.164       -0.165     -8.845    0.000     -29861.148     -19020.484 \n            PROX_CBD     -78669.779      6768.972       -0.268    -11.622    0.000     -91948.061     -65391.496 \n      PROX_CHILDCARE    -351617.910    109467.252       -0.092     -3.212    0.001    -566353.201    -136882.619 \n    PROX_ELDERLYCARE     171029.418     42110.506        0.083      4.061    0.000      88423.783     253635.053 \nPROX_URA_GROWTH_AREA      38474.534     12523.567        0.059      3.072    0.002      13907.809      63041.258 \n  PROX_HAWKER_MARKET      23746.098     29299.755        0.019      0.810    0.418     -33729.461      81221.657 \n   PROX_KINDERGARTEN     147468.986     82668.868        0.031      1.784    0.075     -14697.534     309635.506 \n            PROX_MRT    -314599.679     57947.441       -0.120     -5.429    0.000    -428271.672    -200927.687 \n           PROX_PARK     563280.499     66551.675        0.148      8.464    0.000     432730.102     693830.897 \n    PROX_PRIMARY_SCH     180186.083     65237.948        0.070      2.762    0.006      52212.744     308159.421 \nPROX_TOP_PRIMARY_SCH       2280.036     20410.435        0.002      0.112    0.911     -37757.880      42317.951 \n  PROX_SHOPPING_MALL    -206604.057     42840.595       -0.108     -4.823    0.000    -290641.863    -122566.252 \n    PROX_SUPERMARKET     -44991.803     77082.635       -0.012     -0.584    0.560    -196200.149     106216.542 \n       PROX_BUS_STOP     683121.347    138353.278        0.134      4.938    0.000     411722.087     954520.608 \n         NO_Of_UNITS       -231.180        89.033       -0.050     -2.597    0.010       -405.830        -56.530 \n     FAMILY_FRIENDLY     140340.770     47020.551        0.055      2.985    0.003      48103.399     232578.141 \n            FREEHOLD     359913.008     49220.224        0.140      7.312    0.000     263360.671     456465.345 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#variable-selection",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#variable-selection",
    "title": "In-Class Exercise 10",
    "section": "Variable selection",
    "text": "Variable selection\nStepwise regression is the iterative construction of a regression model that involves the selection of independent variables to be used in a final model. It involves adding/removing potential explanatory variables in succession and testing for statistical significance after each iteration.\n\nForward stepwise regression\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE)\n\ncondo_fw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Base Model              44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP           42984.951    43048.186    38909.581    0.64424    0.64175 \n 11     FAMILY_FRIENDLY         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH        42966.758    43051.072    38891.872    0.65067    0.64723 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_fw_mlr)\n\n\n\n\n\n\n\n\n\n\nBackward stepwise regression\n\ncondo_bw_mlr &lt;- ols_step_backward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE)\n\ncondo_bw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Full Model              42970.175    43075.567    38895.493    0.65179    0.64736 \n 1      PROX_TOP_PRIMARY_SCH    42968.188    43068.310    38893.478    0.65178    0.64761 \n 2      PROX_SUPERMARKET        42966.534    43061.387    38891.789    0.65170    0.64777 \n 3      PROX_HAWKER_MARKET      42965.558    43055.141    38890.764    0.65145    0.64777 \n 4      PROX_KINDERGARTEN       42966.758    43051.072    38891.872    0.65067    0.64723 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\nBidirectional stepwise regression\n\ncondo_both_mlr &lt;- ols_step_both_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE)\n\ncondo_both_mlr\n\n\n                                       Stepwise Summary                                        \n---------------------------------------------------------------------------------------------\nStep    Variable                       AIC          SBC         SBIC         R2       Adj. R2 \n---------------------------------------------------------------------------------------------\n 0      Base Model                  44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM (+)                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD (+)                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK (+)               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD (+)                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE (+)                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE (+)        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL (+)      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA (+)    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT (+)                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP (+)           42984.951    43048.186    38909.581    0.64424    0.64175 \n 11     FAMILY_FRIENDLY (+)         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS (+)             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE (+)          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH (+)        42966.758    43051.072    38891.872    0.65067    0.64723 \n 15     PROX_KINDERGARTEN (+)       42965.558    43055.141    38890.764    0.65145    0.64777 \n---------------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751161.087 \nR-Squared                    0.651       MSE                570600646491.086 \nAdj. R-Squared               0.648       Coef. Var                    43.135 \nPred R-Squared               0.638       AIC                       42965.558 \nMAE                     413583.799       SBC                       43055.141 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.514394e+15          15        1.009596e+14    176.936    0.0000 \nResidual      8.102529e+14        1420    570600646491.086                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     459826.675    114616.014                   4.012    0.000     234991.777     684661.574 \n            AREA_SQM      12720.174       368.610        0.581     34.509    0.000      11997.096      13443.252 \n            PROX_CBD     -75676.065      5816.474       -0.258    -13.011    0.000     -87085.870     -64266.259 \n           PROX_PARK     575749.528     65523.382        0.151      8.787    0.000     447216.504     704282.552 \n            FREEHOLD     360203.286     48768.851        0.140      7.386    0.000     264536.552     455870.021 \n                 AGE     -24697.719      2752.751       -0.167     -8.972    0.000     -30097.615     -19297.824 \n    PROX_ELDERLYCARE     182435.081     39910.469        0.088      4.571    0.000     104145.268     260724.893 \n  PROX_SHOPPING_MALL    -224513.955     36588.872       -0.117     -6.136    0.000    -296288.004    -152739.906 \nPROX_URA_GROWTH_AREA      40145.474     11758.824        0.062      3.414    0.001      17078.942      63212.007 \n            PROX_MRT    -311753.202     57670.032       -0.119     -5.406    0.000    -424880.814    -198625.590 \n       PROX_BUS_STOP     711858.014    135420.040        0.140      5.257    0.000     446213.188     977502.840 \n     FAMILY_FRIENDLY     144034.218     46874.683        0.057      3.073    0.002      52083.153     235985.283 \n         NO_Of_UNITS       -236.270        88.032       -0.051     -2.684    0.007       -408.956        -63.583 \n      PROX_CHILDCARE    -336118.857    108331.761       -0.088     -3.103    0.002    -548626.339    -123611.374 \n    PROX_PRIMARY_SCH     162183.897     60202.895        0.063      2.694    0.007      44087.730     280280.063 \n   PROX_KINDERGARTEN     141915.768     79726.155        0.029      1.780    0.075     -14477.927     298309.464 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#model-selection",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#model-selection",
    "title": "In-Class Exercise 10",
    "section": "Model selection",
    "text": "Model selection\nIn the code chunk below, compare_performance of performance package is used to compare the performance of the models.\n\nmetric &lt;- compare_performance(condo_mlr,\n                              condo_fw_mlr$model,\n                              condo_bw_mlr$model,\n                              condo_both_mlr$model)\n\nIn the code chunk below, gsub() is used to tidy the test value in Name field.\n\nmetric$Name &lt;- gsub(\".*\\\\\\\\([a-zA-Z0-9_]+)\\\\\\\\, \\\\\\\\model\\\\\\\\.*\", \"\\\\1\", metric$Name)\n\nIn the code chunk below, plot() of see package is used to plot a radar chart to compare the performance measures of the models.\nThe different indices are normalised and larger values indicate better model performance. Points closer to the centre indicate worse fit indices.\n\nplot(metric)\n\n\n\n\n\n\n\n# plot for condo_both_mlr(lm) is covered by plot for condo_fw_mlr(lm)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#visualising-model-parameters",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#visualising-model-parameters",
    "title": "In-Class Exercise 10",
    "section": "Visualising model parameters",
    "text": "Visualising model parameters\n\nggcoefstats(condo_both_mlr$model, sort = \"ascending\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#checking-for-multicollinearity",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#checking-for-multicollinearity",
    "title": "In-Class Exercise 10",
    "section": "Checking for multicollinearity",
    "text": "Checking for multicollinearity\n\ncheck_collinearity(condo_both_mlr$model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n             AREA_SQM 1.15 [1.10, 1.24]         1.07      0.87     [0.81, 0.91]\n             PROX_CBD 1.60 [1.50, 1.73]         1.27      0.62     [0.58, 0.67]\n            PROX_PARK 1.21 [1.15, 1.30]         1.10      0.83     [0.77, 0.87]\n             FREEHOLD 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n                  AGE 1.41 [1.33, 1.52]         1.19      0.71     [0.66, 0.75]\n     PROX_ELDERLYCARE 1.52 [1.42, 1.63]         1.23      0.66     [0.61, 0.70]\n   PROX_SHOPPING_MALL 1.49 [1.40, 1.60]         1.22      0.67     [0.62, 0.72]\n PROX_URA_GROWTH_AREA 1.33 [1.26, 1.43]         1.16      0.75     [0.70, 0.79]\n             PROX_MRT 1.96 [1.83, 2.13]         1.40      0.51     [0.47, 0.55]\n        PROX_BUS_STOP 2.89 [2.66, 3.15]         1.70      0.35     [0.32, 0.38]\n      FAMILY_FRIENDLY 1.38 [1.30, 1.48]         1.18      0.72     [0.67, 0.77]\n          NO_Of_UNITS 1.45 [1.37, 1.56]         1.21      0.69     [0.64, 0.73]\n       PROX_CHILDCARE 3.29 [3.02, 3.59]         1.81      0.30     [0.28, 0.33]\n     PROX_PRIMARY_SCH 2.21 [2.05, 2.40]         1.49      0.45     [0.42, 0.49]\n    PROX_KINDERGARTEN 1.11 [1.06, 1.20]         1.05      0.90     [0.84, 0.94]\n\n\n\nplot(check_collinearity(condo_both_mlr$model)) +\n  theme(axis.text.x = element_text(\n        angle = 45, hjust = 1))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#linearity-assumption-test",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#linearity-assumption-test",
    "title": "In-Class Exercise 10",
    "section": "Linearity assumption test",
    "text": "Linearity assumption test\n\nout &lt;- plot(check_model(condo_both_mlr$model, panel = FALSE))\n\nout[[2]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#normality-assumption-test",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#normality-assumption-test",
    "title": "In-Class Exercise 10",
    "section": "Normality assumption test",
    "text": "Normality assumption test\n\nplot(check_normality(condo_both_mlr$model))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#checking-of-outliers",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#checking-of-outliers",
    "title": "In-Class Exercise 10",
    "section": "Checking of outliers",
    "text": "Checking of outliers\n\noutliers &lt;- check_outliers(condo_both_mlr$model,\n                           method = \"cook\")\n\noutliers\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (1).\n- For variable: (Whole model)\n\n\n\nplot(check_outliers(condo_both_mlr$model,\n                           method = \"cook\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#spatial-non-stationary-assumption",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#spatial-non-stationary-assumption",
    "title": "In-Class Exercise 10",
    "section": "Spatial Non-stationary Assumption",
    "text": "Spatial Non-stationary Assumption\nThe hedonic model we try to build uses geographically referenced attributes, hence it is also important for us to visualise the residuals of the hedonic pricing mode.\n\nH0: The residuals are randomly distributed (aka spatially stationary)\nH1: The residuals are spatially non-stationary (signs of clustering/regularity)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Load sf, spdep, tmap, tidyverse, knitr and GWmodel.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\n\n\nImport the Hunan shapefile and parse it into sf polygon feature object\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nImport Hunan_2012.csv\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nclass(hunan2012)\n\nJoin the two data sets. The two data sets are joined on “County”. Examine the data sets first to ensure that the county names in both are consistent (note that R is case-sensitive)\n\n# The code chunk is displayed, but is not run\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\n\n\n\n\nNote: GWmodel is built around sp and not sf formats.\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\n\n\n\nDetermine adaptive bandwidth\n\n# Method 1: Cross-validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\n# Method 2: AIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n# longlat = TRUE shows that coordinates are in latitude/longitude format - R will transform it to projected coordinate system, end unit will be km\n\nCompute geographically weighted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\nLM: local mean\nLSD: local standard deviation\nLV: local variance\nLSKe: local skewness\nLCV: local coefficient of variation\nLocal means: 22 closest neighbours (and itself)\n\n\nExtract SDF data table from gwss object output and convert into data.frame.\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\ncbind() is used to append the newly derived data.frame onto hunan_sf.\nNote: cbind() assumes that order of observations is the same in both dataframes. Does not work if either has been sorted.\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\n\nGeographically weighted mean\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\", n = 5, style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geograpically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE\n            )\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Method 1: Cross-validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\n# Method 2: AIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#loading-the-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#loading-the-packages",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Load sf, spdep, tmap, tidyverse, knitr and GWmodel.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-data",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Import the Hunan shapefile and parse it into sf polygon feature object\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nImport Hunan_2012.csv\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nclass(hunan2012)\n\nJoin the two data sets. The two data sets are joined on “County”. Examine the data sets first to ensure that the county names in both are consistent (note that R is case-sensitive)\n\n# The code chunk is displayed, but is not run\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#converting-to-spatialpolygondataframe",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#converting-to-spatialpolygondataframe",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Note: GWmodel is built around sp and not sf formats.\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Determine adaptive bandwidth\n\n# Method 1: Cross-validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\n# Method 2: AIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n# longlat = TRUE shows that coordinates are in latitude/longitude format - R will transform it to projected coordinate system, end unit will be km\n\nCompute geographically weighted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\nLM: local mean\nLSD: local standard deviation\nLV: local variance\nLSKe: local skewness\nLCV: local coefficient of variation\nLocal means: 22 closest neighbours (and itself)\n\n\nExtract SDF data table from gwss object output and convert into data.frame.\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\ncbind() is used to append the newly derived data.frame onto hunan_sf.\nNote: cbind() assumes that order of observations is the same in both dataframes. Does not work if either has been sorted.\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\n\nGeographically weighted mean\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\", n = 5, style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geograpically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE\n            )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "# Method 1: Cross-validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\n# Method 2: AIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415-Geospatial",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Install and load sf and tidyverse packages into R environment.\n\npacman::p_load(tidyverse, sf)\n\nThis code chunk imports shapefile.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThis code chunk imports kml file.\n\n# mpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\nThe second code chunk does not work due to a problem with the source. We use the following code chunk to export mpsz14_shp into kml format and save the output in the data subfolder.\n\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n#delete_dsn = TRUE avoids Error: Dataset already exists."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-2014-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-2014-subzone-boundary-data",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Install and load sf and tidyverse packages into R environment.\n\npacman::p_load(tidyverse, sf)\n\nThis code chunk imports shapefile.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThis code chunk imports kml file.\n\n# mpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\nThe second code chunk does not work due to a problem with the source. We use the following code chunk to export mpsz14_shp into kml format and save the output in the data subfolder.\n\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n#delete_dsn = TRUE avoids Error: Dataset already exists."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "title": "In-class Exercise 2",
    "section": "Working with Master Plan 2019 Subzone Boundary Data",
    "text": "Working with Master Plan 2019 Subzone Boundary Data\nThis code chunk imports shapefile.\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\", layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThis code chunk imports kml.\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nTransform the data to the svy21 projected coordinate system.\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nCheck the CRS.\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz19_kml)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-population-data",
    "title": "In-class Exercise 2",
    "section": "Working with Population Data",
    "text": "Working with Population Data\nImport the data.\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")\n\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG, values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,`ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\nJoining popdata2023 and mpsz19_shp\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), .funs = list(toupper))\n  \npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.\n\n\n\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)\n\n\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nCreating and customizing ‘ggplot2’- based publication ready plots\n\nggpubr\n\nCreating publication-ready summary tables in R\n\ngtsummary\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n\n\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.\n\n\n\n\n\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. It is also important to note that mpsz simple feature object does not have EPSG information.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\n\nThe code chunk below updates the newly imported mpsz with the correct ESPG code for svy21 (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, we will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\n\n\n\n\n\n\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunk below uses glimpse() to display the data structure of condo_resale.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nTo see the data in LONGITUDE (x-coordinate) column:\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\nTo see the data in the LATITUDE (y-coordinate) column:\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nThe coordinates appear to be in the wgs84 coordinate reference system (EPSG: 4326).\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame.\n\n\n\n\nIn the section, we will learn how to use statistical graphics functions of ggplot2 package to perform EDA.\n\n\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data = condo_resale.sf, aes(x = `SELLING_PRICE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that most condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data = condo_resale.sf, aes(x = `LOG_SELLING_PRICE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n\nIn this section, we will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histograms into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data = condo_resale.sf, aes(x = `AREA_SQM`)) + \n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nAGE &lt;- ggplot(data = condo_resale.sf, aes(x = `AGE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CBD &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CBD`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CHILDCARE`)) + \n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data = condo_resale.sf, \n                               aes(x = `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_MRT &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_MRT`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PARK &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PARK`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, \n                               aes(x = `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\nLastly, we want to reveal the geospatial distribution of condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.5) +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style = \"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")\n\n\n\n\n\nIn this section, we will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or, for multiple responses of class, c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\ny = -258121.1 + 14719x1\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis and infer that the simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data = condo_resale.sf,  \n       aes(x = `AREA_SQM`, y = `SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n\n\n\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\nIn this section, we would like to introduce a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\nIn multiple linear regression, it is important for us to test the assumption of linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residuals of the multiple linear regression model (i.e. condo.mlr1) resemble normal distribution.\nIf we prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residuals are not normally distributed.\n\n\n\nThe hedonic model we try to build is using geographically referenced attributes, hence it is also important for us to visualise the residual of the hedonic pricing model.\nFirst, we will export the residuals of the hedonic pricing model and save this as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nRemember to switch back to “plot” mode before continuing.\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights matrix.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that its p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-data",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "Two data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#getting-started",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "Before we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nCreating and customizing ‘ggplot2’- based publication ready plots\n\nggpubr\n\nCreating publication-ready summary tables in R\n\ngtsummary\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#a-short-note-about-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#a-short-note-about-gwmodel",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "GWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "The geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. It is also important to note that mpsz simple feature object does not have EPSG information.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\n\nThe code chunk below updates the newly imported mpsz with the correct ESPG code for svy21 (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, we will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#aspatial-data-wrangling",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "The condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunk below uses glimpse() to display the data structure of condo_resale.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nTo see the data in LONGITUDE (x-coordinate) column:\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\nTo see the data in the LATITUDE (y-coordinate) column:\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nThe coordinates appear to be in the wgs84 coordinate reference system (EPSG: 4326).\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In the section, we will learn how to use statistical graphics functions of ggplot2 package to perform EDA.\n\n\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data = condo_resale.sf, aes(x = `SELLING_PRICE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that most condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data = condo_resale.sf, aes(x = `LOG_SELLING_PRICE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n\nIn this section, we will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histograms into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data = condo_resale.sf, aes(x = `AREA_SQM`)) + \n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nAGE &lt;- ggplot(data = condo_resale.sf, aes(x = `AGE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CBD &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CBD`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CHILDCARE`)) + \n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data = condo_resale.sf, \n                               aes(x = `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_MRT &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_MRT`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PARK &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PARK`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, \n                               aes(x = `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\nLastly, we want to reveal the geospatial distribution of condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.5) +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style = \"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#hedonic-pricing-modelling-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#hedonic-pricing-modelling-in-r",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In this section, we will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or, for multiple responses of class, c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\ny = -258121.1 + 14719x1\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis and infer that the simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data = condo_resale.sf,  \n       aes(x = `AREA_SQM`, y = `SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n\n\n\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\nIn this section, we would like to introduce a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\nIn multiple linear regression, it is important for us to test the assumption of linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residuals of the multiple linear regression model (i.e. condo.mlr1) resemble normal distribution.\nIf we prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residuals are not normally distributed.\n\n\n\nThe hedonic model we try to build is using geographically referenced attributes, hence it is also important for us to visualise the residual of the hedonic pricing model.\nFirst, we will export the residuals of the hedonic pricing model and save this as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nRemember to switch back to “plot” mode before continuing.\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights matrix.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that its p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis types, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, we will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto perform cluster analysis by using hclust() of Base R;\nto visualise the analysis output by using ggplot2 and tmap package.\n\n\n\n\n\n\n\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are downloaded from Myanmar Information Management Unit (MIMU)\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse)\n\n\n\n\nIn this section, we import Myanmar Township Boundary GIS data and its associated attribute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\")  %&gt;%\n  dplyr::filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  dplyr::select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveals the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\n\n\nThe unit of measurement of the values is number of households. Using these values directly will be biased by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR.\n\n\n\n\n\n\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution).\n\nggplot(data = ict_derived, aes(x = `RADIO`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data = ict_derived, aes(x = `RADIO`)) +\n  geom_boxplot(color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data = ict_derived, \n       aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data = ict_derived, \n       aes(x = `RADIO_PR`)) +\n  geom_boxplot(color = \"black\", \n               fill = \"light blue\")\n\n\n\n\n\n\n\n\nThe variable RADIO has a right-skewed distribution and there are three townships that are seemingly outliers with extremely high RADIO values (over 10000 households), even though most townships have relatively low RADIO values with the median being around 2500 households. However, when we use the penetration rate RADIO_PR instead, this has a closer to normal distribution with a median of slightly more than 200 per 1000 households, and there is only one outlier with an extremely high radio penetration rate of less than 500 per 1000 households.\nThe code chunks below are used to create multiple histograms and reveal the distribution of the selected variables in the ict_derived data.frame. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data = ict_derived, \n             aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color =\"black\", \n                 fill = \"light blue\")\n\ntv &lt;- ggplot(data = ict_derived, \n             aes(x = `TV_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\nllphone &lt;- ggplot(data = ict_derived, \n             aes(x = `LLPHONE_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\nmphone &lt;- ggplot(data = ict_derived, \n             aes(x = `MPHONE_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\ncomputer &lt;- ggplot(data = ict_derived, \n             aes(x = `COMPUTER_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\ninternet &lt;- ggplot(data = ict_derived, \n             aes(x = `INTERNET_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by = \"TS_PCODE\")\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nThe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal that the distribution shown in the choropleth map above is biased by the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp = NA, ncol = 2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger total number of households also show relatively higher numbers of households that own radios.\nNow let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins = 0, asp=0)\n\n\n\n\n\n\n\n\nWe can clearly see that some townships that appeared to have a low number of households owning radios actually had very high radio penetration rates, including in townships in the northwestern corner, along the southwestern border, and in the southeastern corner of the state.\n\n\n\n\n\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated (which will give rise to multicollinearity).\nIn this section, we use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\n\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both.\n\n\n\nIn this section, we learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\nFirst, we use st_set_geometry(NULL) to remove the geometry list-column and coerce shan_sf to a data.frame.\nThen we select the columns containing the township names and the clustering variables.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  dplyr::select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\n\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced by the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- dplyr::select(cluster_vars, c(2:6))\n\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\nIn general, multiple variables will be used in cluster analysis. It is not unusual for their values range to be different. In order to avoid the cluster analysis result being biased to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n\nIn the code chunk below, normalize() of heatmaply package is used to stadardise the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\n\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values ranges of the Min-max standardised clustering variables are 0-1 now.\n\n\n\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardise the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\nBesides reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphically.\nThe code chunk below plots the scaled Radio_PR field.\n\nr &lt;- ggplot(data = ict_derived, \n             aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  ggtitle(\"Raw values (unstandardised)\") +\n  theme(plot.title = element_text(size = 10))\n\n\ns &lt;- ggplot(data = shan_ict.std, \n       aes(x =`RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")  +\n  theme(plot.title = element_text(size = 10))\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\n\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  ggtitle(\"Z-score Standardisation\")  +\n  theme(plot.title = element_text(size = 10))\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\nWe conclude that standardisation does not affect the shapes of the distributions of the clustering variables, but only changes the scales.\nThis is even clearer when we visualise the distributions using density plots instead of histograms.\n\nr &lt;- ggplot(data = ict_derived, \n             aes(x = `RADIO_PR`)) +\n  geom_density(color = \"black\",\n               fill = \"light blue\") +\n  ggtitle(\"Raw values (unstandardised)\")  +\n  theme(plot.title = element_text(size = 8))\n\ns &lt;- ggplot(data = shan_ict.std, \n       aes(x = `RADIO_PR`)) +\n  geom_density(color = \"black\",\n               fill = \"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")  +\n  theme(plot.title = element_text(size = 8))\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\n\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x = `RADIO_PR`)) +\n  geom_density(color = \"black\",\n               fill = \"light blue\") +\n  ggtitle(\"Z-score Standardisation\")  +\n  theme(plot.title = element_text(size = 8))\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\nIn R, there are several packages that provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\nAnother technical challenge faced by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximizes the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\n\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package. This function computes hierarchical clustering (the default hierarchical clustering function used is hclust) and cuts the tree into k clusters.\nWe can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the next largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument k specifies the number of clusters produced when the tree is cut. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\n\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n\n\nheatmaply(normalize(shan_ict_mat),\n          Colv = NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n\nWith close examination of the dendrogram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k = 6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the clusters formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitations when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis types, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, we will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto perform cluster analysis by using hclust() of Base R;\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "Two data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are downloaded from Myanmar Information Management Unit (MIMU)\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse)\n\n\n\n\nIn this section, we import Myanmar Township Boundary GIS data and its associated attribute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\")  %&gt;%\n  dplyr::filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  dplyr::select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveals the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\n\n\nThe unit of measurement of the values is number of households. Using these values directly will be biased by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "We can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution).\n\nggplot(data = ict_derived, aes(x = `RADIO`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data = ict_derived, aes(x = `RADIO`)) +\n  geom_boxplot(color = \"black\", fill = \"light blue\")\n\n\n\n\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data = ict_derived, \n       aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data = ict_derived, \n       aes(x = `RADIO_PR`)) +\n  geom_boxplot(color = \"black\", \n               fill = \"light blue\")\n\n\n\n\n\n\n\n\nThe variable RADIO has a right-skewed distribution and there are three townships that are seemingly outliers with extremely high RADIO values (over 10000 households), even though most townships have relatively low RADIO values with the median being around 2500 households. However, when we use the penetration rate RADIO_PR instead, this has a closer to normal distribution with a median of slightly more than 200 per 1000 households, and there is only one outlier with an extremely high radio penetration rate of less than 500 per 1000 households.\nThe code chunks below are used to create multiple histograms and reveal the distribution of the selected variables in the ict_derived data.frame. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data = ict_derived, \n             aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color =\"black\", \n                 fill = \"light blue\")\n\ntv &lt;- ggplot(data = ict_derived, \n             aes(x = `TV_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\nllphone &lt;- ggplot(data = ict_derived, \n             aes(x = `LLPHONE_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\nmphone &lt;- ggplot(data = ict_derived, \n             aes(x = `MPHONE_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\ncomputer &lt;- ggplot(data = ict_derived, \n             aes(x = `COMPUTER_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\ninternet &lt;- ggplot(data = ict_derived, \n             aes(x = `INTERNET_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by = \"TS_PCODE\")\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nThe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal that the distribution shown in the choropleth map above is biased by the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp = NA, ncol = 2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger total number of households also show relatively higher numbers of households that own radios.\nNow let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins = 0, asp=0)\n\n\n\n\n\n\n\n\nWe can clearly see that some townships that appeared to have a low number of households owning radios actually had very high radio penetration rates, including in townships in the northwestern corner, along the southwestern border, and in the southeastern corner of the state."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#correlation-analysis",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "Before we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated (which will give rise to multicollinearity).\nIn this section, we use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\n\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#hierarchy-cluster-analysis",
    "title": "Hands-On Exercise 7",
    "section": "",
    "text": "In this section, we learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\nFirst, we use st_set_geometry(NULL) to remove the geometry list-column and coerce shan_sf to a data.frame.\nThen we select the columns containing the township names and the clustering variables.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  dplyr::select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\n\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced by the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- dplyr::select(cluster_vars, c(2:6))\n\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\nIn general, multiple variables will be used in cluster analysis. It is not unusual for their values range to be different. In order to avoid the cluster analysis result being biased to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n\nIn the code chunk below, normalize() of heatmaply package is used to stadardise the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\n\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values ranges of the Min-max standardised clustering variables are 0-1 now.\n\n\n\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardise the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\nBesides reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphically.\nThe code chunk below plots the scaled Radio_PR field.\n\nr &lt;- ggplot(data = ict_derived, \n             aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  ggtitle(\"Raw values (unstandardised)\") +\n  theme(plot.title = element_text(size = 10))\n\n\ns &lt;- ggplot(data = shan_ict.std, \n       aes(x =`RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")  +\n  theme(plot.title = element_text(size = 10))\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\n\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  ggtitle(\"Z-score Standardisation\")  +\n  theme(plot.title = element_text(size = 10))\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\nWe conclude that standardisation does not affect the shapes of the distributions of the clustering variables, but only changes the scales.\nThis is even clearer when we visualise the distributions using density plots instead of histograms.\n\nr &lt;- ggplot(data = ict_derived, \n             aes(x = `RADIO_PR`)) +\n  geom_density(color = \"black\",\n               fill = \"light blue\") +\n  ggtitle(\"Raw values (unstandardised)\")  +\n  theme(plot.title = element_text(size = 8))\n\ns &lt;- ggplot(data = shan_ict.std, \n       aes(x = `RADIO_PR`)) +\n  geom_density(color = \"black\",\n               fill = \"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")  +\n  theme(plot.title = element_text(size = 8))\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\n\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x = `RADIO_PR`)) +\n  geom_density(color = \"black\",\n               fill = \"light blue\") +\n  ggtitle(\"Z-score Standardisation\")  +\n  theme(plot.title = element_text(size = 8))\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\nIn R, there are several packages that provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\nAnother technical challenge faced by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximizes the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\n\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package. This function computes hierarchical clustering (the default hierarchical clustering function used is hclust) and cuts the tree into k clusters.\nWe can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the next largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument k specifies the number of clusters produced when the tree is cut. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\n\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n\n\nheatmaply(normalize(shan_ict_mat),\n          Colv = NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n\nWith close examination of the dendrogram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k = 6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the clusters formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitations when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, we learn how to compute spatial weights using R. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap, knitr and tidyverse packages of R are currently installed.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nView(hunan)\n\n\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nView(hunan2012)\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nglimpse(hunan_joined)\n\nRows: 88\nColumns: 7\n$ NAME_2    &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Chan…\n$ ID_3      &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2111…\n$ NAME_3    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ ENGTYPE_3 &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Coun…\n$ County    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ GDPPC     &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7066…\n$ geometry  &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 2…\n\n\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nclass(hunan_joined)\n\n[1] \"sf\"         \"data.frame\"\n\nbasemap &lt;- tm_shape(hunan_joined) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan_joined, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan_joined$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\n\nhunan_joined$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan_joined$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan_joined, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan_joined, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs.\nGetting Latitude and Longitude of Polygon Centroids:\nWe will need points to associated with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nAnswer: It means that the mean number of neighbours within 62km of each region point is 3.681818.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\n\ntable(hunan_joined$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nNotice that each county has exactly six neighbours.\n\n\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to derive a spatial weight matrix based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep. Then, we calculate the inverse of these distances.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\nNotice that the weights assigned to each neighbour are now unequal. The weights assigned to the neighbours of the first polygon correspond to the inverse distances calculated earlier and stored in ids.\n\n\n\nIn this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan_joined$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall in the previous section, we retrieved the GDPPC of the five nearest neighbours to polygon 1 by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan_joined$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\nAnswer: Spatial lag with row-standardized weights is the fraction 1/(#ofneighbors)\n\nWe can append the spatially lagged GDPPC values onto hunan_joined sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan_joined$NAME_3, GDPPC.lag)\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined,lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan_joined)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan_joined, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan_joined$NAME_3, lag.listw(b_weights2, hunan_joined$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined,lag.res)\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan_joined, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs, style=\"W\")\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan_joined$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan_joined$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan_joined, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan_joined %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan_joined, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan_joined$NAME_3, lag.listw(b_weights2, hunan_joined$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC valuTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.es onto hunan_joined sf data.frame by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan_joined, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan_joined %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan_joined, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, we learn how to compute spatial weights using R. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-study-area-and-data",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap, knitr and tidyverse packages of R are currently installed.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "The code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nView(hunan)\n\n\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nView(hunan2012)\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nglimpse(hunan_joined)\n\nRows: 88\nColumns: 7\n$ NAME_2    &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Chan…\n$ ID_3      &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2111…\n$ NAME_3    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ ENGTYPE_3 &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Coun…\n$ County    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ GDPPC     &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7066…\n$ geometry  &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 2…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Now, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nclass(hunan_joined)\n\n[1] \"sf\"         \"data.frame\"\n\nbasemap &lt;- tm_shape(hunan_joined) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan_joined, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan_joined$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\n\nhunan_joined$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan_joined$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan_joined, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan_joined, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs.\nGetting Latitude and Longitude of Polygon Centroids:\nWe will need points to associated with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this section, you will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nAnswer: It means that the mean number of neighbours within 62km of each region point is 3.681818.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\n\ntable(hunan_joined$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nNotice that each county has exactly six neighbours.\n\n\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#weights-based-on-idw",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this section, we will learn how to derive a spatial weight matrix based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep. Then, we calculate the inverse of these distances.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\nNotice that the weights assigned to each neighbour are now unequal. The weights assigned to the neighbours of the first polygon correspond to the inverse distances calculated earlier and stored in ids."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan_joined$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall in the previous section, we retrieved the GDPPC of the five nearest neighbours to polygon 1 by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan_joined$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\nAnswer: Spatial lag with row-standardized weights is the fraction 1/(#ofneighbors)\n\nWe can append the spatially lagged GDPPC values onto hunan_joined sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan_joined$NAME_3, GDPPC.lag)\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined,lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan_joined)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan_joined, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan_joined$NAME_3, lag.listw(b_weights2, hunan_joined$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined,lag.res)\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan_joined, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs, style=\"W\")\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan_joined$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan_joined$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan_joined, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan_joined %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan_joined, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan_joined$NAME_3, lag.listw(b_weights2, hunan_joined$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC valuTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.es onto hunan_joined sf data.frame by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan_joined, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan_joined %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan_joined, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-On Exercise 2",
    "section": "",
    "text": "In this chapter, we plot functional and truthful choropleth maps by using the tmap package.\n\n\n\nIn this hands-on exercise, the key R package used is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nreadr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nTwo data sets will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv).\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nBefore a thematic map can be prepared, we are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarize(`Pop` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG, values_from = Pop) %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,`ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThis can also be achieved using the across() function.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(.cols = c(PA, SZ), .fns = toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLastly, write_rds() is used to save mpsz_pop2020.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          title = \"Dependency Ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(col = \"black\", lwd = 0.1,  alpha = 1, lty = \"solid\")\n\n\n\n\n\n\n\n\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed than equal data classification method.\n\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, pretty data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, kmeans data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, hclust data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, bclust data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\nIn the code chunk below, fisher data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, jenks data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAs can be seen from the above maps, the kmeans, hclust, fisher and jenks methods produce more even distributions, while the pretty and bclust methods produce distributions that are highly skewed by outliers. The sd method also appears to produce distributions that are skewed by outliers, albeit less so than pretty and bclust. The fixed method’s outcome depends on the breaks that we choose.\n\n\n\nThe code chunk below shows a quantile data classification that used 2 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 2, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below shows a quantile data classification that used 6 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 6, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below shows a quantile data classification that used 10 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 10, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below shows a quantile data classification that used 20 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 20, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWith too few classes, a class can have an extremely wide range which makes the classification is no longer meaningful since features in the same class can be extremely different. On the other hand, with too many classes, the map becomes hard to read and features in adjacent classes are difficult to differentiate from each other. The classes may also no longer be meaningful since the range of each class is so small. Using 6 or 10 classes appears ideal.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 100)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", breaks = c(0, 0.60, 0.70, 0.80, 0.90, 100)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          n = 6, \n          style = \"quantile\", \n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in blue.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          n = 6, \n          style = \"quantile\", \n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\n by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nWe can reset the default style using the code below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\n by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining col in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n          style = c(\"equal\", \"quantile\"),\n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords = TRUE, \n            drop.units = TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\", style = \"quantile\", palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\", style = \"quantile\", palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.outside.size = 0.2,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-On Exercise 2",
    "section": "",
    "text": "In this chapter, we plot functional and truthful choropleth maps by using the tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-On Exercise 2",
    "section": "",
    "text": "In this hands-on exercise, the key R package used is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nreadr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data-into-r",
    "title": "Hands-On Exercise 2",
    "section": "",
    "text": "Two data sets will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv).\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nBefore a thematic map can be prepared, we are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarize(`Pop` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG, values_from = Pop) %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,`ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThis can also be achieved using the across() function.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(.cols = c(PA, SZ), .fns = toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLastly, write_rds() is used to save mpsz_pop2020.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-On Exercise 2",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          title = \"Dependency Ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(col = \"black\", lwd = 0.1,  alpha = 1, lty = \"solid\")\n\n\n\n\n\n\n\n\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed than equal data classification method.\n\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, pretty data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, kmeans data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, hclust data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, bclust data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\nIn the code chunk below, fisher data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, jenks data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAs can be seen from the above maps, the kmeans, hclust, fisher and jenks methods produce more even distributions, while the pretty and bclust methods produce distributions that are highly skewed by outliers. The sd method also appears to produce distributions that are skewed by outliers, albeit less so than pretty and bclust. The fixed method’s outcome depends on the breaks that we choose.\n\n\n\nThe code chunk below shows a quantile data classification that used 2 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 2, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below shows a quantile data classification that used 6 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 6, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below shows a quantile data classification that used 10 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 10, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below shows a quantile data classification that used 20 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 20, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWith too few classes, a class can have an extremely wide range which makes the classification is no longer meaningful since features in the same class can be extremely different. On the other hand, with too many classes, the map becomes hard to read and features in adjacent classes are difficult to differentiate from each other. The classes may also no longer be meaningful since the range of each class is so small. Using 6 or 10 classes appears ideal.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 100)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", breaks = c(0, 0.60, 0.70, 0.80, 0.90, 100)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          n = 6, \n          style = \"quantile\", \n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in blue.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          n = 6, \n          style = \"quantile\", \n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\n by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nWe can reset the default style using the code below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\n by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining col in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n          style = c(\"equal\", \"quantile\"),\n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords = TRUE, \n            drop.units = TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\", style = \"quantile\", palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\", style = \"quantile\", palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.outside.size = 0.2,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello world"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-On Exercise 1",
    "section": "",
    "text": "In this hands-on exercise, I learn how to perform geospatial data science tasks in R by using sf package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#overview",
    "title": "Hands-On Exercise 1",
    "section": "",
    "text": "In this hands-on exercise, I learn how to perform geospatial data science tasks in R by using sf package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-acquisition",
    "title": "Hands-On Exercise 1",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nIn this hands-on exercise, I extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-On Exercise 1",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nIn this hands-on exercise, two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\np_load function pf pacman package is used to install and load sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-On Exercise 1",
    "section": "1.4 Importing Geospatial Data",
    "text": "1.4 Importing Geospatial Data\nIn this section, I import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Importing polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n1.4.2 Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message above reveals that there are a total of 3138 features and 2 fields in cyclingpath linestring feature data frame and it is in svy21 projected coordinates system too.\n\n\n1.4.3 Importing GIS data in kml format\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-On Exercise 1",
    "section": "1.5 Checking the Content of A Simple Feature Data Frame",
    "text": "1.5 Checking the Content of A Simple Feature Data Frame\n\n1.5.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column using st_geometry().\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n1.5.2 Working with glimpse()\nWe also would like to learn more about the associated attribute information in the data frame. This is the time we use find glimpse() of dplyr.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n1.5.3 Working with head()\n\nhead(mpsz, n = 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-On Exercise 1",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nWe can visualise the geospatial features using plot() of R Graphic.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nWe can choose to plot only the geometry.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "title": "Hands-On Exercise 1",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21.\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nThe print below reveals that the preschool simple feature data frame is in wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThis is a scenario where st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-On Exercise 1",
    "section": "1.8 Importing and Converting An Aspatial Data",
    "text": "1.8 Importing and Converting An Aspatial Data\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, we import an aspatial data into R environment and save it as a tibble data frame. Next, we convert it into a simple feature data frame.\n\n1.8.1 Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nThe output reveals that listing tibble data frame consists of 3540 rows and 75 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n1.8.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                     coords = c(\"longitude\", \"latitude\"), \n                     crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-On Exercise 1",
    "section": "1.9 Geoprocessing with sf package",
    "text": "1.9 Geoprocessing with sf package\n\n1.9.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n1.9.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nTo calculate the density of pre-school by planning subzone, first use st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;% st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/ Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 1",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, we use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\n  labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are few planning sub-zones with at least 20 pre-schools\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nNext, using ggplot2 method, we plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data = mpsz3414,\n       aes(y = `PreSch Count` , x = as.numeric(`PreSch Density`))) +\n  geom_point(color=\"black\", fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\", x = \"Pre-school density (per km sq)\", y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childcare centres in Singapore.\n\n\n\nTo provide answers to the questions above, three data sets will be used. They are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nUse the code chunk below to install and launch the five R packages.\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\n\n\n\n\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\n\nDIY: Using the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that except childcare_sf, both mpsz_sf and sg_sf do not have proper crs information. The EPSG code indicated in the prints for mpsz_sf and sg_sf is 9001 even though both data frames are projected in svy21. The correct EPSG code for svy21 should be 3414.\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\nAssign the correct EPSG code for svy21 to mpsz_sf and sg_sf with the following code chunk.\n\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf, 3414)\nsg_sf3414 &lt;- st_set_crs(sg_sf, 3414)\n\n\nDIY: If necessary, changing the referencing system to Singapore national projected coordinate system.\n\nMeanwhile, childcare_sf is projected in the geographical coordinate system wgs84. We reproject it to the projected coordinate system svy21, which is more appropriate when the analysis requires distance and/or area measurements.\n\nchildcare_sf3414 &lt;- st_transform(childcare_sf, crs = 3414)\n\nst_crs(childcare_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nDIY: Using the mapping methods you learned in Hands-on Exercise 2, prepare a map as shown below.\n\n\ntmap_mode(\"plot\")\n\ntm_shape(sg_sf3414) + \n  tm_polygons() +\n    tm_shape(mpsz_sf3414) + \n      tm_polygons() + \n       tm_shape(childcare_sf3414) + \n         tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\n\ntmap_mode(\"plot\")\n\n\n\n\n\nIn this section, we will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf3414)\nmpsz &lt;- as_Spatial(mpsz_sf3414)\nsg &lt;- as_Spatial(sg_sf3414)\n\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now.\n\n\n\nspatstat requires the analytical data in ppp object form.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\n\nWe will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf3414), st_bbox(childcare_sf3414))\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the difference.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-incident points, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1 )\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntm_shape(childcare_sf3414) +\n  tm_dots(alpha=0.4, size=0.05)\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nIt is difficult to identify the duplicates from this map. There are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, retry = TRUE, nsim = 1, drop = TRUE)\n\nDIY: Using the method you learned in previous section, check if any duplicated point in this geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\nsum(multiplicity(childcare_ppp_jit) &gt; 1)\n\n[1] 0\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000025 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\n\n\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n\n\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth returned by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, kernel = \"gaussian\")\n\npar(mfrow = c(1,2), mar = c(1, 1, 1, 1))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE,\n             kernel = \"gaussian\"), \n     main = \"Gaussian\")\n\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"epanechnikov\"), \n     main = \"Epanechnikov\")\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"quartic\"), \n     main = \"Quartic\")\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"disc\"), \n     main = \"Disc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma = 0.6, edge = TRUE, kernel = \"gaussian\")\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, we derive adaptive kernel density estimation.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method = \"kernel\")\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow = c(1,2), mar = c(1, 1, 1, 1))\n\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nWe convert the KDE output so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\n\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n\n\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) +\n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “values” field.\n\n\n\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Ponggol\")\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that are required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(childcare_pg_ppp.km, main = \"Punggol\")\nplot(childcare_tm_ppp.km, main = \"Tampines\")\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(density(childcare_pg_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Punggol\")\n\nplot(density(childcare_tm_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Tempines\")\n\nplot(density(childcare_ck_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\n\nplot(density(childcare_jw_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"JUrong West\")\n\n\n\n\n\n\n\n\n\n\n\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(density(childcare_ck_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\n\nplot(density(childcare_jw_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\n\nplot(density(childcare_pg_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Punggol\")\n\nplot(density(childcare_tm_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp, \n                correction = \"none\", \n                clipregion = \"sg_owin\", \n                alternative = \"clustered\", \n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe p-value is extremely small. There is sufficient evidence to reject the null hypothesis that the distribution of childcare services is random. We conclude that childcare services are distributed in a clustered point pattern.\n\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centres in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = \"ck_owin\",\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.88006, p-value = 0.07312\nalternative hypothesis: two-sided\n\n\nThe p-value is extremely large. There is insufficient evidence to reject the null hypothesis that the distribution of childcare services is random in Choa Chu Kang.\n\n\n\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction = \"none\",\n                clipregion = \"tm_owin\",\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.81377, p-value = 0.0007767\nalternative hypothesis: two-sided\n\n\nThe p-value is extremely small. There is sufficent evidence to reject the null hypothesis and conclude that the distribution of childcare services is not random in Tampines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childcare centres in Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "To provide answers to the questions above, three data sets will be used. They are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nUse the code chunk below to install and launch the five R packages.\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\n\nDIY: Using the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that except childcare_sf, both mpsz_sf and sg_sf do not have proper crs information. The EPSG code indicated in the prints for mpsz_sf and sg_sf is 9001 even though both data frames are projected in svy21. The correct EPSG code for svy21 should be 3414.\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\nAssign the correct EPSG code for svy21 to mpsz_sf and sg_sf with the following code chunk.\n\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf, 3414)\nsg_sf3414 &lt;- st_set_crs(sg_sf, 3414)\n\n\nDIY: If necessary, changing the referencing system to Singapore national projected coordinate system.\n\nMeanwhile, childcare_sf is projected in the geographical coordinate system wgs84. We reproject it to the projected coordinate system svy21, which is more appropriate when the analysis requires distance and/or area measurements.\n\nchildcare_sf3414 &lt;- st_transform(childcare_sf, crs = 3414)\n\nst_crs(childcare_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nDIY: Using the mapping methods you learned in Hands-on Exercise 2, prepare a map as shown below.\n\n\ntmap_mode(\"plot\")\n\ntm_shape(sg_sf3414) + \n  tm_polygons() +\n    tm_shape(mpsz_sf3414) + \n      tm_polygons() + \n       tm_shape(childcare_sf3414) + \n         tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, we will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf3414)\nmpsz &lt;- as_Spatial(mpsz_sf3414)\nsg &lt;- as_Spatial(sg_sf3414)\n\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now.\n\n\n\nspatstat requires the analytical data in ppp object form.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\n\nWe will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf3414), st_bbox(childcare_sf3414))\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the difference.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-incident points, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1 )\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntm_shape(childcare_sf3414) +\n  tm_dots(alpha=0.4, size=0.05)\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nIt is difficult to identify the duplicates from this map. There are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, retry = TRUE, nsim = 1, drop = TRUE)\n\nDIY: Using the method you learned in previous section, check if any duplicated point in this geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\nsum(multiplicity(childcare_ppp_jit) &gt; 1)\n\n[1] 0\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000025 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\n\n\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n\n\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth returned by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, kernel = \"gaussian\")\n\npar(mfrow = c(1,2), mar = c(1, 1, 1, 1))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE,\n             kernel = \"gaussian\"), \n     main = \"Gaussian\")\n\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"epanechnikov\"), \n     main = \"Epanechnikov\")\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"quartic\"), \n     main = \"Quartic\")\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"disc\"), \n     main = \"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Next, we will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma = 0.6, edge = TRUE, kernel = \"gaussian\")\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, we derive adaptive kernel density estimation.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method = \"kernel\")\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow = c(1,2), mar = c(1, 1, 1, 1))\n\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nWe convert the KDE output so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\n\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n\n\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) +\n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “values” field.\n\n\n\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;% filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Ponggol\")\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that are required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(childcare_pg_ppp.km, main = \"Punggol\")\nplot(childcare_tm_ppp.km, main = \"Tampines\")\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(density(childcare_pg_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Punggol\")\n\nplot(density(childcare_tm_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Tempines\")\n\nplot(density(childcare_ck_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\n\nplot(density(childcare_jw_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"JUrong West\")\n\n\n\n\n\n\n\n\n\n\n\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow = c(2,2), mar = c(1, 1, 1, 1))\n\nplot(density(childcare_ck_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\n\nplot(density(childcare_jw_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\n\nplot(density(childcare_pg_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Punggol\")\n\nplot(density(childcare_tm_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n     main = \"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp, \n                correction = \"none\", \n                clipregion = \"sg_owin\", \n                alternative = \"clustered\", \n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe p-value is extremely small. There is sufficient evidence to reject the null hypothesis that the distribution of childcare services is random. We conclude that childcare services are distributed in a clustered point pattern.\n\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centres in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = \"ck_owin\",\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.88006, p-value = 0.07312\nalternative hypothesis: two-sided\n\n\nThe p-value is extremely large. There is insufficient evidence to reject the null hypothesis that the distribution of childcare services is random in Choa Chu Kang.\n\n\n\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction = \"none\",\n                clipregion = \"tm_owin\",\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.81377, p-value = 0.0007767\nalternative hypothesis: two-sided\n\n\nThe p-value is extremely small. There is sufficent evidence to reject the null hypothesis and conclude that the distribution of childcare services is not random in Tampines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 3",
    "section": "5.7 Analysing Spatial Point Process Using G-Function",
    "text": "5.7 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we learn how to compute G-function estimation by using Gest() of spatstat package. We will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.7.1 Choa Chu Kang planning area\n\n5.7.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\n\nplot(G_CK, xlim = c(0, 500))\n\n\n\n\n\n\n\n\n\n\n5.7.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\nSince the estimated G(r) lies between the upper and lower envelopes, there is insufficient evidence to reject the null hypothesis that the distribution of childcare services at Choa Chu Kang is random.\n\n\n\n5.7.2 Tampines planning area\n\n5.7.2.1 Computing G-function estimation\n\nG_tm &lt;- Gest(childcare_tm_ppp, correction = \"best\")\n\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n5.7.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\nThe estimated G(r) lies between the upper and lower envelopes for most distances except for a very small range. There is insufficient evidence to reject the null hypothesis that the distribution of childcare services at Tampines is random."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 3",
    "section": "5.8 Analysing Spatial Point Process Using F-Function",
    "text": "5.8 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, you will learn how to compute F-function estimation by using Fest() of spatstat package. You will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n5.8.1 Choa Chu Kang planning area\n\n5.8.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\n\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n\n5.8.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\nEstimated F(r) lies between the upper and lower envelopes . There is insufficient evidence to reject the null hypothesis. We conclude that the distribution of childcare services at Choa Chu Kang is random.\n\n\n5.8.3 Tampines planning area\n\n5.8.3.1 Computing F-function estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\n\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n5.8.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\nEstimated F(r) lies below the lower envelope for distances above 350m, suggesting that the distribution of childcare services at Tampines is clustered."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 3",
    "section": "5.9 Analysing Spatial Point Process Using K-Function",
    "text": "5.9 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.9.1 Choa Chu Kang planning area\n\n5.9.1.1 Computing K-function estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, ylab= \"K(r)\", xlab = \"r(m)\")\n\n\n\n\n\n\n\n\n\n\n5.9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 999, nrank = 1, global = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(K_ck.csr, xlab=\"r\", ylab=\"K(d)\")\n\n\n\n\n\n\n\n\nThe estimated K(r) lies between the upper and lower envelopes. There is insufficient evidence to reject the null hypothesis. We conclude that the distribution of childcare services at Choa Chu Kang is random.\n\n\n\n5.9.2 Tampines planning area\n\n5.9.2.1 Computing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\n\nplot(K_tm, ylab= \"K(r)\", xlab = \"r(m)\", xlim = c(0,1000))\n\n\n\n\n\n\n\n\n\n\n5.9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.{r}\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 999, nrank = 1, global = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10 [3:35 remaining] .........20 [3:43 remaining] ...\n......30 [3:22 remaining] .........40 [3:12 remaining] .........50 [3:03 remaining] ..\n.......60 [2:56 remaining] .........70 [2:56 remaining] .........80 [2:51 remaining] .\n........90 [2:48 remaining] .........100 [2:45 remaining] .........110\n [2:40 remaining] .........120 [2:37 remaining] .........130 [2:35 remaining] .........\n140 [2:32 remaining] .........150 [2:29 remaining] .........160 [2:26 remaining] ........\n.170 [2:24 remaining] .........180 [2:22 remaining] .........190 [2:21 remaining] .......\n..200 [2:20 remaining] .........210 [2:19 remaining] .........220 [2:17 remaining] ......\n...230 [2:15 remaining] .........240 [2:13 remaining] .........250 [2:11 remaining] .....\n....260 [2:09 remaining] .........270 [2:07 remaining] .........280 [2:06 remaining] ....\n.....290 [2:05 remaining] .........300 [2:03 remaining] .........310 [2:02 remaining] ...\n......320 [2:01 remaining] .........330 [1:59 remaining] .........340 [1:58 remaining] ..\n.......350 [1:57 remaining] .........360 [1:55 remaining] .........370 [1:54 remaining] .\n........380 [1:52 remaining] .........390 [1:51 remaining] .........400\n [1:49 remaining] .........410 [1:48 remaining] .........420 [1:47 remaining] .........\n430 [1:45 remaining] .........440 [1:44 remaining] .........450 [1:42 remaining] ........\n.460 [1:41 remaining] .........470 [1:39 remaining] .........480 [1:37 remaining] .......\n..490 [1:35 remaining] .........500 [1:33 remaining] .........510 [1:31 remaining] ......\n...520 [1:29 remaining] .........530 [1:27 remaining] .........540 [1:25 remaining] .....\n....550 [1:23 remaining] .........560 [1:21 remaining] .........570 [1:20 remaining] ....\n.....580 [1:18 remaining] .........590 [1:16 remaining] .........600 [1:14 remaining] ...\n......610 [1:13 remaining] .........620 [1:11 remaining] .........630 [1:09 remaining] ..\n.......640 [1:07 remaining] .........650 [1:06 remaining] .........660 [1:04 remaining] .\n........670 [1:02 remaining] .........680 [1:00 remaining] .........690\n [59 sec remaining] .........700 [57 sec remaining] .........710 [55 sec remaining] .........\n720 [53 sec remaining] .........730 [51 sec remaining] .........740 [49 sec remaining] ........\n.750 [47 sec remaining] .........760 [46 sec remaining] .........770 [44 sec remaining] .......\n..780 [42 sec remaining] .........790 [40 sec remaining] .........800 [38 sec remaining] ......\n...810 [36 sec remaining] .........820 [34 sec remaining] .........830 [32 sec remaining] .....\n....840 [30 sec remaining] .........850 [28 sec remaining] .........860 [26 sec remaining] ....\n.....870 [24 sec remaining] .........880 [23 sec remaining] .........890 [21 sec remaining] ...\n......900 [19 sec remaining] .........910 [17 sec remaining] .........920 [15 sec remaining] ..\n.......930 [13 sec remaining] .........940 [11 sec remaining] .........950 [9 sec remaining] .\n........960 [7 sec remaining] .........970 [5 sec remaining] .........980\n [4 sec remaining] .........990 [2 sec remaining] ........\n999.\n\nDone.\n\n\n\nplot(K_tm.csr, xlab = \"r\", ylab = \"K(r)\", xlim = c(0,500))\n\n\n\n\n\n\n\n\nThe estimated K(r) lies above the upper envelope. There is sufficient evidence to reject the null hypothesis and conclude that the distribution of childcare services at Tampines is non-random. Since the estimated K(r) lies above the upper envelope, there is a significant cluster pattern."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 3",
    "section": "5.10 Analysing Spatial Point Process Using L-Function",
    "text": "5.10 Analysing Spatial Point Process Using L-Function\nIn this section, you will learn how to compute L-function estimation by using Lest() of spatstat package. You will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n5.10.1 Choa Chu Kang planning area\n\n5.10.1.1 Computing modified L Function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\n\nplot(L_ck, .-r ~ r, ylab= \"L(r) - r\", xlab = \"r(m)\")\n\n\n\n\n\n\n\n\n\n\n5.10.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 999, rank = 1, global = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab = \"r\", ylab = \"L(r)-r\")\n\n\n\n\n\n\n\n\nThe estimated L(r) lies between the upper and lower envelopes. There is insufficient evidence to reject the null hypothesis. Again, we conclude that the distribution of childcare services at Choa Chu Kang is random.\n\n\n\n5.10.2 Tampines planning area\n\n5.10.2.1 Computing L-function estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\n\nplot(L_tm, . -r ~ r, ylab= \"L(r)-r\", xlab = \"r(m)\", xlim = c(0,1000))\n\n\n\n\n\n\n\n\n\n\n5.10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 999, nrank = 1, global = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10 [3:35 remaining] .........20 [3:13 remaining] ...\n......30 [3:20 remaining] .........40 [3:11 remaining] .........50 [3:06 remaining] ..\n.......60 [3:03 remaining] .........70 [2:58 remaining] .........80 [2:54 remaining] .\n........90 [2:51 remaining] .........100 [2:51 remaining] .........110\n [2:49 remaining] .........120 [2:48 remaining] .........130 [2:46 remaining] .........\n140 [2:44 remaining] .........150 [2:43 remaining] .........160 [2:41 remaining] ........\n.170 [2:39 remaining] .........180 [2:37 remaining] .........190 [2:35 remaining] .......\n..200 [2:34 remaining] .........210 [2:32 remaining] .........220 [2:32 remaining] ......\n...230 [2:30 remaining] .........240 [2:28 remaining] .........250 [2:27 remaining] .....\n....260 [2:25 remaining] .........270 [2:23 remaining] .........280 [2:21 remaining] ....\n.....290 [2:19 remaining] .........300 [2:17 remaining] .........310 [2:15 remaining] ...\n......320 [2:13 remaining] .........330 [2:11 remaining] .........340 [2:10 remaining] ..\n.......350 [2:08 remaining] .........360 [2:06 remaining] .........370 [2:03 remaining] .\n........380 [2:02 remaining] .........390 [2:00 remaining] .........400\n [1:58 remaining] .........410 [1:56 remaining] .........420 [1:53 remaining] .........\n430 [1:51 remaining] .........440 [1:49 remaining] .........450 [1:47 remaining] ........\n.460 [1:45 remaining] .........470 [1:43 remaining] .........480 [1:41 remaining] .......\n..490 [1:39 remaining] .........500 [1:38 remaining] .........510 [1:36 remaining] ......\n...520 [1:34 remaining] .........530 [1:32 remaining] .........540 [1:30 remaining] .....\n....550 [1:27 remaining] .........560 [1:25 remaining] .........570 [1:23 remaining] ....\n.....580 [1:21 remaining] .........590 [1:19 remaining] .........600 [1:17 remaining] ...\n......610 [1:15 remaining] .........620 [1:13 remaining] .........630 [1:11 remaining] ..\n.......640 [1:09 remaining] .........650 [1:07 remaining] .........660 [1:05 remaining] .\n........670 [1:03 remaining] .........680 [1:01 remaining] .........690\n [59 sec remaining] .........700 [57 sec remaining] .........710 [55 sec remaining] .........\n720 [54 sec remaining] .........730 [52 sec remaining] .........740 [50 sec remaining] ........\n.750 [48 sec remaining] .........760 [46 sec remaining] .........770 [44 sec remaining] .......\n..780 [42 sec remaining] .........790 [40 sec remaining] .........800 [38 sec remaining] ......\n...810 [37 sec remaining] .........820 [35 sec remaining] .........830 [33 sec remaining] .....\n....840 [31 sec remaining] .........850 [29 sec remaining] .........860 [27 sec remaining] ....\n.....870 [25 sec remaining] .........880 [23 sec remaining] .........890 [21 sec remaining] ...\n......900 [19 sec remaining] .........910 [17 sec remaining] .........920 [15 sec remaining] ..\n.......930 [13 sec remaining] .........940 [11 sec remaining] .........950 [9 sec remaining] .\n........960 [7 sec remaining] .........970 [5 sec remaining] .........980\n [4 sec remaining] .........990 [2 sec remaining] ........\n999.\n\nDone.\n\n\nThen, plot the model output by using the code chunk below.\n\nplot(L_tm.csr, . - r ~ r, xlab = \"r\", ylab = \"L(r)-r\", xlim = c(0,500))\n\n\n\n\n\n\n\n\nThe estimated L(r) lies above the upper envelope. There is sufficient evidence to reject the null hypothesis and conclude that the distribution of childcare services in Tampines is non-random. Since L(r) &gt;0, this indicates that the observed distribution is geographically concentrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics.\n\n\n\n\n\n\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development is evenly distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\n\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan_joined) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan_joined) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If we look at the documentation we will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If we do not specify this argument the default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan_joined, \n                queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons, thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style = \"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nWhat can we learn from the code chunk above?\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n\n\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan_joined$GDPPC, \n           listw = rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan_joined$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince the Moran I statistic is positive with p-value = 1.095e-06 &lt; 0.05, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm = moran.mc(hunan_joined$GDPPC, \n                listw = rswm_q, \n                nsim = 999, \n                zero.policy = TRUE, \n                na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nAgain, since the Moran I statistic is positive and the pseudo p-value of the test is 0.001, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 20, \n     xlab = \"Simulated Moran's I\")\n\nabline(v = 0, \n       col = \"red\") \n\n\n\n\n\n\n\n\nFrom the output above, we can conclude that the simulated Moran’s I values are extremely close to zero on average.\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n\nggplot(data = data.frame(bperm$res), aes(x = bperm.res)) +\n  geom_histogram() +\n  xlab(\"Simulated Moran's I\") +\n  ggtitle(\"Histogram of bperm$res\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan_joined$GDPPC, listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nAs the Geary C statistic = 0.6907223 &lt; 1, with p-value = 0.0001526 &lt; 0.05, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\n\nbperm=geary.mc(hunan_joined$GDPPC, \n               listw = rswm_q, \n               nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nAgain, since the Geary’s C statistic is small and the pseudo p-value of the test is 0.001, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 20, \n     xlab = \"Simulated Geary C\")\n\nabline(v = 1, col = \"red\") \n\n\n\n\n\n\n\n\nFrom the output above, we can conclude that the simulated Geary’s C values are extremely close to 1 on average.\n\n\n\n\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance. Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation is used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan_joined$GDPPC, \n                          order=6, \n                          method = \"I\", \n                          style = \"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan_joined$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs the distance between pairs of spatial observations increases, Moran’s I approaches 0 and autocorrelation decreases.\n\n\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan_joined$GDPPC, \n                          order = 6, \n                          method = \"C\", \n                          style = \"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan_joined$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAgain, we can see that as the distance between pairs of spatial observations increases, Geary’s C approaches 1 and autocorrelation decreases.\n\n\n\n\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan_joined$County)\nlocalMI &lt;- localmoran(hunan_joined$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below lists the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(localMI[fips,], row.names = hunan_joined$County[fips]), check.names = FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The output SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan_joined,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan_joined$GDPPC, rswm_q,\n                  labels = as.character(hunan_joined$County), \n                  xlab = \"GDPPC 2012\", \n                  ylab = \"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\n\nFirst we will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan_joined$GDPPC) %&gt;% \n  as.vector()\n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels = as.character(hunan_joined$County),\n                   xlab = \"z-GDPPC 2012\", \n                   ylab = \"Spatially Lagged z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode = \"numeric\",length = nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan_joined$lag_GDPPC &lt;- lag.listw(rswm_q, hunan_joined$GDPPC)\nDV &lt;- hunan_joined$lag_GDPPC - mean(hunan_joined$lag_GDPPC)     \n\nThis is followed by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV&lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV&gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV&lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV&gt;0 & LM_I&gt;0] &lt;- 4     \n\nLastly, places non-significant Moran in the category 0.\n\np_val &lt;- localMI[,5]\n\nquadrant[p_val&gt;signif] &lt;- 0\n\n\n\n\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nWe plot this map next to a choropleth map showing the distribution of GDPPC 2012.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\nFrom the LISA map above, we can observe a cluster of counties with high GDPPC in northeastern Hunan, as well as three neighbouring counties that are outliers with relatively low GDPPC. In addition, we observe a cluster of two counties with low GDPPC in central-western Hunan.\n\n\n\n\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object hunan_joined. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of hunan_joined and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\n\n\n\n\n\n\n\ngi.fixed &lt;- localG(hunan_joined$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan_joined$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan_joined sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan_joined, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan_joined data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nFrom the Gi map, we can observe a clear east-west divide in Gi values, with hotspot areas being concentrated in eastern Hunan and coldspot areas being concentrated in western Hunan.\n\n\n\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\ngi.adaptive &lt;- localG(hunan_joined$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan_joined, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\n\ngdppc&lt;- qtm(hunan_joined, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\nFrom the Gi map, we can observe a clear east-west divide in Gi values, with hotspot areas being concentrated in eastern Hunan and coldspot areas being concentrated in western Hunan."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development is evenly distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan_joined &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan_joined) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan_joined) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-1",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If we look at the documentation we will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If we do not specify this argument the default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan_joined, \n                queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons, thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style = \"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nWhat can we learn from the code chunk above?\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan_joined$GDPPC, \n           listw = rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan_joined$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince the Moran I statistic is positive with p-value = 1.095e-06 &lt; 0.05, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm = moran.mc(hunan_joined$GDPPC, \n                listw = rswm_q, \n                nsim = 999, \n                zero.policy = TRUE, \n                na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nAgain, since the Moran I statistic is positive and the pseudo p-value of the test is 0.001, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 20, \n     xlab = \"Simulated Moran's I\")\n\nabline(v = 0, \n       col = \"red\") \n\n\n\n\n\n\n\n\nFrom the output above, we can conclude that the simulated Moran’s I values are extremely close to zero on average.\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n\nggplot(data = data.frame(bperm$res), aes(x = bperm.res)) +\n  geom_histogram() +\n  xlab(\"Simulated Moran's I\") +\n  ggtitle(\"Histogram of bperm$res\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, we will learn how to perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan_joined$GDPPC, listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nAs the Geary C statistic = 0.6907223 &lt; 1, with p-value = 0.0001526 &lt; 0.05, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\n\nbperm=geary.mc(hunan_joined$GDPPC, \n               listw = rswm_q, \n               nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nAgain, since the Geary’s C statistic is small and the pseudo p-value of the test is 0.001, at alpha = 0.05, we reject the null hypothesis and conclude that similar values are clustered.\n\n\n\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 20, \n     xlab = \"Simulated Geary C\")\n\nabline(v = 1, col = \"red\") \n\n\n\n\n\n\n\n\nFrom the output above, we can conclude that the simulated Geary’s C values are extremely close to 1 on average."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Spatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance. Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation is used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan_joined$GDPPC, \n                          order=6, \n                          method = \"I\", \n                          style = \"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan_joined$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs the distance between pairs of spatial observations increases, Moran’s I approaches 0 and autocorrelation decreases.\n\n\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan_joined$GDPPC, \n                          order = 6, \n                          method = \"C\", \n                          style = \"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan_joined$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAgain, we can see that as the distance between pairs of spatial observations increases, Geary’s C approaches 1 and autocorrelation decreases."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-indicators-of-spatial-association-lisa",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-indicators-of-spatial-association-lisa",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan_joined$County)\nlocalMI &lt;- localmoran(hunan_joined$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below lists the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(localMI[fips,], row.names = hunan_joined$County[fips]), check.names = FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The output SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan_joined,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan_joined$GDPPC, rswm_q,\n                  labels = as.character(hunan_joined$County), \n                  xlab = \"GDPPC 2012\", \n                  ylab = \"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\n\nFirst we will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan_joined$GDPPC) %&gt;% \n  as.vector()\n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels = as.character(hunan_joined$County),\n                   xlab = \"z-GDPPC 2012\", \n                   ylab = \"Spatially Lagged z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode = \"numeric\",length = nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan_joined$lag_GDPPC &lt;- lag.listw(rswm_q, hunan_joined$GDPPC)\nDV &lt;- hunan_joined$lag_GDPPC - mean(hunan_joined$lag_GDPPC)     \n\nThis is followed by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV&lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV&gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV&lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV&gt;0 & LM_I&gt;0] &lt;- 4     \n\nLastly, places non-significant Moran in the category 0.\n\np_val &lt;- localMI[,5]\n\nquadrant[p_val&gt;signif] &lt;- 0\n\n\n\n\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nWe plot this map next to a choropleth map showing the distribution of GDPPC 2012.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette = \"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\nFrom the LISA map above, we can observe a cluster of counties with high GDPPC in northeastern Hunan, as well as three neighbouring counties that are outliers with relatively low GDPPC. In addition, we observe a cluster of two counties with low GDPPC in central-western Hunan."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object hunan_joined. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of hunan_joined and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "gi.fixed &lt;- localG(hunan_joined$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan_joined$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan_joined sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan_joined, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan_joined data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nFrom the Gi map, we can observe a clear east-west divide in Gi values, with hotspot areas being concentrated in eastern Hunan and coldspot areas being concentrated in western Hunan.\n\n\n\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\ngi.adaptive &lt;- localG(hunan_joined$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan_joined, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\n\ngdppc&lt;- qtm(hunan_joined, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\nFrom the Gi map, we can observe a clear east-west divide in Gi values, with hotspot areas being concentrated in eastern Hunan and coldspot areas being concentrated in western Hunan."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-On Exercise 8",
    "section": "",
    "text": "The R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nIn addition, we import shan_sf, shan_ict, shan_sf_cluster, and proxmat which we created last week in Hands-On Exercise 7.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\nshan_ict &lt;- read_rds(\"data/rds/shan_ict.rds\")\n\nshan_sf_cluster &lt;- read_rds(\"data/rds/shan_sf_cluster.rds\")\n\nproxmat &lt;- read_rds(\"data/rds/proxmat.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#spatially-constrained-clustering-skater-approach",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#spatially-constrained-clustering-skater-approach",
    "title": "Hands-On Exercise 8",
    "section": "12.8 Spatially Constrained Clustering: SKATER approach",
    "text": "12.8 Spatially Constrained Clustering: SKATER approach\nIn this section, we will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n12.8.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n12.8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\ncoords &lt;- st_coordinates(st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\n\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n12.8.3 Computing minimum spanning tree\n\n12.8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n12.8.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   11   42 238.67060\n[2,]   42   15 392.48568\n[3,]   15   40 204.54010\n[4,]   15   39 229.37894\n[5,]   39   19  79.41836\n[6,]   39   41 162.80878\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\n\n\n12.8.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 11 15 41 51 42 43 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 11 38 41 51 42 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the code chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 1 2 2 2 1 2 2 2 1 4 2 1 5 2 2 2 1 2 1 1 2 1 1 2 2 3 2 1\n[39] 1 1 1 1 1 4 2 3 1 2 2 2 1 2 1 2 2\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n18 22 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\n\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005,\n     add = TRUE)\n\n\n\n\n\n\n\n\n\n\n12.8.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\n\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\n\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Hands-On Exercise 8",
    "section": "12.9 Spatially Constrained Clustering: ClustGeo Method",
    "text": "12.9 Spatially Constrained Clustering: ClustGeo Method\nIn this section, we will gain hands-on experience on using functions provided by ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n12.9.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha().\n\n\n12.9.2 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n12.9.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n12.9.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.2 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visual-interpretation-of-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visual-interpretation-of-clusters",
    "title": "Hands-On Exercise 8",
    "section": "12.10 Visual Interpretation of Clusters",
    "text": "12.10 Visual Interpretation of Clusters\n\n12.10.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n12.10.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package is used to create this.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex02/data/MPSZ-2019.html",
    "title": "IS415-Geospatial",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "pacman::p_load(sf, spatstat, raster, tmap, tidyverse)\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nmaptools is retired and binary is removed from CRAN. However, we can download it from Posit Public Package Manager using the code chunk below.\n\n# Avoid maptools being repetitively installed every time the Quarto document is rendered\n\n#install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\n\nst_combine() returns a single, combined geometry with no resolved boundaries; returned geometries may well be invalid\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all unioned pairs of x[i] and y[j]\nst_union() is used to derive the coastal outline sf tibble data.frame, sg_sf.\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nplot(sg_sf)\n\n\n\n\n\n\n\nsg_sf_combine &lt;- mpsz_sf %&gt;%\n  st_combine()\n\nplot(sg_sf_combine)\n\n\n\n\n\n\n\n\n\n\n\nThe as.SpatialGridDataFrame.im() function can only be used if maptools is installed\n\n# gridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\n\n# spplot(gridded_kde_childcareSG_ad)\n\nAlternatively, we can use the as() function.\n\n# gridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive, \"SpatialGridDataFrame\")\n\n\n\n\nImport ACLED data.\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\nacled_sf\n\nSimple feature collection with 55574 features and 29 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -207135 ymin: 1103500 xmax: 640934.5 ymax: 3067910\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 55,574 × 30\n   event_id_cnty event_date  year time_precision disorder_type        event_type\n * &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;     \n 1 MMR56099      2023-12-31  2023              1 Political violence   Explosion…\n 2 MMR56222      2023-12-31  2023              1 Political violence   Explosion…\n 3 MMR56370      2023-12-31  2023              1 Political violence   Battles   \n 4 MMR56376      2023-12-31  2023              1 Demonstrations       Protests  \n 5 MMR56380      2023-12-31  2023              1 Strategic developme… Strategic…\n 6 MMR56869      2023-12-31  2023              1 Strategic developme… Strategic…\n 7 MMR56871      2023-12-31  2023              1 Political violence   Battles   \n 8 MMR56873      2023-12-31  2023              1 Political violence   Explosion…\n 9 MMR56874      2023-12-31  2023              1 Political violence   Battles   \n10 MMR56876      2023-12-31  2023              1 Political violence   Violence …\n# ℹ 55,564 more rows\n# ℹ 24 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   geo_precision &lt;dbl&gt;, source &lt;chr&gt;, source_scale &lt;chr&gt;, notes &lt;chr&gt;,\n#   fatalities &lt;dbl&gt;, tags &lt;chr&gt;, timestamp &lt;dbl&gt;, geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#issue-1-installing-mapstools",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#issue-1-installing-mapstools",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "maptools is retired and binary is removed from CRAN. However, we can download it from Posit Public Package Manager using the code chunk below.\n\n# Avoid maptools being repetitively installed every time the Quarto document is rendered\n\n#install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#issue-2-creating-coastal-outline",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#issue-2-creating-coastal-outline",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "st_combine() returns a single, combined geometry with no resolved boundaries; returned geometries may well be invalid\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all unioned pairs of x[i] and y[j]\nst_union() is used to derive the coastal outline sf tibble data.frame, sg_sf.\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nplot(sg_sf)\n\n\n\n\n\n\n\nsg_sf_combine &lt;- mpsz_sf %&gt;%\n  st_combine()\n\nplot(sg_sf_combine)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#issue-3-as.spatialgriddataframe.im",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#issue-3-as.spatialgriddataframe.im",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "The as.SpatialGridDataFrame.im() function can only be used if maptools is installed\n\n# gridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\n\n# spplot(gridded_kde_childcareSG_ad)\n\nAlternatively, we can use the as() function.\n\n# gridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive, \"SpatialGridDataFrame\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#geospatial-analytics-for-social-good-myanmar-armed-conflict-case-study",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#geospatial-analytics-for-social-good-myanmar-armed-conflict-case-study",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Import ACLED data.\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\nacled_sf\n\nSimple feature collection with 55574 features and 29 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -207135 ymin: 1103500 xmax: 640934.5 ymax: 3067910\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 55,574 × 30\n   event_id_cnty event_date  year time_precision disorder_type        event_type\n * &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;     \n 1 MMR56099      2023-12-31  2023              1 Political violence   Explosion…\n 2 MMR56222      2023-12-31  2023              1 Political violence   Explosion…\n 3 MMR56370      2023-12-31  2023              1 Political violence   Battles   \n 4 MMR56376      2023-12-31  2023              1 Demonstrations       Protests  \n 5 MMR56380      2023-12-31  2023              1 Strategic developme… Strategic…\n 6 MMR56869      2023-12-31  2023              1 Strategic developme… Strategic…\n 7 MMR56871      2023-12-31  2023              1 Political violence   Battles   \n 8 MMR56873      2023-12-31  2023              1 Political violence   Explosion…\n 9 MMR56874      2023-12-31  2023              1 Political violence   Battles   \n10 MMR56876      2023-12-31  2023              1 Political violence   Violence …\n# ℹ 55,564 more rows\n# ℹ 24 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   geo_precision &lt;dbl&gt;, source &lt;chr&gt;, source_scale &lt;chr&gt;, notes &lt;chr&gt;,\n#   fatalities &lt;dbl&gt;, tags &lt;chr&gt;, timestamp &lt;dbl&gt;, geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "Load the required packages.\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)\n\n\n\n\n\n\n\nkbb_sf &lt;- st_read(dsn = \"data/rawdata\", \n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n# POLYGON Z: defined in 3 dimensions (includes height)\n\n\n\n\nConvert kbb_sf into an owin object.\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nConfirm that the output is indeed an owin object.\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\n\n\n\nNext, we import the forest fire data set.\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\")  %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nclass(fire_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nBecause ppp object only accepts numerical or character, the code chunk below is used to convert data from acq_date to numeric.\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date, label = TRUE, abbr = FALSE))\n\nWe prepare a map of the fire points.\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nWe prepare a point symbol map with monthly geographic distribution of forest fires in 2023.\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by = \"Month_fac\", free.coords = FALSE, drop.units = TRUE)\n\n\n\n\n\n\n\n# free.coords = FALSE ensures constant zoom level/map extent\n\n\n\n\nRemove unwanted fields from fire_sf as as.ppp() only requires the mark field and geometry field from the input.\n\nfire_month &lt;- fire_sf %&gt;%\n  dplyr::select(Month_num)\n\n\nfire_month_ppp &lt;- as.ppp(fire_month)\n\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nWe will check if there are duplicated point events using the code below.\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\nCombine the ppp and owin objects.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\n\n\n\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\n\n\n\ntims &lt;- c(7,8,9,10,11,12)\n  \npar(mfcol = c(2,3))\n\nfor (i in tims) {\n  plot(st_kde, i,\n       override.par = FALSE,\n       fix.range = TRUE,\n       main = paste(\"KDE at month\", i))\n  \n}\n\n\n\n\n\n\n\n\n\n\n\nWe can analyse this continuously instead.\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin\n)\n\nsummary(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#setup",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#setup",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "Load the required packages.\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-and-preparing-study-area",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-and-preparing-study-area",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "kbb_sf &lt;- st_read(dsn = \"data/rawdata\", \n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n# POLYGON Z: defined in 3 dimensions (includes height)\n\n\n\n\nConvert kbb_sf into an owin object.\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nConfirm that the output is indeed an owin object.\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-and-preparing-forest-fire-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-and-preparing-forest-fire-data",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "Next, we import the forest fire data set.\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\")  %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nclass(fire_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nBecause ppp object only accepts numerical or character, the code chunk below is used to convert data from acq_date to numeric.\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date, label = TRUE, abbr = FALSE))\n\nWe prepare a map of the fire points.\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nWe prepare a point symbol map with monthly geographic distribution of forest fires in 2023.\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by = \"Month_fac\", free.coords = FALSE, drop.units = TRUE)\n\n\n\n\n\n\n\n# free.coords = FALSE ensures constant zoom level/map extent"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#computing-skde-by-month",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#computing-skde-by-month",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "Remove unwanted fields from fire_sf as as.ppp() only requires the mark field and geometry field from the input.\n\nfire_month &lt;- fire_sf %&gt;%\n  dplyr::select(Month_num)\n\n\nfire_month_ppp &lt;- as.ppp(fire_month)\n\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nWe will check if there are duplicated point events using the code below.\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\nCombine the ppp and owin objects.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\n\n\n\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\n\n\n\ntims &lt;- c(7,8,9,10,11,12)\n  \npar(mfcol = c(2,3))\n\nfor (i in tims) {\n  plot(st_kde, i,\n       override.par = FALSE,\n       fix.range = TRUE,\n       main = paste(\"KDE at month\", i))\n  \n}\n\n\n\n\n\n\n\n\n\n\n\nWe can analyse this continuously instead.\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin\n)\n\nsummary(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-Class Exercise 6",
    "section": "",
    "text": "sfdep package: sf and tidyverse friendly interface to spdep package (allows us to use tibble format); utilises list columns to make this interface possible\n\n\n\nWe load sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse)\n\nImport the necessary datasets.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n# Should be finding out projections\n\nCombine the data frames.\n\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\nStep 1: Deriving Queen’s Contiguity Weights\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n\n#.before = 1 inserts the two new columns to the left of the existing columns\n\nst_contiguity() builds contiguity matrix\nst_weights() builds weight matrix based on nb\n\nnb: neighbour list object as created by st_neighbors\nstyle: default “W” for row-standardised weights (sums over all links to n)\nallow_zero: if TRUE, assigns zero as lagged value to zone without neighbours\n\nComputing Global Moran’s I\n\nmoranI &lt;- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nPerforming Global Moran’s I Test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistic.\n\nglobal_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nAt alpha = 0.05, there is sufficient evidence to reject the null hypothesis of a random distribution. Since the Moran I statistic is positive but small, we infer that there is relatively weak clustering.\nPerforming Global Moran’s Permutation Test\nIn practice, Monte Carlo simulation should be used to perform the statistical test. We can skip the previous step and proceed to this immediately. We must use set.seed() before simulation to ensure that the computation is reproducible.\n\nset.seed(1234)\n\nglobal_moran_perm(wm_q$GDPPC, wm_q$nb, wm_q$wt, nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nAt alpha = 0.05, there is sufficient evidence to reject the null hypothesis of a random distribution. Since the Moran I statistic is positive but small, we infer that there is relatively weak clustering.\nComputing local Moran’s I\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nImportant output fields:\n\nii: local Moran’s I\n3 different p-values based on 3 different methods (p_ii is base method, p_ii_sim is using simulation (without replacement), p_folded_sim based on simulation with different algorithm (with replacement)) - choose any of these, but be consistent\nmean, median, pysal: 3 different methods to label hotspots and coldspots - use median if data is highly skewed\n\nVisualising local Moran’s I\n\ntmap_mode(\"plot\")\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of GDPPC\", main.title.size = 1)\n\nVisualising p-value of local Moran’s I\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii_sim\", breaks = c(0, 0.001, 0.01, 0.05, 1), labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"P-values of Local Moran's I of GDPPC\", main.title.size = 1)\n  \ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05, and not significant instead of using the default.\nLISA Map\nLISA map is a categorical map showing outliers and clusters.\n\nTwo types of outliers: High-Low (High surrounded by Low) and Low-High (Low surrounded by High)\nTwo types of clusters: High-High and Low-Low\n\nLISA map is an interpreted map combining local Moran’s I of geographical areas and respective p-values\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi*\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         .before = 1)\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods should be used to derive the spatial weight matrix.\nNext, we compute the local Gi*\n\nHCSA &lt;- wm_idw %&gt;%\n  mutate(local_Gi = local_gstar_perm(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\nVisualising Gi*\n\ntmap_mode(\"plot\")\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Gi*\")\n\n\n\n\n\n\n\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in a spatially weighted attribute.\n\nHCSA_sig &lt;- HCSA %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA) +\n  tm_polygons +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA\")\n\n\n\n\n\n\n\n\nFigure above reveals there is one hot spot area and two cold spot areas. The hot spot areas coincide with the High-High cluster identified using local Moran’s I."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#in-class-exercise-6-global-and-local-measures-of-spatial-autocorrelation",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#in-class-exercise-6-global-and-local-measures-of-spatial-autocorrelation",
    "title": "In-Class Exercise 6",
    "section": "",
    "text": "sfdep package: sf and tidyverse friendly interface to spdep package (allows us to use tibble format); utilises list columns to make this interface possible\n\n\n\nWe load sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse)\n\nImport the necessary datasets.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n# Should be finding out projections\n\nCombine the data frames.\n\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\nStep 1: Deriving Queen’s Contiguity Weights\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n\n#.before = 1 inserts the two new columns to the left of the existing columns\n\nst_contiguity() builds contiguity matrix\nst_weights() builds weight matrix based on nb\n\nnb: neighbour list object as created by st_neighbors\nstyle: default “W” for row-standardised weights (sums over all links to n)\nallow_zero: if TRUE, assigns zero as lagged value to zone without neighbours\n\nComputing Global Moran’s I\n\nmoranI &lt;- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nPerforming Global Moran’s I Test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistic.\n\nglobal_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nAt alpha = 0.05, there is sufficient evidence to reject the null hypothesis of a random distribution. Since the Moran I statistic is positive but small, we infer that there is relatively weak clustering.\nPerforming Global Moran’s Permutation Test\nIn practice, Monte Carlo simulation should be used to perform the statistical test. We can skip the previous step and proceed to this immediately. We must use set.seed() before simulation to ensure that the computation is reproducible.\n\nset.seed(1234)\n\nglobal_moran_perm(wm_q$GDPPC, wm_q$nb, wm_q$wt, nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nAt alpha = 0.05, there is sufficient evidence to reject the null hypothesis of a random distribution. Since the Moran I statistic is positive but small, we infer that there is relatively weak clustering.\nComputing local Moran’s I\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nImportant output fields:\n\nii: local Moran’s I\n3 different p-values based on 3 different methods (p_ii is base method, p_ii_sim is using simulation (without replacement), p_folded_sim based on simulation with different algorithm (with replacement)) - choose any of these, but be consistent\nmean, median, pysal: 3 different methods to label hotspots and coldspots - use median if data is highly skewed\n\nVisualising local Moran’s I\n\ntmap_mode(\"plot\")\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of GDPPC\", main.title.size = 1)\n\nVisualising p-value of local Moran’s I\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii_sim\", breaks = c(0, 0.001, 0.01, 0.05, 1), labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"P-values of Local Moran's I of GDPPC\", main.title.size = 1)\n  \ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05, and not significant instead of using the default.\nLISA Map\nLISA map is a categorical map showing outliers and clusters.\n\nTwo types of outliers: High-Low (High surrounded by Low) and Low-High (Low surrounded by High)\nTwo types of clusters: High-High and Low-Low\n\nLISA map is an interpreted map combining local Moran’s I of geographical areas and respective p-values\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi*\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         .before = 1)\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods should be used to derive the spatial weight matrix.\nNext, we compute the local Gi*\n\nHCSA &lt;- wm_idw %&gt;%\n  mutate(local_Gi = local_gstar_perm(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\nVisualising Gi*\n\ntmap_mode(\"plot\")\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Gi*\")\n\n\n\n\n\n\n\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in a spatially weighted attribute.\n\nHCSA_sig &lt;- HCSA %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA) +\n  tm_polygons +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA\")\n\n\n\n\n\n\n\n\nFigure above reveals there is one hot spot area and two cold spot areas. The hot spot areas coincide with the High-High cluster identified using local Moran’s I."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-Class Exercise 9",
    "section": "",
    "text": "pacman::p_load(spdep, sp, tmap, sf, ClustGeo, cluster, factoextra, NbClust, tidyverse, GGally)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#spatially-constrained-clustering",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#spatially-constrained-clustering",
    "title": "In-Class Exercise 9",
    "section": "Spatially Constrained Clustering",
    "text": "Spatially Constrained Clustering"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#skater-method-hard-classification",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#skater-method-hard-classification",
    "title": "In-Class Exercise 9",
    "section": "SKATER method (hard classification)",
    "text": "SKATER method (hard classification)\n\nStep 1: Computing nearest neighbours\n\nshan.nb &lt;- poly2nb(shan_sf)\n\n# Notice that we can use shan_sf directly in poly2nb() without converting it into an sp object first. Latest version of spdep package allows most functions to accept sf objects directly.\n\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\n\nStep 2: Visualising the neighbours\n\nplot(st_geometry(shan_sf),\n     border = grey(.5))\n\npts &lt;- st_coordinates(st_centroid(shan_sf))\n\nplot(shan.nb, pts, col = \"blue\", add = TRUE)\n\n\n\n\n\n\n\n\n\n\nStep 3: Computing minimum spanning tree\n\n# Calculating edge costs\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n# Incorporating these costs into a weights object (style must be B)\n\nshan.w &lt;- nb2listw(shan.nb, lcosts, style = \"B\")\n\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n# Computing MST\n\nshan.mst &lt;- mstree(shan.w)\n\n# Visualising MST\n\nplot(st_geometry(shan_sf), border = gray(.5))\n\nplot.mst(shan.mst, pts, col = \"blue\", cex.lab = 0.7, cex.circles = 0.005, add = TRUE)\n\n\n\n\n\n\n\n\n\n\nComputing spatially constrained clusters\n\nskater.clust6 &lt;- skater(edges = shan.mst[, 1:2],\n                        data = shan_ict,\n                        method = \"euclidean\",\n                        ncuts = 5)\n\n\n# Plot skater tree\n\nplot(st_geometry(shan_sf),\n     border = gray(.5))\n\nplot(skater.clust6,\n     pts,\n     cex.lab = .7,\n     groups.colors = c(\"red\", \"green\", \"blue\", \"brown\", \"pink\"),\n     cex.circles = 0.005,\n     add = TRUE)\n\n\n\n\n\n\n\n\n\n\nVisualising the clusters in choropleth map\n\ngroups_mat &lt;- as.matrix(skater.clust6$groups)\n\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`skater_CLUSTER` = `as.factor.groups_mat.`)\n\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n\n\n\n\n\n\n\n# use as.factor to ensure that clusters are arranged on an ordinal scale OR alphabetically"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#clustgeo-method-soft-classification",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#clustgeo-method-soft-classification",
    "title": "In-Class Exercise 9",
    "section": "ClustGeo method (soft classification)",
    "text": "ClustGeo method (soft classification)\nSoft classification: allows user to decide relative importance of attribute/spatial distance (D0/D1). By default, uses cut-off value where D0 and D1 are closest.\nIf user wants to emphasise spatial distance, choose cut-off value where D1is higher.\nIf user wants to emphasise attribute distance, choose cut-off value where D0 is higher.\nComputing spatial distance matrix\nUse st_distance() of sf to compute the distance matrix\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nCreate cluster graphs\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K = 6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Use first graph (not the standardised one)\n\nSaving clustGeo output\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n# value of alpha is cut-off point based on cluster graph above\n\n\ngroups &lt;- as.factor(cutree(clustG, k = 6))\n\nshan_sf_clustGeo &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`clustGeo` = `as.matrix.groups.`)\n\n\nVisualising the clusters in choropleth map\n\nqtm(shan_sf_clustGeo, \"clustGeo\")\n\n\n\n\n\n\n\n\n\n\nCharacterising the clusters\n\nggparcoord(data = shan_sf_clustGeo,\n           columns = c(17:21),\n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE,\n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ clustGeo) +\n  theme(axis.text.x = element_text(angle = 30, size = 4))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#comparing-cluster-maps",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#comparing-cluster-maps",
    "title": "In-Class Exercise 9",
    "section": "Comparing cluster maps",
    "text": "Comparing cluster maps\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n\n\n\n\n\n\n\nqtm(shan_sf_clustGeo, \"clustGeo\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11/In-class_Ex11.html",
    "href": "In-class_Ex/In-class_Ex11/In-class_Ex11.html",
    "title": "In-Class Exercise 11",
    "section": "",
    "text": "Loading the R package\n\npacman::p_load(tidyverse, sf, tmap, httr, performance)\n\n\n\nImporting data\nThe code chunk below imports multiple csv files in a specified folder and appends them into a single tibble data frame.\n\nfolder_path &lt;- \"data/aspatial\"\n\nfile_list &lt;- list.files(path = folder_path,\n                        pattern = \"^realis.*\\\\.csv$\",\n                        full.names = TRUE)\n\nrealis_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\n\n\nWrangling data\n\ncondo_resale &lt;- realis_data %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %&gt;%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")\n\n\n\nGeocoding\n\npostcode &lt;- unique(condo_resale$`Postal Code`)\n\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\n\nfound &lt;- data.frame()\n\nnot_found &lt;- data.frame()\n\nfor (postcode in postcode) {\n  \n  query &lt;- list('searchVal' = postcode, 'returnGeom' = 'Y',\n                'getAddrDetails' = 'Y', 'pageNum' = '1')\n\n  res &lt;- GET(url, query = query)\n  \n  if (content(res)$found != 0) {\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  }\n  else {not_found = data.frame(postcode)}\n}\n\n\n\nTidying field names\n\nfound &lt;- found %&gt;%\n  select(c(6:8)) %&gt;%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)\n\n\n\nJoining tables\n\ncondo_resale_geocoded = left_join(\n  condo_resale, found,\n  by = c('Postal Code' = 'POSTAL'))\n\n\n\nConverting to sf\n\ncondo_resale_sf &lt;- st_as_sf(condo_resale_geocoded,\n                            coords = c(\"XCOORD\", \"YCOORD\"),\n                            crs = 3414)\n\n\n\nCleaning Spatial Data\n\n# Checking for ovrlapping point features\n\noverlapping_points &lt;- condo_resale_sf %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\noverlapping_points\n\nSimple feature collection with 5991 features and 22 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14973.78 ymin: 24730.35 xmax: 43287.74 ymax: 48670.84\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 5,991 × 23\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n * &lt;chr&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 CASA ROSA                          1500000         1367.                 1097\n 2 THE MINTON                         1840000         1216.                 1513\n 3 NV RESIDENCES                      1350000         1109.                 1218\n 4 SANT RITZ                           890000          527.                 1687\n 5 ECO                                1620000          990.                 1636\n 6 MARINA BAY RESIDEN…                1420000          710.                 1999\n 7 THE GARDENS AT BIS…                1800000         1206.                 1493\n 8 THOMSON 800                        2800000         1625.                 1723\n 9 SELETAR PARK RESID…                1490000         1507.                  989\n10 THE ESTUARY                        1540000         1195.                 1289\n# ℹ 5,981 more rows\n# ℹ 19 more variables: `Sale Date` &lt;date&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;, geometry &lt;POINT [m]&gt;, …\n\n\nIn the code chunk below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  st_jitter(amount = 2)\n\n\n\nRevisiting Take-Home Exercise 2\nTo avoid centroids being affected by outlying islands, we must do the following\nSplit the multipolygons into individual polygons using st_cast()\n\nsf_polygon &lt;- prov_sf %&gt;%\n  st_cast(\"POLYGON\") %&gt;%\n  mutate(area = st_area(.))\n\n\nGroup provinces by their unique name\nSelect the largest polygon by area\n\n\nprov_cleaned &lt;- sf_polygon %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  filter(area == max(area)) %&gt;%\n  ungroup() %&gt;%\n  select(-area) %&gt;%\n  select(ADM1_EN)\n\n\nEnsure that ADM1_EN values are consistent between the two tables that you want to join\n\n\ndrug_cleaned &lt;- drug %&gt;%\n  mutate(AMD1_EN = case_when(\n    ADM1_EN == \"buogkan\" ~ \"Bueng Kan\",\n    ADM1_EN == \"Loburi\" ~ \"Lop Buri\",\n    TRUE ~ ADM1_EN\n  ))"
  },
  {
    "objectID": "Project/proposal.html#exploratory-data-analysis",
    "href": "Project/proposal.html#exploratory-data-analysis",
    "title": "Proposal",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\n\nUsers will be able to view an interactive point map of armed conflict events in the Indonesian provinces of Southwest Papua, West Papua, Central Papua, Papua, Highland Papua and South Papua, occurring from January 2015 to June 2024. The map will allow users to overlay administrative (province; regency and city) boundaries and to filter event points by:\n\nStudy areas (regencies and cities)\nEvent type\nActors involved\nNumber of reported fatalities\nTime period (start date and end date)\n\nUsers will also be able to view an interactive graph of the aggregate number of armed conflict events over time. They will be also be able to view the time series data for their chosen:\n\nStudy areas (regencies and cities)\nEvent type\nActors involved\nNumber of reported fatalities\nTime period (start date and end date)"
  },
  {
    "objectID": "Project/proposal.html#spatial-point-patterns-analysis-1st-and-2nd-order",
    "href": "Project/proposal.html#spatial-point-patterns-analysis-1st-and-2nd-order",
    "title": "Proposal",
    "section": "3.2 Spatial Point Patterns Analysis: 1st and 2nd Order",
    "text": "3.2 Spatial Point Patterns Analysis: 1st and 2nd Order\n\nUsers will be able to derive kernel density estimation (KDE) layers for visualising the spatial intensity of armed conflict point events over a chosen study area, during a time period stipulated by them.\nThey will also be able to choose a:\n\nBandwidth selection method (bw.diggle, bw.CvL, bw.scott, bw.ppl, or adaptive bandwidth)\nSmoothing kernel method (Gaussian, Epanechnikov, Quartic, or Disc)\n\nUsers will also be able to perform 2nd order spatial point patterns analysis on the armed conflict point events occurring within the chosen study area and time period, and conduct a Monte Carlo test of complete spatial randomness on the point process, using any of the following functions:\n\nG-function\nF-function\nK-function\nL-function\nThey will also be able to specify the edge correction to be applied and the number of simulations to be generated in the Monte Carlo test."
  },
  {
    "objectID": "Project/proposal.html#spatio-point-patterns-analysis-1st-and-2nd-order",
    "href": "Project/proposal.html#spatio-point-patterns-analysis-1st-and-2nd-order",
    "title": "Proposal",
    "section": "3.3 Spatio Point Patterns Analysis: 1st and 2nd Order",
    "text": "3.3 Spatio Point Patterns Analysis: 1st and 2nd Order\n\nUsers will be able to derive quarterly or monthly spatiotemporal kernel density estimation (STKDE) layers for armed conflict point events in their chosen study area, which will be displayed in a single animation.\nUsers will be able to compute and visualise the space-time inhomogeneous K-function for their chosen study area, which will allow them to assess the spatiotemporal aggregation or regularity of the point process."
  },
  {
    "objectID": "Project/proposal.html#exploratory-data-analysis-page",
    "href": "Project/proposal.html#exploratory-data-analysis-page",
    "title": "Proposal",
    "section": "Exploratory Data Analysis Page",
    "text": "Exploratory Data Analysis Page"
  },
  {
    "objectID": "Project/proposal.html#spatial-point-patterns-analysis-page",
    "href": "Project/proposal.html#spatial-point-patterns-analysis-page",
    "title": "Proposal",
    "section": "Spatial Point Patterns Analysis Page",
    "text": "Spatial Point Patterns Analysis Page"
  },
  {
    "objectID": "Project/proposal.html#spatiotemporal-point-patterns-analysis-page",
    "href": "Project/proposal.html#spatiotemporal-point-patterns-analysis-page",
    "title": "Proposal",
    "section": "Spatiotemporal Point Patterns Analysis Page",
    "text": "Spatiotemporal Point Patterns Analysis Page"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Drug abuse is associated with significant negative health, financial and social consequences. Yet, illicit drug consumption remains highly prevalent and continues to be a growing problem worldwide. In 2021, 1 in 17 people aged 15–64 in the world had used a drug in the past 12 months. Notwithstanding population growth, the estimated number of drug users grew from 240 million in 2011 to 296 million in 2021.\nIn Thailand, drug abuse is a major social issue. There are about 2.7 million youths using drugs in Thailand. Among youths aged between 15 and 19 years, there are about 300,000 who have needs for drug treatment. Most of Thai youths involved with drugs are vocational-school students, which nearly doubles in number compared to secondary-school students.\n\n\n\nWe are interested to discover:\n\nif the key indicators of drug abuse of Thailand are independent from space.\nIf the indicators of drug abuse is indeed spatially dependent, then, we would like to detect where are the clusters and outliers, and the hotspots.\nLast but not least, we are also interested to investigate how the observations above evolve over time.\n\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\na study area layer in sf polygon features. It must be at province level (including Bangkok) of Thailand.\na drug abuse indicators layer within the study area in sf polygon features.\n\nUsing the extracted data, perform global spatial autocorrelation analysis by using sfdep methods.\nUsing the extracted data, perform local spatial autocorrelation analysis by using sfdep methods.\nDescribe the spatial patterns revealed by the analysis above.\n\n\n\n\nThe following two data sets will be used:\n\nthai_drug_offenses_2017_2022.csv This dataset presents statistics related to different types of drug offenses in Thailand, categorized by fiscal year, and provides insights into the prevalence of various drug-related cases and their distribution across different provinces. It was downloaded from https://www.kaggle.com/datasets/thaweewatboy/thailand-drug-offenses-2017-2022.\ntha_admbnda_adm1_rtsd_20220121 This dataset provides information on Thailand province boundaries in shapefile format. It was downloaded from the Humanitarian Data Exchange, a service provided by the United Nations Office for the Coordination of Humanitarian Affairs (OCHA).\n\n\n\n\nFor this exercise, the following R packages are used:\n\ntidyverse, a collection of R packages designed for data science, and which provides functions to import, transform, and visualise the data.\nsf, to import, manage and process vector-based geospatial data in R.\nsfdep, which creates an sf and tidyverse friendly interface to the spdep package that is used to compute spatial weights, global and local spatial autocorrelation statistics\ntmap, which provides functions for plotting cartographic quality choropleth maps.\nKendall, which computes the Kendall rank correlation and Mann-Kendall trend test. This will be necessary for us to perform emerging hot spot analysis.\n\n\npacman::p_load(tidyverse, sf, sfdep, tmap, Kendall)\n\n\n\n\n\n\nImport tha_admbnda_adm1_rtsd_20220121 as a simple features object, which we name thailand. This is the required study area layer in sf polygon feature format.\n\n#|eval: FALSE\n\nthailand &lt;- st_read(dsn = \"data/geospatial\", layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nthailand has a total of 77 features, and is projected in WGS 84.\nWe save thailand with the write_rds() function.\n\nwrite_rds(thailand, \"data/rds/thailand.rds\")\n\nVerify that all the geometries in thailand are valid.\n\nlength(which(st_is_valid(thailand) == TRUE))\n\n[1] 77\n\n\nSometimes, when importing geospatial data into R, the coordinate system of the source data is wrongly assigned during the importing process. Check the CRS of thailand.\n\nst_crs(thailand)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThe EPSG code indicated is 4326, which is correct since the data is projected in WGS 84.\n\n\n\nSince thai_drug_offenses_2017_2022.csv is in csv format, we used read_csv() of the readr package (part of the tidyverse) to import it.\n\ndrugs &lt;- read_csv(\"data/aspatial/thai_drug_offenses_2017_2022.csv\")\n\nglimpse(drugs)\n\nRows: 7,392\nColumns: 5\n$ fiscal_year            &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,…\n$ types_of_drug_offenses &lt;chr&gt; \"drug_use_cases\", \"drug_use_cases\", \"drug_use_c…\n$ no_cases               &lt;dbl&gt; 11871, 200, 553, 450, 378, 727, 820, 69, 127, 2…\n$ province_th            &lt;chr&gt; \"กรุงเทพมหานคร\", \"ชัยนาท\", \"นนทบุรี\", \"ปทุมธานี\", \"พร…\n$ province_en            &lt;chr&gt; \"Bangkok\", \"Chai Nat\", \"Nonthaburi\", \"Pathum Th…\n\n\nThe data on the number of drug-related cases in drugs is categorized by fiscal year, type of drug offense, and province. We derive the total number of drug-related cases in each province, in each fiscal year, using group_by() and summarize() of dplyr (part of the tidyverse).\n\ndrugs_all &lt;- drugs %&gt;% \n  group_by(fiscal_year, province_en, province_th) %&gt;%\n  summarize(cases = sum(no_cases))\n\nglimpse(drugs_all)\n\nRows: 462\nColumns: 4\nGroups: fiscal_year, province_en [462]\n$ fiscal_year &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017…\n$ province_en &lt;chr&gt; \"Amnat Charoen\", \"Ang Thong\", \"Bangkok\", \"Buri Ram\", \"Chac…\n$ province_th &lt;chr&gt; \"อำนาจเจริญ\", \"อ่างทอง\", \"กรุงเทพมหานคร\", \"บุรีรัมย์\", \"ฉะเชิงเทรา…\n$ cases       &lt;dbl&gt; 5076, 1614, 60067, 5061, 9318, 1536, 6435, 4021, 15620, 88…\n\n\nNext, we use pivot_wider() of dplyr so that each row contains the data for a single province, and each column contains the data for a single fiscal year.\n\ndrugs_all1 &lt;- drugs_all %&gt;%\n  pivot_wider(names_from = \"fiscal_year\", values_from = \"cases\")\n\nglimpse(drugs_all1)\n\nRows: 77\nColumns: 8\nGroups: province_en [77]\n$ province_en &lt;chr&gt; \"Amnat Charoen\", \"Ang Thong\", \"Bangkok\", \"Buri Ram\", \"Chac…\n$ province_th &lt;chr&gt; \"อำนาจเจริญ\", \"อ่างทอง\", \"กรุงเทพมหานคร\", \"บุรีรัมย์\", \"ฉะเชิงเทรา…\n$ `2017`      &lt;dbl&gt; 5076, 1614, 60067, 5061, 9318, 1536, 6435, 4021, 15620, 88…\n$ `2018`      &lt;dbl&gt; 5651, 2717, 70215, 8774, 8685, 2195, 11334, 5430, 18944, 1…\n$ `2019`      &lt;dbl&gt; 7339, 2781, 62291, 12393, 9086, 3215, 14796, 5862, 21722, …\n$ `2020`      &lt;dbl&gt; 3949, 2636, 44169, 6897, 9203, 3119, 8333, 5877, 22574, 14…\n$ `2021`      &lt;dbl&gt; 8961, 3513, 37318, 15960, 12344, 3128, 15131, 6635, 28778,…\n$ `2022`      &lt;dbl&gt; 4459, 2907, 12420, 8267, 4878, 2117, 8468, 3648, 14174, 96…\n\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of thailand with the attribute fields of thedrugs_all1 dataframe, retaining only the relevant columns. This is performed by using inner_join() of dplyr package. We join the data frames on the English-language names of each province.\n\nthailand_drugs &lt;- left_join(thailand, drugs_all1, by = c(\"ADM1_EN\" = \"province_en\")) %&gt;%\n  select(3, 18:24)\n\nglimpse(thailand_drugs)\n\nRows: 77\nColumns: 8\n$ ADM1_EN  &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"Phr…\n$ `2017`   &lt;dbl&gt; 60067, 12452, 7348, 7616, 6221, 1614, NA, 1574, 1536, 4288, 1…\n$ `2018`   &lt;dbl&gt; 70215, 17656, 9583, 11005, 8555, 2717, NA, 2117, 2195, 5766, …\n$ `2019`   &lt;dbl&gt; 62291, 23295, 11347, 14643, 10631, 2781, NA, 2586, 3215, 6391…\n$ `2020`   &lt;dbl&gt; 44169, 14615, 7064, 8744, 8549, 2636, NA, 2209, 3119, 5632, 2…\n$ `2021`   &lt;dbl&gt; 37318, 14002, 10290, 8927, 8013, 3513, NA, 2872, 3128, 6744, …\n$ `2022`   &lt;dbl&gt; 12420, 7366, 3912, 5571, 4890, 2907, NA, 1744, 2117, 3585, 86…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON (((…\n\n\nThere are 77 rows, corresponding to Thailand’s 77 provinces (including Bangkok). However, on further examination, we notice that values from drugs_all1 are missing for two provinces: Lop Buri and Buengkan.\nThis is due to a discrepancy in the English-language transcriptions of these 2 provinces in drugsall1 and thailand. To solve this, we join the two data frames using the Thai-language province names instead.\n\nthailand_drugs &lt;- left_join(thailand, drugs_all1, by = c(\"ADM1_TH\" = \"province_th\")) %&gt;%\n  select(3, 18:24)\n\nglimpse(thailand_drugs)\n\nRows: 77\nColumns: 8\n$ ADM1_EN  &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"Phr…\n$ `2017`   &lt;dbl&gt; 60067, 12452, 7348, 7616, 6221, 1614, 5872, 1574, 1536, 4288,…\n$ `2018`   &lt;dbl&gt; 70215, 17656, 9583, 11005, 8555, 2717, 9547, 2117, 2195, 5766…\n$ `2019`   &lt;dbl&gt; 62291, 23295, 11347, 14643, 10631, 2781, 10043, 2586, 3215, 6…\n$ `2020`   &lt;dbl&gt; 44169, 14615, 7064, 8744, 8549, 2636, 8132, 2209, 3119, 5632,…\n$ `2021`   &lt;dbl&gt; 37318, 14002, 10290, 8927, 8013, 3513, 9254, 2872, 3128, 6744…\n$ `2022`   &lt;dbl&gt; 12420, 7366, 3912, 5571, 4890, 2907, 4647, 1744, 2117, 3585, …\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON (((…\n\n\nThe values for all provinces are now reflected. As required, we have now obtained a drug abuse indicators layer within the study area in sf polygon feature format.\n\n\n\nWe can now plot a choropleth map showing the distribution of drug-related cases in Thailand by province for each year between 2017 and 2022, using the tmap package.\n\ntmap_mode(\"plot\")\n\nthailand_2017 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2017\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2018 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2018\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2019 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2019\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2020 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2020\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2021 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2021\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2022 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2022\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\ntmap_arrange(thailand_2017, thailand_2018, thailand_2019, thailand_2020, thailand_2021, thailand_2022, asp = 1, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights matrix of the study area. The spatial weights matrix is used to define the neighbourhood relationships between the provinces.\nIn the code chunk below, st_contiguity() of sfdep is used to compute a contiguity weight matrix. This function builds a neighbours list nb based on provinces with contiguous boundaries. We use the Queen criteria to calculate our neighbours list.\nThen, st_weights() is used to to assign weights to neighboring polygons. We use row-standardised weights (style = “W”). This means that for each province i, each neighbouring province is assigned an equal weight of 1/(number of neighbours of i). The spatially lagged drug-related case count of province i is calculated by summing the weighted case count values of its neighbours.\n\nwm_q &lt;- thailand_drugs %&gt;%\n  mutate(nb = st_contiguity(geometry, queen = TRUE),\n         wt = st_weights(nb, style = \"W\", allow_zero = TRUE),\n         .before = 1)\n\nwm_q\n\nSimple feature collection with 77 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                            nb\n1          2, 3, 4, 15, 59, 60\n2                        1, 15\n3                  1, 4, 5, 59\n4          1, 3, 5, 10, 15, 17\n5       3, 4, 6, 7, 10, 58, 59\n6                  5, 7, 8, 58\n7  5, 6, 8, 10, 19, 25, 48, 55\n8              6, 7, 9, 48, 58\n9                8, 48, 49, 58\n10             4, 5, 7, 17, 19\n                                                                            wt\n1             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n2                                                                     0.5, 0.5\n3                                                       0.25, 0.25, 0.25, 0.25\n4             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n5  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n6                                                       0.25, 0.25, 0.25, 0.25\n7                       0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n8                                                      0.2, 0.2, 0.2, 0.2, 0.2\n9                                                       0.25, 0.25, 0.25, 0.25\n10                                                     0.2, 0.2, 0.2, 0.2, 0.2\n                    ADM1_EN  2017  2018  2019  2020  2021  2022\n1                   Bangkok 60067 70215 62291 44169 37318 12420\n2              Samut Prakan 12452 17656 23295 14615 14002  7366\n3                Nonthaburi  7348  9583 11347  7064 10290  3912\n4              Pathum Thani  7616 11005 14643  8744  8927  5571\n5  Phra Nakhon Si Ayutthaya  6221  8555 10631  8549  8013  4890\n6                 Ang Thong  1614  2717  2781  2636  3513  2907\n7                  Lop Buri  5872  9547 10043  8132  9254  4647\n8                 Sing Buri  1574  2117  2586  2209  2872  1744\n9                  Chai Nat  1536  2195  3215  3119  3128  2117\n10                 Saraburi  4288  5766  6391  5632  6744  3585\n                         geometry\n1  MULTIPOLYGON (((100.6139 13...\n2  MULTIPOLYGON (((100.7306 13...\n3  MULTIPOLYGON (((100.3415 14...\n4  MULTIPOLYGON (((100.8916 14...\n5  MULTIPOLYGON (((100.5131 14...\n6  MULTIPOLYGON (((100.3332 14...\n7  MULTIPOLYGON (((101.3453 15...\n8  MULTIPOLYGON (((100.3691 15...\n9  MULTIPOLYGON (((100.1199 15...\n10 MULTIPOLYGON (((101.3994 15...\n\n\nNotice a warning message that some observations have no neighbours. Examining wm_q, this is due to the province of Phuket, which consists of islands and does not have contiguous boundaries with any other province.\n\n\n\n\n\nIn the code chunk below, global_moran() is used to compute the Moran’s I value for each year. The global Moran’s I value measures spatial autocorrelation for the entire study area.\n\nmoranI_2017 &lt;- global_moran(wm_q$\"2017\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\nmoranI_2018 &lt;- global_moran(wm_q$\"2018\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\nmoranI_2019 &lt;- global_moran(wm_q$\"2019\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nmoranI_2020 &lt;- global_moran(wm_q$\"2020\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nmoranI_2021 &lt;- global_moran(wm_q$\"2021\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nmoranI_2022 &lt;- global_moran(wm_q$\"2022\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nglimpse(moranI_2017)\n\nList of 2\n $ I: num 0.135\n $ K: num 31.4\n\nglimpse(moranI_2018)\n\nList of 2\n $ I: num 0.118\n $ K: num 30.4\n\nglimpse(moranI_2019)\n\nList of 2\n $ I: num 0.157\n $ K: num 18.8\n\nglimpse(moranI_2020)\n\nList of 2\n $ I: num 0.131\n $ K: num 12.3\n\nglimpse(moranI_2021)\n\nList of 2\n $ I: num 0.202\n $ K: num 5.54\n\nglimpse(moranI_2022)\n\nList of 2\n $ I: num 0.204\n $ K: num 3.34\n\n\nSince the computed global Moran’s I values are close to zero in every year, it appears that drug-related case levels are distributed randomly over space in Thailand and there is no spatial autocorrelation.\n\n\n\nFor a more rigorous analysis, we perform a statistical test using Monte Carlo simulation. This is done using global_moran_perm(). To ensure reproducibility, we set a seed before performing the simulations.\n\nset.seed(1234)\n\nglobal_moran_perm(wm_q$\"2017\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.13314, observed rank = 98, p-value = 0.04\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2018\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.11637, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2019\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15541, observed rank = 97, p-value = 0.06\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2020\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.1296, observed rank = 98, p-value = 0.04\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2021\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.19889, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2022\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.20113, observed rank = 99, p-value = 0.02\nalternative hypothesis: two.sided\n\n\nAt alpha = 0.05, the p-values in every year other than 2019 are smaller than the alpha value, which means that for these years, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random. Since the Moran’s I statistics is greater than 0, we infer that the spatial distribution shows signs of clustering in all the years apart from 2019 (i.e. in these years, provinces with similar drug-related case levels are likely to be clustered together).\nOn the other hand, the p-value in 2019 is larger than the alpha value of 0.05, which means that we do not have enough evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random for 2019.\n\n\n\n\nWe can perform the simulations using the Geary’s C statistic instead.\n\nset.seed(1234)\n\n\nglobal_c_perm(wm_q$\"2017\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.99196, observed rank = 59, p-value = 0.59\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2018\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 1.0014, observed rank = 42, p-value = 0.42\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2019\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.92999, observed rank = 39, p-value = 0.39\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2020\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.94641, observed rank = 26, p-value = 0.26\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2021\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.86448, observed rank = 14, p-value = 0.14\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2022\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.84715, observed rank = 6, p-value = 0.06\nalternative hypothesis: greater\n\n\nIn contrast to simulations of the global Moran’s I statistics, the p-values are larger than the alpha value of 0.05 in every year, which means that we do not have enough evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random.\n\n\n\n\nLocal Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the entire study area.\nGiven a set of geospatial features and an analysis field, the spatial statistics identify spatial clusters of features with high or low values, as well as outliers.\n\n\n\n\nLocal Moran’s I is the most popular spatial statistical method used. We compute Local Moran’s I drug-related case levels at the provincial level for each year by using local.moran() of sfdep.\n\nset.seed(1234)\n\nlisa2017 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2017\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2017 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 7 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.467277 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  2.56   2.00e-26 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.0583 4.84e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.0737 4.80e- 4 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4  0.293  6.13e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5  0.0964 4.62e- 3 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.706  8.08e- 6 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n7  0.0769 2.20e- 2 High-High Krabi         (((99.11329 7.489274, 99.11337 7.489…\n\n\n\nset.seed(1234)\n\nlisa2018 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2018\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2018 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99.8141 ymin: 13.17847 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  3.40   2.32e-24 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.133  3.65e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.239  8.17e- 4 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4 -0.0293 4.61e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5  0.110  2.75e- 3 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.854  5.05e- 6 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n\n\n\nset.seed(1234)\n\nlisa2019 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2019\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2019 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99.8141 ymin: 13.17847 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  4.73   5.42e-15 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.317  8.02e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.509  6.71e- 3 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4 -0.0738 4.65e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5 -0.0606 1.03e- 2 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.845  5.35e- 4 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n\n\n\nset.seed(1234)\n\nlisa2020 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2020\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2020 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 7 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.090332 xmax: 101.9901 ymax: 14.14025\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  2.36   9.75e-11 High-High Samut Prakan        (((100.7306 13.71713, 100.7307…\n2 -0.283  7.22e- 3 High-High Nonthaburi          (((100.3415 14.10079, 100.3415…\n3  0.0741 1.88e- 2 High-High Chachoengsao        (((101.0612 13.97613, 101.0625…\n4 -0.691  3.15e- 2 Low-High  Samut Sakhon        (((100.3091 13.7217, 100.3091 …\n5  2.48   3.77e- 2 High-High Nakhon Si Thammarat (((99.77467 9.313729, 99.77478…\n6  0.237  3.28e- 3 High-High Krabi               (((99.11329 7.489274, 99.11337…\n7 -0.632  2.29e- 2 Low-High  Phatthalung         (((99.96416 7.90199, 99.9642 7…\n\n\n\nset.seed(1234)\n\nlisa2021 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2021\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2021 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.090332 xmax: 100.9639 ymax: 16.19126\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n      ii     p_ii median    ADM1_EN                                     geometry\n*  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                             &lt;MULTIPOLYGON [°]&gt;\n1  0.612 0.000687 High-High Samut Prakan (((100.7306 13.71713, 100.7307 13.7168…\n2  0.439 0.0232   Low-Low   Nakhon Sawan (((100.0266 16.189, 100.0267 16.18889,…\n3  0.674 0.0243   Low-Low   Ratchaburi   (((99.8821 13.94977, 99.88218 13.94976…\n4  0.553 0.0216   Low-Low   Suphan Buri  (((99.37118 15.05073, 99.37454 15.0495…\n5 -0.103 0.00782  High-High Krabi        (((99.11329 7.489274, 99.11337 7.48927…\n6 -0.595 0.0105   Low-High  Phatthalung  (((99.96416 7.90199, 99.9642 7.901912,…\n\n\n\nset.seed(1234)\n\nlisa2022 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2022\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2022 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 11 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99.01629 ymin: 7.090332 xmax: 104.4353 ymax: 18.30525\nGeodetic CRS:  WGS 84\n# A tibble: 11 × 5\n       ii    p_ii median    ADM1_EN                                     geometry\n *  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                             &lt;MULTIPOLYGON [°]&gt;\n 1 -0.185 0.0221  High-High Surin            (((103.1336 15.47831, 103.1343 15.…\n 2 -1.37  0.00598 Low-High  Nong Bua Lam Phu (((102.2866 17.69207, 102.2867 17.…\n 3  1.65  0.00351 High-High Khon Kaen        (((102.7072 17.08713, 102.708 17.0…\n 4  2.13  0.0324  High-High Udon Thani       (((102.0581 18.0862, 102.0583 18.0…\n 5  0.119 0.0218  High-High Nong Khai        (((103.2985 18.29698, 103.2984 18.…\n 6  0.283 0.0122  High-High Maha Sarakham    (((103.1562 16.6425, 103.1567 16.6…\n 7  2.14  0.00191 High-High Kalasin          (((103.584 17.09981, 103.5845 17.0…\n 8  0.880 0.0377  High-High Sakon Nakhon     (((103.5404 18.06785, 103.5405 18.…\n 9  0.428 0.00849 Low-Low   Nakhon Sawan     (((100.0266 16.189, 100.0267 16.18…\n10  0.705 0.0359  Low-Low   Kamphaeng Phet   (((99.48875 16.91044, 99.48883 16.…\n11 -0.446 0.0493  Low-High  Phatthalung      (((99.96416 7.90199, 99.9642 7.901…\n\n\n\n\n\nUsing the following code, we can visualise the significant clusters and outliers on a map for each year.\n\nlisa2017_sig &lt;- lisa2017 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2017map &lt;- tm_shape(lisa2017) +\n  tm_polygons() +\ntm_shape(lisa2017_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2018_sig &lt;- lisa2018 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2018map &lt;- tm_shape(lisa2018) +\n  tm_polygons() +\ntm_shape(lisa2018_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2019_sig &lt;- lisa2019 %&gt;%\n  filter(p_ii &lt; 0.05) \n\nlisa2019map &lt;- tm_shape(lisa2019) +\n  tm_polygons() +\ntm_shape(lisa2019_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2020_sig &lt;- lisa2020 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2020map &lt;- tm_shape(lisa2020) +\n  tm_polygons() +\ntm_shape(lisa2020_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2021_sig &lt;- lisa2021 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2021map &lt;- tm_shape(lisa2021) +\n  tm_polygons() +\ntm_shape(lisa2021_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2022_sig &lt;- lisa2022 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2022map &lt;- tm_shape(lisa2022) +\n  tm_polygons() +\ntm_shape(lisa2022_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(lisa2017map, lisa2018map, lisa2019map, lisa2020map, lisa2021map, lisa2022map, asp = 1, nrow = 2)\n\n\n\n\n\n\n\n\nFrom the maps, we can see that in 2017, there were two significant High-High clusters (consisting of provinces that, similar to their neighbours, had high drug-related case levels), located in Southern and Central Thailand respectively. The cluster in Central Thailand, including provinces like Chachoengsao and Chonburi, continues to be significant until 2020.\nThroughout this period, Samut Sakhon province, also in Central Thailand, is a notable outlier, having relatively low drug-related case levels in contrast to its neighbours.\nIn 2021, a significant Low-Low cluster emerges in Western Thailand.\nIn 2022, a significant High-High cluster in Northeastern Thailand emerges, consisting of provinces such as Khon Kaen and Udon Thani, and comprising a much larger area than the clusters previously identified. Statistically significant spatial autocorrelation in drug abuse levels had not previously been observed in this region, and this new trend is concerning as it suggests that there are some recently-emerged factors facilitating the spread of drug abuse here.\n\n\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s Gi* statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values.\n\n\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- thailand_drugs %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         .before = 1)\n\n\n\n\nWe proceed to compute the local Gi* statistics for each year.\n\nset.seed(1234)\n\n\nHCSA2017 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2017\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2018 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2018\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2019 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2019\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2020 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2020\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2021 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2021\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2022 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2022\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nBy mapping the local Gi* statistics, we can identify hot spot and cold spot areas. A hot spot area is an area where where features with high values (i.e. hot spots) cluster spatially, while a low spot area is one where features with low values (cold spots) cluster spatially. Unlike when we use the local Moran’s I statistic, outliers are not identified.\nWe focus only on plotting the significant hot spot and cold spot areas, where p_sim &lt; 0.05.\n\nHCSA2017_sig &lt;- HCSA2017 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2017_map &lt;- tm_shape(HCSA2017) +\n  tm_polygons() +\ntm_shape(HCSA2017_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2018_sig &lt;- HCSA2018 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2018_map &lt;- tm_shape(HCSA2018) +\n  tm_polygons() +\ntm_shape(HCSA2018_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2019_sig &lt;- HCSA2019 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2019_map &lt;- tm_shape(HCSA2019) +\n  tm_polygons() +\ntm_shape(HCSA2019_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2019_sig &lt;- HCSA2019 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2019_map &lt;- tm_shape(HCSA2019) +\n  tm_polygons() +\ntm_shape(HCSA2019_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2020_sig &lt;- HCSA2020 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2020_map &lt;- tm_shape(HCSA2020) +\n  tm_polygons() +\ntm_shape(HCSA2020_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2020_sig &lt;- HCSA2020 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2020_map &lt;- tm_shape(HCSA2020) +\n  tm_polygons() +\ntm_shape(HCSA2020_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2021_sig &lt;- HCSA2021 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2021_map &lt;- tm_shape(HCSA2021) +\n  tm_polygons() +\ntm_shape(HCSA2021_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2022_sig &lt;- HCSA2022 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2022_map &lt;- tm_shape(HCSA2022) +\n  tm_polygons() +\ntm_shape(HCSA2022_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\n\ntmap_arrange(HCSA2017_map, HCSA2018_map, HCSA2019_map, HCSA2020_map, HCSA2021_map, HCSA2022_map, asp = 1, nrow = 2)\n\n\n\n\n\n\n\n\nThe emergence of a significant cold spot area in Western Thailand in 2021 is now very obvious.\n\n\n\n\nEmerging hot spot analysis (EHSA) allows us to evaluate how hot and cold spots are changing over time. It combines the traditional exploratory spatial data analysis technique of hot spot analysis using the Getis-Ord Gi* statistic with the traditional time-series Mann-Kendall test for monotonic trends.\nWe will perform EHSA analysis by using emerging_hotspot_analysis(). This requires us to first create a spacetime object. The following steps are inspired by a previous student in this course, Khant (2024).\nThere are four important data required to create the spacetime object:\n\ndata: a tibble data frame object containing location and time identifiers\ngeometry: an sf object containing location identifiers\nlocation identifier: a common column between data and geometry\ntime: a column in data that includes temporal information.\n\nTo achieve this, we first use the pivot_longer() function of dplyr to transform thailand_drugs into a tibble data frame data with a single column each for the location identifers (ADM1_EN) and time identifiers (year). Here, the argument names_transform is used to ensure that the year column is of integer type.\n\ndata &lt;- thailand_drugs %&gt;% \n  pivot_longer(cols = 2:7, names_to = \"year\", values_to = \"cases\", names_transform = list(year = as.integer)) %&gt;%\n  select(ADM1_EN, year, cases) %&gt;%\n  as_tibble()\n\nWe can now create the spacetime object using the spacetime() function of sfdep.\n\nspt &lt;- spacetime (.data = data, .geometry = thailand, .loc_col = \"ADM1_EN\", .time_col = \"year\")\n\nA spacetime object is a spacetime cube if every location has a value for every time index. We use is_spacetime_cube() to very that our newly created spt object is a spacetime cube.\n\nis_spacetime_cube(spt)\n\n[1] TRUE\n\n\nWe can perform the EHSA analysis.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = spt, \n  .var = \"cases\", \n  k = 1, \n  nsim = 99,\n  threshold = 0.05\n)\n\nglimpse(ehsa)\n\nRows: 77\nColumns: 4\n$ location       &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\"…\n$ tau            &lt;dbl&gt; 0.59999996, -0.06666666, 0.06666666, 0.33333331, 0.5999…\n$ p_value        &lt;dbl&gt; 0.13285494, 1.00000000, 1.00000000, 0.45237041, 0.13285…\n$ classification &lt;chr&gt; \"no pattern detected\", \"sporadic coldspot\", \"sporadic h…\n\n\n\nggplot(data = ehsa, aes(y = classification)) +\n  geom_bar(aes(fill = classification))\n\n\n\n\n\n\n\n\nWe can see that most provinces have no pattern detected, while sporadic coldspots and sporadic hotspots are the next most common classes of provinces.\nWe can further limit our observations to provinces that fall into an EHSA class with p-value &lt; 0.05.\n\nggplot(data = filter(ehsa, p_value &lt; 0.05), aes(y = classification)) +\n  geom_bar(aes(fill = classification))\n\n\n\n\n\n\n\n\nAs we can see, most of our observations from before were not statistically significant. Only 4 classes of hotspots and coldspots remain: consecutive coldspots and hotspots, and intensifying coldspots and hotspots.\nWe visualise these on a map using functions of the tmap package.\n\nehsa_map &lt;- thailand_drugs %&gt;%\n  left_join(filter(ehsa, p_value &lt; 0.05), by = c(\"ADM1_EN\" = \"location\"))\n\ntm_shape(ehsa_map) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Emerging Hotspots & Coldspots \\nof Drug Abuse in Thailand (2017-2022)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.text.size = 0.45,\n            legend.height = 0.5, \n            legend.width = 0.5, \n            asp = 1,\n            frame = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nHaving performed the EHSA, we do not observe many statistically significant emerging hotspots or coldspots. One possible reason is that the length of each time period (1 year) is too short for clear spatial patterns to be observed. The fact that most of the calculated global and local spatial autocorrelation statistics in Parts 5 and 6 were not statistically significant also suggest that this might be a problem.\nMoreover, if our time period used is too short, the year-to-year variation may create too much noise in our data.\nWe repeat Part 5 and 6, this time using a time period of 3 years as our period of analysis. Hopefully, this will reduce the amount of noise in the data and allow us to have more meaningful findings.\nThe following code chunk creates 2 new columns in thailand_drugs, sum1 and sum2 . These are the aggregate counts of drug-related cases in each province from 2017-2019 and 2020-2022 respectively.\n\nthailand_drugs_sum &lt;- thailand_drugs %&gt;%\n  mutate(sum1 = rowSums(across(2:4)), sum2 = rowSums(across(5:7))) %&gt;%\n  select(1, 8, 9, 10)\n\n\n\n\n\nIn the code chunk below, global_moran() is used to compute the Moran’s I value for each time period. The global Moran’s I value measures spatial autocorrelation for the entire study area. We reuse the contiguity weight matrix derived from before in Part 5, wm_q.\n\nmoranI_before &lt;- global_moran(thailand_drugs_sum$sum1,\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\nmoranI_after &lt;- global_moran(thailand_drugs_sum$sum2,\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nglimpse(moranI_before)\n\nList of 2\n $ I: num 0.138\n $ K: num 27.1\n\nglimpse(moranI_after)\n\nList of 2\n $ I: num 0.146\n $ K: num 6.25\n\n\nSimilar to what we found earlier, the computed global Moran’s I values are close to zero in both time periods, meaning that in both time periods, it appears that drug-related case levels are distributed randomly over space in Thailand and there is no spatial autocorrelation.\n\n\n\nFor a more rigorous analysis, we perform a statistical test using Monte Carlo simulation. This is done using global_moran_perm(). To ensure reproducibility, we set a seed before performing the simulations.\n\nset.seed(1234)\n\nglobal_moran_perm(thailand_drugs_sum$sum1, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.13613, observed rank = 99, p-value = 0.02\nalternative hypothesis: two.sided\n\nglobal_moran_perm(thailand_drugs_sum$sum2, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.1437, observed rank = 97, p-value = 0.06\nalternative hypothesis: two.sided\n\n\nAt alpha = 0.05, the p-value in the first time period (2017-2019) is smaller than the alpha value, which means that for this period, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random. Since the Moran’s I statistics is greater than 0, we infer that the spatial distribution shows signs of clustering in this period.\nOn the other hand, the p-value in the second time period (2020-2022) is larger than the alpha value of 0.05, which means that we do not have enough evidence to reject the null hypothesis that the spatial distribution of drug-related case levels in the second period is random.\n\n\n\n\nWe compute Local Moran’s I drug-related case levels at the provincial level for each period by using local.moran() of sfdep.\n\nset.seed(1234)\n\nlisa_before &lt;- thailand_drugs_sum %&gt;% \n  mutate(local_moran = local_moran(.$sum1, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa_before %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 7 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.467277 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  3.77   1.28e-21 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.180  4.64e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.303  1.40e- 3 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4  0.0563 4.63e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5  0.0423 4.64e- 3 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.831  2.77e- 5 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n7 -0.0183 4.98e- 2 High-High Krabi         (((99.11329 7.489274, 99.11337 7.489…\n\n\n\nset.seed(1234)\n\nlisa_after &lt;- thailand_drugs_sum %&gt;% \n  mutate(local_moran = local_moran(.$sum2, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa_after %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.090332 xmax: 100.9639 ymax: 16.19126\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 5\n      ii      p_ii median    ADM1_EN                                    geometry\n*  &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  1.16  0.0000479 High-High Samut Prakan (((100.7306 13.71713, 100.7307 13.716…\n2  0.413 0.0240    Low-Low   Nakhon Sawan (((100.0266 16.189, 100.0267 16.18889…\n3  0.359 0.0444    Low-Low   Suphan Buri  (((99.37118 15.05073, 99.37454 15.049…\n4 -0.153 0.0136    High-High Krabi        (((99.11329 7.489274, 99.11337 7.4892…\n5 -0.648 0.0125    Low-High  Phatthalung  (((99.96416 7.90199, 99.9642 7.901912…\n\n\nUsing the following code, we can visualise the significant clusters and outliers on a map for each time period.\n\nlisa_before_sig &lt;- lisa_before %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa_before_map &lt;- tm_shape(lisa_before) +\n  tm_polygons() +\ntm_shape(lisa_before_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\nlisa_after_sig &lt;- lisa_after %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa_after_map &lt;- tm_shape(lisa_after) +\n  tm_polygons() +\ntm_shape(lisa_after_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(lisa_before_map, lisa_after_map)\n\n\n\n\n\n\n\n\n\n\n\nNext, we perform hot and cold spot analysis in the same way as in Part 6. We reuse the distance weight matrix wm_idw obtained in Part 6.\n\nset.seed(1234)\n\nHCSAbefore &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    thailand_drugs_sum$sum1, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSAafter &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    thailand_drugs_sum$sum2, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSAbefore_sig &lt;- HCSAbefore %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSAbefore_map &lt;- tm_shape(HCSAbefore) +\n  tm_polygons() +\ntm_shape(HCSAbefore_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\nHCSAafter_sig &lt;- HCSAafter %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSAafter_map &lt;- tm_shape(HCSAafter) +\n  tm_polygons() +\ntm_shape(HCSAafter_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(HCSAbefore_map, HCSAafter_map)\n\n\n\n\n\n\n\n\nAn interesting finding from these maps is that Samut Prakan province in central Thailand (part of the Bangkok metropolitan area) is a significant hotspot of drug abuse in both time periods, and this is consistent with what is observed in the LISA maps plotted in the previous section.\nIn contrast, and counterintuitively, although neighbouring Bangkok has the highest raw drug-related case counts in both periods (as shown by the output of the following code chunk), it does not appear as a significant hotspot or exhibit statistically significant clustering.\n\nthailand_drugs_sum %&gt;%\n  arrange(desc(sum1)) %&gt;%\n  head(1)\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 100.3279 ymin: 13.49339 xmax: 100.9385 ymax: 13.9552\nGeodetic CRS:  WGS 84\n  ADM1_EN   sum1  sum2                       geometry\n1 Bangkok 192573 93907 MULTIPOLYGON (((100.6139 13...\n\nthailand_drugs_sum %&gt;%\n  arrange(desc(sum2)) %&gt;%\n  head(1)\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 100.3279 ymin: 13.49339 xmax: 100.9385 ymax: 13.9552\nGeodetic CRS:  WGS 84\n  ADM1_EN   sum1  sum2                       geometry\n1 Bangkok 192573 93907 MULTIPOLYGON (((100.6139 13...\n\n\nTo investigate further, we plot a choropleth map showing the distribution of drug-related cases in Thailand by province again, this time for the two time periods 2017-2019 and 2020-2022.\n\ntmap_mode(\"plot\")\n\nthailand_before &lt;- tm_shape(thailand_drugs_sum) +\n  tm_fill(\"sum1\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5,  frame = TRUE) +\n  tm_layout(legend.text.size = 0.5)\n\nthailand_after &lt;- tm_shape(thailand_drugs_sum) +\n  tm_fill(\"sum2\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE) + tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(thailand_before, thailand_after)\n\n\n\n\n\n\n\n\nA possible explanation for this is that Bangkok has 6 neighbouring provinces, one of which is Samut Sakhon, which consistently ranks in the bottom quantile for level of drug-related cases.\nOn the other hand, Samut Prakan only has 2 neighbouring provinces, one of which is Bangkok (as mentioned, the province with the highest level of drug-related cases in both periods) and the other is Chachoengsao (in second-highest quantile in both periods).\nIt is important to remember that the LISA statistics for each observation give an indication of the extent of significant spatial clustering of similar values around that observation (Anselin, L., 1995). In other words, they depend not only on the value of the observation itself, but also the neighbouring observations.\nHence, unlike Samut Prakan, which has high levels of drug-related cases and is only surrounded by neighbours with similarly high or higher levels, Bangkok’s LISA statistics may be “dragged” downwards by a neighbour (Samut Sakhon) with an extremely low level of drug-related cases, despite its own extremely high level of drug-related cases.\nIt seems that the presence outliers can make it difficult for us to identify significant clustering/hotspot and coldspot areas, and we may consider adjusting our analysis accordingly (for example, by relaxing our requirements for statistical significance) in future studies.\nAnother limitation of this study is that the drug abuse indicators used in this analysis (absolute number of drug-related cases) are not normalised by the population size of each province, which means that variations between provinces may reflect differences in population and not just differences in the prevalence of drug abuse."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Drug abuse is associated with significant negative health, financial and social consequences. Yet, illicit drug consumption remains highly prevalent and continues to be a growing problem worldwide. In 2021, 1 in 17 people aged 15–64 in the world had used a drug in the past 12 months. Notwithstanding population growth, the estimated number of drug users grew from 240 million in 2011 to 296 million in 2021.\nIn Thailand, drug abuse is a major social issue. There are about 2.7 million youths using drugs in Thailand. Among youths aged between 15 and 19 years, there are about 300,000 who have needs for drug treatment. Most of Thai youths involved with drugs are vocational-school students, which nearly doubles in number compared to secondary-school students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "We are interested to discover:\n\nif the key indicators of drug abuse of Thailand are independent from space.\nIf the indicators of drug abuse is indeed spatially dependent, then, we would like to detect where are the clusters and outliers, and the hotspots.\nLast but not least, we are also interested to investigate how the observations above evolve over time."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#task",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#task",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "The specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\na study area layer in sf polygon features. It must be at province level (including Bangkok) of Thailand.\na drug abuse indicators layer within the study area in sf polygon features.\n\nUsing the extracted data, perform global spatial autocorrelation analysis by using sfdep methods.\nUsing the extracted data, perform local spatial autocorrelation analysis by using sfdep methods.\nDescribe the spatial patterns revealed by the analysis above."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "The following two data sets will be used:\n\nthai_drug_offenses_2017_2022.csv This dataset presents statistics related to different types of drug offenses in Thailand, categorized by fiscal year, and provides insights into the prevalence of various drug-related cases and their distribution across different provinces. It was downloaded from https://www.kaggle.com/datasets/thaweewatboy/thailand-drug-offenses-2017-2022.\ntha_admbnda_adm1_rtsd_20220121 This dataset provides information on Thailand province boundaries in shapefile format. It was downloaded from the Humanitarian Data Exchange, a service provided by the United Nations Office for the Coordination of Humanitarian Affairs (OCHA)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setup",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setup",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "For this exercise, the following R packages are used:\n\ntidyverse, a collection of R packages designed for data science, and which provides functions to import, transform, and visualise the data.\nsf, to import, manage and process vector-based geospatial data in R.\nsfdep, which creates an sf and tidyverse friendly interface to the spdep package that is used to compute spatial weights, global and local spatial autocorrelation statistics\ntmap, which provides functions for plotting cartographic quality choropleth maps.\nKendall, which computes the Kendall rank correlation and Mann-Kendall trend test. This will be necessary for us to perform emerging hot spot analysis.\n\n\npacman::p_load(tidyverse, sf, sfdep, tmap, Kendall)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Import tha_admbnda_adm1_rtsd_20220121 as a simple features object, which we name thailand. This is the required study area layer in sf polygon feature format.\n\n#|eval: FALSE\n\nthailand &lt;- st_read(dsn = \"data/geospatial\", layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\ImmanuelLeong\\IS415-Geospatial\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nthailand has a total of 77 features, and is projected in WGS 84.\nWe save thailand with the write_rds() function.\n\nwrite_rds(thailand, \"data/rds/thailand.rds\")\n\nVerify that all the geometries in thailand are valid.\n\nlength(which(st_is_valid(thailand) == TRUE))\n\n[1] 77\n\n\nSometimes, when importing geospatial data into R, the coordinate system of the source data is wrongly assigned during the importing process. Check the CRS of thailand.\n\nst_crs(thailand)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThe EPSG code indicated is 4326, which is correct since the data is projected in WGS 84.\n\n\n\nSince thai_drug_offenses_2017_2022.csv is in csv format, we used read_csv() of the readr package (part of the tidyverse) to import it.\n\ndrugs &lt;- read_csv(\"data/aspatial/thai_drug_offenses_2017_2022.csv\")\n\nglimpse(drugs)\n\nRows: 7,392\nColumns: 5\n$ fiscal_year            &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,…\n$ types_of_drug_offenses &lt;chr&gt; \"drug_use_cases\", \"drug_use_cases\", \"drug_use_c…\n$ no_cases               &lt;dbl&gt; 11871, 200, 553, 450, 378, 727, 820, 69, 127, 2…\n$ province_th            &lt;chr&gt; \"กรุงเทพมหานคร\", \"ชัยนาท\", \"นนทบุรี\", \"ปทุมธานี\", \"พร…\n$ province_en            &lt;chr&gt; \"Bangkok\", \"Chai Nat\", \"Nonthaburi\", \"Pathum Th…\n\n\nThe data on the number of drug-related cases in drugs is categorized by fiscal year, type of drug offense, and province. We derive the total number of drug-related cases in each province, in each fiscal year, using group_by() and summarize() of dplyr (part of the tidyverse).\n\ndrugs_all &lt;- drugs %&gt;% \n  group_by(fiscal_year, province_en, province_th) %&gt;%\n  summarize(cases = sum(no_cases))\n\nglimpse(drugs_all)\n\nRows: 462\nColumns: 4\nGroups: fiscal_year, province_en [462]\n$ fiscal_year &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017…\n$ province_en &lt;chr&gt; \"Amnat Charoen\", \"Ang Thong\", \"Bangkok\", \"Buri Ram\", \"Chac…\n$ province_th &lt;chr&gt; \"อำนาจเจริญ\", \"อ่างทอง\", \"กรุงเทพมหานคร\", \"บุรีรัมย์\", \"ฉะเชิงเทรา…\n$ cases       &lt;dbl&gt; 5076, 1614, 60067, 5061, 9318, 1536, 6435, 4021, 15620, 88…\n\n\nNext, we use pivot_wider() of dplyr so that each row contains the data for a single province, and each column contains the data for a single fiscal year.\n\ndrugs_all1 &lt;- drugs_all %&gt;%\n  pivot_wider(names_from = \"fiscal_year\", values_from = \"cases\")\n\nglimpse(drugs_all1)\n\nRows: 77\nColumns: 8\nGroups: province_en [77]\n$ province_en &lt;chr&gt; \"Amnat Charoen\", \"Ang Thong\", \"Bangkok\", \"Buri Ram\", \"Chac…\n$ province_th &lt;chr&gt; \"อำนาจเจริญ\", \"อ่างทอง\", \"กรุงเทพมหานคร\", \"บุรีรัมย์\", \"ฉะเชิงเทรา…\n$ `2017`      &lt;dbl&gt; 5076, 1614, 60067, 5061, 9318, 1536, 6435, 4021, 15620, 88…\n$ `2018`      &lt;dbl&gt; 5651, 2717, 70215, 8774, 8685, 2195, 11334, 5430, 18944, 1…\n$ `2019`      &lt;dbl&gt; 7339, 2781, 62291, 12393, 9086, 3215, 14796, 5862, 21722, …\n$ `2020`      &lt;dbl&gt; 3949, 2636, 44169, 6897, 9203, 3119, 8333, 5877, 22574, 14…\n$ `2021`      &lt;dbl&gt; 8961, 3513, 37318, 15960, 12344, 3128, 15131, 6635, 28778,…\n$ `2022`      &lt;dbl&gt; 4459, 2907, 12420, 8267, 4878, 2117, 8468, 3648, 14174, 96…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-relational-join",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-relational-join",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "The code chunk below will be used to update the attribute table of thailand with the attribute fields of thedrugs_all1 dataframe, retaining only the relevant columns. This is performed by using inner_join() of dplyr package. We join the data frames on the English-language names of each province.\n\nthailand_drugs &lt;- left_join(thailand, drugs_all1, by = c(\"ADM1_EN\" = \"province_en\")) %&gt;%\n  select(3, 18:24)\n\nglimpse(thailand_drugs)\n\nRows: 77\nColumns: 8\n$ ADM1_EN  &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"Phr…\n$ `2017`   &lt;dbl&gt; 60067, 12452, 7348, 7616, 6221, 1614, NA, 1574, 1536, 4288, 1…\n$ `2018`   &lt;dbl&gt; 70215, 17656, 9583, 11005, 8555, 2717, NA, 2117, 2195, 5766, …\n$ `2019`   &lt;dbl&gt; 62291, 23295, 11347, 14643, 10631, 2781, NA, 2586, 3215, 6391…\n$ `2020`   &lt;dbl&gt; 44169, 14615, 7064, 8744, 8549, 2636, NA, 2209, 3119, 5632, 2…\n$ `2021`   &lt;dbl&gt; 37318, 14002, 10290, 8927, 8013, 3513, NA, 2872, 3128, 6744, …\n$ `2022`   &lt;dbl&gt; 12420, 7366, 3912, 5571, 4890, 2907, NA, 1744, 2117, 3585, 86…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON (((…\n\n\nThere are 77 rows, corresponding to Thailand’s 77 provinces (including Bangkok). However, on further examination, we notice that values from drugs_all1 are missing for two provinces: Lop Buri and Buengkan.\nThis is due to a discrepancy in the English-language transcriptions of these 2 provinces in drugsall1 and thailand. To solve this, we join the two data frames using the Thai-language province names instead.\n\nthailand_drugs &lt;- left_join(thailand, drugs_all1, by = c(\"ADM1_TH\" = \"province_th\")) %&gt;%\n  select(3, 18:24)\n\nglimpse(thailand_drugs)\n\nRows: 77\nColumns: 8\n$ ADM1_EN  &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"Phr…\n$ `2017`   &lt;dbl&gt; 60067, 12452, 7348, 7616, 6221, 1614, 5872, 1574, 1536, 4288,…\n$ `2018`   &lt;dbl&gt; 70215, 17656, 9583, 11005, 8555, 2717, 9547, 2117, 2195, 5766…\n$ `2019`   &lt;dbl&gt; 62291, 23295, 11347, 14643, 10631, 2781, 10043, 2586, 3215, 6…\n$ `2020`   &lt;dbl&gt; 44169, 14615, 7064, 8744, 8549, 2636, 8132, 2209, 3119, 5632,…\n$ `2021`   &lt;dbl&gt; 37318, 14002, 10290, 8927, 8013, 3513, 9254, 2872, 3128, 6744…\n$ `2022`   &lt;dbl&gt; 12420, 7366, 3912, 5571, 4890, 2907, 4647, 1744, 2117, 3585, …\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON (((…\n\n\nThe values for all provinces are now reflected. As required, we have now obtained a drug abuse indicators layer within the study area in sf polygon feature format."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-drug-abuse-indicators",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-drug-abuse-indicators",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "We can now plot a choropleth map showing the distribution of drug-related cases in Thailand by province for each year between 2017 and 2022, using the tmap package.\n\ntmap_mode(\"plot\")\n\nthailand_2017 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2017\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2018 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2018\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2019 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2019\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2020 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2020\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2021 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2021\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\nthailand_2022 &lt;- tm_shape(thailand_drugs) +\n  tm_fill(\"2022\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE)\n\ntmap_arrange(thailand_2017, thailand_2018, thailand_2019, thailand_2020, thailand_2021, thailand_2022, asp = 1, nrow = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "In this section, we compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights matrix of the study area. The spatial weights matrix is used to define the neighbourhood relationships between the provinces.\nIn the code chunk below, st_contiguity() of sfdep is used to compute a contiguity weight matrix. This function builds a neighbours list nb based on provinces with contiguous boundaries. We use the Queen criteria to calculate our neighbours list.\nThen, st_weights() is used to to assign weights to neighboring polygons. We use row-standardised weights (style = “W”). This means that for each province i, each neighbouring province is assigned an equal weight of 1/(number of neighbours of i). The spatially lagged drug-related case count of province i is calculated by summing the weighted case count values of its neighbours.\n\nwm_q &lt;- thailand_drugs %&gt;%\n  mutate(nb = st_contiguity(geometry, queen = TRUE),\n         wt = st_weights(nb, style = \"W\", allow_zero = TRUE),\n         .before = 1)\n\nwm_q\n\nSimple feature collection with 77 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                            nb\n1          2, 3, 4, 15, 59, 60\n2                        1, 15\n3                  1, 4, 5, 59\n4          1, 3, 5, 10, 15, 17\n5       3, 4, 6, 7, 10, 58, 59\n6                  5, 7, 8, 58\n7  5, 6, 8, 10, 19, 25, 48, 55\n8              6, 7, 9, 48, 58\n9                8, 48, 49, 58\n10             4, 5, 7, 17, 19\n                                                                            wt\n1             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n2                                                                     0.5, 0.5\n3                                                       0.25, 0.25, 0.25, 0.25\n4             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n5  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n6                                                       0.25, 0.25, 0.25, 0.25\n7                       0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n8                                                      0.2, 0.2, 0.2, 0.2, 0.2\n9                                                       0.25, 0.25, 0.25, 0.25\n10                                                     0.2, 0.2, 0.2, 0.2, 0.2\n                    ADM1_EN  2017  2018  2019  2020  2021  2022\n1                   Bangkok 60067 70215 62291 44169 37318 12420\n2              Samut Prakan 12452 17656 23295 14615 14002  7366\n3                Nonthaburi  7348  9583 11347  7064 10290  3912\n4              Pathum Thani  7616 11005 14643  8744  8927  5571\n5  Phra Nakhon Si Ayutthaya  6221  8555 10631  8549  8013  4890\n6                 Ang Thong  1614  2717  2781  2636  3513  2907\n7                  Lop Buri  5872  9547 10043  8132  9254  4647\n8                 Sing Buri  1574  2117  2586  2209  2872  1744\n9                  Chai Nat  1536  2195  3215  3119  3128  2117\n10                 Saraburi  4288  5766  6391  5632  6744  3585\n                         geometry\n1  MULTIPOLYGON (((100.6139 13...\n2  MULTIPOLYGON (((100.7306 13...\n3  MULTIPOLYGON (((100.3415 14...\n4  MULTIPOLYGON (((100.8916 14...\n5  MULTIPOLYGON (((100.5131 14...\n6  MULTIPOLYGON (((100.3332 14...\n7  MULTIPOLYGON (((101.3453 15...\n8  MULTIPOLYGON (((100.3691 15...\n9  MULTIPOLYGON (((100.1199 15...\n10 MULTIPOLYGON (((101.3994 15...\n\n\nNotice a warning message that some observations have no neighbours. Examining wm_q, this is due to the province of Phuket, which consists of islands and does not have contiguous boundaries with any other province.\n\n\n\n\n\nIn the code chunk below, global_moran() is used to compute the Moran’s I value for each year. The global Moran’s I value measures spatial autocorrelation for the entire study area.\n\nmoranI_2017 &lt;- global_moran(wm_q$\"2017\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\nmoranI_2018 &lt;- global_moran(wm_q$\"2018\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\nmoranI_2019 &lt;- global_moran(wm_q$\"2019\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nmoranI_2020 &lt;- global_moran(wm_q$\"2020\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nmoranI_2021 &lt;- global_moran(wm_q$\"2021\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nmoranI_2022 &lt;- global_moran(wm_q$\"2022\",\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nglimpse(moranI_2017)\n\nList of 2\n $ I: num 0.135\n $ K: num 31.4\n\nglimpse(moranI_2018)\n\nList of 2\n $ I: num 0.118\n $ K: num 30.4\n\nglimpse(moranI_2019)\n\nList of 2\n $ I: num 0.157\n $ K: num 18.8\n\nglimpse(moranI_2020)\n\nList of 2\n $ I: num 0.131\n $ K: num 12.3\n\nglimpse(moranI_2021)\n\nList of 2\n $ I: num 0.202\n $ K: num 5.54\n\nglimpse(moranI_2022)\n\nList of 2\n $ I: num 0.204\n $ K: num 3.34\n\n\nSince the computed global Moran’s I values are close to zero in every year, it appears that drug-related case levels are distributed randomly over space in Thailand and there is no spatial autocorrelation.\n\n\n\nFor a more rigorous analysis, we perform a statistical test using Monte Carlo simulation. This is done using global_moran_perm(). To ensure reproducibility, we set a seed before performing the simulations.\n\nset.seed(1234)\n\nglobal_moran_perm(wm_q$\"2017\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.13314, observed rank = 98, p-value = 0.04\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2018\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.11637, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2019\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15541, observed rank = 97, p-value = 0.06\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2020\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.1296, observed rank = 98, p-value = 0.04\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2021\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.19889, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nglobal_moran_perm(wm_q$\"2022\", wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.20113, observed rank = 99, p-value = 0.02\nalternative hypothesis: two.sided\n\n\nAt alpha = 0.05, the p-values in every year other than 2019 are smaller than the alpha value, which means that for these years, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random. Since the Moran’s I statistics is greater than 0, we infer that the spatial distribution shows signs of clustering in all the years apart from 2019 (i.e. in these years, provinces with similar drug-related case levels are likely to be clustered together).\nOn the other hand, the p-value in 2019 is larger than the alpha value of 0.05, which means that we do not have enough evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random for 2019.\n\n\n\n\nWe can perform the simulations using the Geary’s C statistic instead.\n\nset.seed(1234)\n\n\nglobal_c_perm(wm_q$\"2017\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.99196, observed rank = 59, p-value = 0.59\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2018\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 1.0014, observed rank = 42, p-value = 0.42\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2019\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.92999, observed rank = 39, p-value = 0.39\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2020\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.94641, observed rank = 26, p-value = 0.26\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2021\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.86448, observed rank = 14, p-value = 0.14\nalternative hypothesis: greater\n\nglobal_c_perm(wm_q$\"2022\", wm_q$nb, wm_q$wt, nsim = 99, allow_zero = TRUE)\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.84715, observed rank = 6, p-value = 0.06\nalternative hypothesis: greater\n\n\nIn contrast to simulations of the global Moran’s I statistics, the p-values are larger than the alpha value of 0.05 in every year, which means that we do not have enough evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the entire study area.\nGiven a set of geospatial features and an analysis field, the spatial statistics identify spatial clusters of features with high or low values, as well as outliers.\n\n\n\n\nLocal Moran’s I is the most popular spatial statistical method used. We compute Local Moran’s I drug-related case levels at the provincial level for each year by using local.moran() of sfdep.\n\nset.seed(1234)\n\nlisa2017 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2017\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2017 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 7 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.467277 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  2.56   2.00e-26 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.0583 4.84e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.0737 4.80e- 4 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4  0.293  6.13e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5  0.0964 4.62e- 3 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.706  8.08e- 6 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n7  0.0769 2.20e- 2 High-High Krabi         (((99.11329 7.489274, 99.11337 7.489…\n\n\n\nset.seed(1234)\n\nlisa2018 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2018\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2018 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99.8141 ymin: 13.17847 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  3.40   2.32e-24 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.133  3.65e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.239  8.17e- 4 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4 -0.0293 4.61e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5  0.110  2.75e- 3 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.854  5.05e- 6 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n\n\n\nset.seed(1234)\n\nlisa2019 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2019\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2019 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99.8141 ymin: 13.17847 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  4.73   5.42e-15 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.317  8.02e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.509  6.71e- 3 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4 -0.0738 4.65e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5 -0.0606 1.03e- 2 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.845  5.35e- 4 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n\n\n\nset.seed(1234)\n\nlisa2020 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2020\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2020 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 7 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.090332 xmax: 101.9901 ymax: 14.14025\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  2.36   9.75e-11 High-High Samut Prakan        (((100.7306 13.71713, 100.7307…\n2 -0.283  7.22e- 3 High-High Nonthaburi          (((100.3415 14.10079, 100.3415…\n3  0.0741 1.88e- 2 High-High Chachoengsao        (((101.0612 13.97613, 101.0625…\n4 -0.691  3.15e- 2 Low-High  Samut Sakhon        (((100.3091 13.7217, 100.3091 …\n5  2.48   3.77e- 2 High-High Nakhon Si Thammarat (((99.77467 9.313729, 99.77478…\n6  0.237  3.28e- 3 High-High Krabi               (((99.11329 7.489274, 99.11337…\n7 -0.632  2.29e- 2 Low-High  Phatthalung         (((99.96416 7.90199, 99.9642 7…\n\n\n\nset.seed(1234)\n\nlisa2021 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2021\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2021 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.090332 xmax: 100.9639 ymax: 16.19126\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n      ii     p_ii median    ADM1_EN                                     geometry\n*  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                             &lt;MULTIPOLYGON [°]&gt;\n1  0.612 0.000687 High-High Samut Prakan (((100.7306 13.71713, 100.7307 13.7168…\n2  0.439 0.0232   Low-Low   Nakhon Sawan (((100.0266 16.189, 100.0267 16.18889,…\n3  0.674 0.0243   Low-Low   Ratchaburi   (((99.8821 13.94977, 99.88218 13.94976…\n4  0.553 0.0216   Low-Low   Suphan Buri  (((99.37118 15.05073, 99.37454 15.0495…\n5 -0.103 0.00782  High-High Krabi        (((99.11329 7.489274, 99.11337 7.48927…\n6 -0.595 0.0105   Low-High  Phatthalung  (((99.96416 7.90199, 99.9642 7.901912,…\n\n\n\nset.seed(1234)\n\nlisa2022 &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(.$\"2022\", nb, wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa2022 %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 11 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99.01629 ymin: 7.090332 xmax: 104.4353 ymax: 18.30525\nGeodetic CRS:  WGS 84\n# A tibble: 11 × 5\n       ii    p_ii median    ADM1_EN                                     geometry\n *  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                             &lt;MULTIPOLYGON [°]&gt;\n 1 -0.185 0.0221  High-High Surin            (((103.1336 15.47831, 103.1343 15.…\n 2 -1.37  0.00598 Low-High  Nong Bua Lam Phu (((102.2866 17.69207, 102.2867 17.…\n 3  1.65  0.00351 High-High Khon Kaen        (((102.7072 17.08713, 102.708 17.0…\n 4  2.13  0.0324  High-High Udon Thani       (((102.0581 18.0862, 102.0583 18.0…\n 5  0.119 0.0218  High-High Nong Khai        (((103.2985 18.29698, 103.2984 18.…\n 6  0.283 0.0122  High-High Maha Sarakham    (((103.1562 16.6425, 103.1567 16.6…\n 7  2.14  0.00191 High-High Kalasin          (((103.584 17.09981, 103.5845 17.0…\n 8  0.880 0.0377  High-High Sakon Nakhon     (((103.5404 18.06785, 103.5405 18.…\n 9  0.428 0.00849 Low-Low   Nakhon Sawan     (((100.0266 16.189, 100.0267 16.18…\n10  0.705 0.0359  Low-Low   Kamphaeng Phet   (((99.48875 16.91044, 99.48883 16.…\n11 -0.446 0.0493  Low-High  Phatthalung      (((99.96416 7.90199, 99.9642 7.901…\n\n\n\n\n\nUsing the following code, we can visualise the significant clusters and outliers on a map for each year.\n\nlisa2017_sig &lt;- lisa2017 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2017map &lt;- tm_shape(lisa2017) +\n  tm_polygons() +\ntm_shape(lisa2017_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2018_sig &lt;- lisa2018 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2018map &lt;- tm_shape(lisa2018) +\n  tm_polygons() +\ntm_shape(lisa2018_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2019_sig &lt;- lisa2019 %&gt;%\n  filter(p_ii &lt; 0.05) \n\nlisa2019map &lt;- tm_shape(lisa2019) +\n  tm_polygons() +\ntm_shape(lisa2019_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2020_sig &lt;- lisa2020 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2020map &lt;- tm_shape(lisa2020) +\n  tm_polygons() +\ntm_shape(lisa2020_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2021_sig &lt;- lisa2021 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2021map &lt;- tm_shape(lisa2021) +\n  tm_polygons() +\ntm_shape(lisa2021_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\nlisa2022_sig &lt;- lisa2022 %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa2022map &lt;- tm_shape(lisa2022) +\n  tm_polygons() +\ntm_shape(lisa2022_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(lisa2017map, lisa2018map, lisa2019map, lisa2020map, lisa2021map, lisa2022map, asp = 1, nrow = 2)\n\n\n\n\n\n\n\n\nFrom the maps, we can see that in 2017, there were two significant High-High clusters (consisting of provinces that, similar to their neighbours, had high drug-related case levels), located in Southern and Central Thailand respectively. The cluster in Central Thailand, including provinces like Chachoengsao and Chonburi, continues to be significant until 2020.\nThroughout this period, Samut Sakhon province, also in Central Thailand, is a notable outlier, having relatively low drug-related case levels in contrast to its neighbours.\nIn 2021, a significant Low-Low cluster emerges in Western Thailand.\nIn 2022, a significant High-High cluster in Northeastern Thailand emerges, consisting of provinces such as Khon Kaen and Udon Thani, and comprising a much larger area than the clusters previously identified. Statistically significant spatial autocorrelation in drug abuse levels had not previously been observed in this region, and this new trend is concerning as it suggests that there are some recently-emerged factors facilitating the spread of drug abuse here.\n\n\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s Gi* statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values.\n\n\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- thailand_drugs %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         .before = 1)\n\n\n\n\nWe proceed to compute the local Gi* statistics for each year.\n\nset.seed(1234)\n\n\nHCSA2017 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2017\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2018 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2018\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2019 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2019\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2020 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2020\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2021 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2021\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\nHCSA2022 &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    .$\"2022\", nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nBy mapping the local Gi* statistics, we can identify hot spot and cold spot areas. A hot spot area is an area where where features with high values (i.e. hot spots) cluster spatially, while a low spot area is one where features with low values (cold spots) cluster spatially. Unlike when we use the local Moran’s I statistic, outliers are not identified.\nWe focus only on plotting the significant hot spot and cold spot areas, where p_sim &lt; 0.05.\n\nHCSA2017_sig &lt;- HCSA2017 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2017_map &lt;- tm_shape(HCSA2017) +\n  tm_polygons() +\ntm_shape(HCSA2017_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2018_sig &lt;- HCSA2018 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2018_map &lt;- tm_shape(HCSA2018) +\n  tm_polygons() +\ntm_shape(HCSA2018_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2019_sig &lt;- HCSA2019 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2019_map &lt;- tm_shape(HCSA2019) +\n  tm_polygons() +\ntm_shape(HCSA2019_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2019_sig &lt;- HCSA2019 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2019_map &lt;- tm_shape(HCSA2019) +\n  tm_polygons() +\ntm_shape(HCSA2019_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2020_sig &lt;- HCSA2020 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2020_map &lt;- tm_shape(HCSA2020) +\n  tm_polygons() +\ntm_shape(HCSA2020_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2020_sig &lt;- HCSA2020 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2020_map &lt;- tm_shape(HCSA2020) +\n  tm_polygons() +\ntm_shape(HCSA2020_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2021_sig &lt;- HCSA2021 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2021_map &lt;- tm_shape(HCSA2021) +\n  tm_polygons() +\ntm_shape(HCSA2021_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\nHCSA2022_sig &lt;- HCSA2022 %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSA2022_map &lt;- tm_shape(HCSA2022) +\n  tm_polygons() +\ntm_shape(HCSA2022_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5)\n\n\ntmap_arrange(HCSA2017_map, HCSA2018_map, HCSA2019_map, HCSA2020_map, HCSA2021_map, HCSA2022_map, asp = 1, nrow = 2)\n\n\n\n\n\n\n\n\nThe emergence of a significant cold spot area in Western Thailand in 2021 is now very obvious."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Emerging hot spot analysis (EHSA) allows us to evaluate how hot and cold spots are changing over time. It combines the traditional exploratory spatial data analysis technique of hot spot analysis using the Getis-Ord Gi* statistic with the traditional time-series Mann-Kendall test for monotonic trends.\nWe will perform EHSA analysis by using emerging_hotspot_analysis(). This requires us to first create a spacetime object. The following steps are inspired by a previous student in this course, Khant (2024).\nThere are four important data required to create the spacetime object:\n\ndata: a tibble data frame object containing location and time identifiers\ngeometry: an sf object containing location identifiers\nlocation identifier: a common column between data and geometry\ntime: a column in data that includes temporal information.\n\nTo achieve this, we first use the pivot_longer() function of dplyr to transform thailand_drugs into a tibble data frame data with a single column each for the location identifers (ADM1_EN) and time identifiers (year). Here, the argument names_transform is used to ensure that the year column is of integer type.\n\ndata &lt;- thailand_drugs %&gt;% \n  pivot_longer(cols = 2:7, names_to = \"year\", values_to = \"cases\", names_transform = list(year = as.integer)) %&gt;%\n  select(ADM1_EN, year, cases) %&gt;%\n  as_tibble()\n\nWe can now create the spacetime object using the spacetime() function of sfdep.\n\nspt &lt;- spacetime (.data = data, .geometry = thailand, .loc_col = \"ADM1_EN\", .time_col = \"year\")\n\nA spacetime object is a spacetime cube if every location has a value for every time index. We use is_spacetime_cube() to very that our newly created spt object is a spacetime cube.\n\nis_spacetime_cube(spt)\n\n[1] TRUE\n\n\nWe can perform the EHSA analysis.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = spt, \n  .var = \"cases\", \n  k = 1, \n  nsim = 99,\n  threshold = 0.05\n)\n\nglimpse(ehsa)\n\nRows: 77\nColumns: 4\n$ location       &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\"…\n$ tau            &lt;dbl&gt; 0.59999996, -0.06666666, 0.06666666, 0.33333331, 0.5999…\n$ p_value        &lt;dbl&gt; 0.13285494, 1.00000000, 1.00000000, 0.45237041, 0.13285…\n$ classification &lt;chr&gt; \"no pattern detected\", \"sporadic coldspot\", \"sporadic h…\n\n\n\nggplot(data = ehsa, aes(y = classification)) +\n  geom_bar(aes(fill = classification))\n\n\n\n\n\n\n\n\nWe can see that most provinces have no pattern detected, while sporadic coldspots and sporadic hotspots are the next most common classes of provinces.\nWe can further limit our observations to provinces that fall into an EHSA class with p-value &lt; 0.05.\n\nggplot(data = filter(ehsa, p_value &lt; 0.05), aes(y = classification)) +\n  geom_bar(aes(fill = classification))\n\n\n\n\n\n\n\n\nAs we can see, most of our observations from before were not statistically significant. Only 4 classes of hotspots and coldspots remain: consecutive coldspots and hotspots, and intensifying coldspots and hotspots.\nWe visualise these on a map using functions of the tmap package.\n\nehsa_map &lt;- thailand_drugs %&gt;%\n  left_join(filter(ehsa, p_value &lt; 0.05), by = c(\"ADM1_EN\" = \"location\"))\n\ntm_shape(ehsa_map) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Emerging Hotspots & Coldspots \\nof Drug Abuse in Thailand (2017-2022)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.text.size = 0.45,\n            legend.height = 0.5, \n            legend.width = 0.5, \n            asp = 1,\n            frame = TRUE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conducting-a-two-period-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conducting-a-two-period-analysis",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Having performed the EHSA, we do not observe many statistically significant emerging hotspots or coldspots. One possible reason is that the length of each time period (1 year) is too short for clear spatial patterns to be observed. The fact that most of the calculated global and local spatial autocorrelation statistics in Parts 5 and 6 were not statistically significant also suggest that this might be a problem.\nMoreover, if our time period used is too short, the year-to-year variation may create too much noise in our data.\nWe repeat Part 5 and 6, this time using a time period of 3 years as our period of analysis. Hopefully, this will reduce the amount of noise in the data and allow us to have more meaningful findings.\nThe following code chunk creates 2 new columns in thailand_drugs, sum1 and sum2 . These are the aggregate counts of drug-related cases in each province from 2017-2019 and 2020-2022 respectively.\n\nthailand_drugs_sum &lt;- thailand_drugs %&gt;%\n  mutate(sum1 = rowSums(across(2:4)), sum2 = rowSums(across(5:7))) %&gt;%\n  select(1, 8, 9, 10)\n\n\n\n\n\nIn the code chunk below, global_moran() is used to compute the Moran’s I value for each time period. The global Moran’s I value measures spatial autocorrelation for the entire study area. We reuse the contiguity weight matrix derived from before in Part 5, wm_q.\n\nmoranI_before &lt;- global_moran(thailand_drugs_sum$sum1,\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\nmoranI_after &lt;- global_moran(thailand_drugs_sum$sum2,\n                       wm_q$nb,\n                       wm_q$wt,\n                       zero.policy = TRUE)\n\n\nglimpse(moranI_before)\n\nList of 2\n $ I: num 0.138\n $ K: num 27.1\n\nglimpse(moranI_after)\n\nList of 2\n $ I: num 0.146\n $ K: num 6.25\n\n\nSimilar to what we found earlier, the computed global Moran’s I values are close to zero in both time periods, meaning that in both time periods, it appears that drug-related case levels are distributed randomly over space in Thailand and there is no spatial autocorrelation.\n\n\n\nFor a more rigorous analysis, we perform a statistical test using Monte Carlo simulation. This is done using global_moran_perm(). To ensure reproducibility, we set a seed before performing the simulations.\n\nset.seed(1234)\n\nglobal_moran_perm(thailand_drugs_sum$sum1, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.13613, observed rank = 99, p-value = 0.02\nalternative hypothesis: two.sided\n\nglobal_moran_perm(thailand_drugs_sum$sum2, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.1437, observed rank = 97, p-value = 0.06\nalternative hypothesis: two.sided\n\n\nAt alpha = 0.05, the p-value in the first time period (2017-2019) is smaller than the alpha value, which means that for this period, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of drug-related case levels is random. Since the Moran’s I statistics is greater than 0, we infer that the spatial distribution shows signs of clustering in this period.\nOn the other hand, the p-value in the second time period (2020-2022) is larger than the alpha value of 0.05, which means that we do not have enough evidence to reject the null hypothesis that the spatial distribution of drug-related case levels in the second period is random.\n\n\n\n\nWe compute Local Moran’s I drug-related case levels at the provincial level for each period by using local.moran() of sfdep.\n\nset.seed(1234)\n\nlisa_before &lt;- thailand_drugs_sum %&gt;% \n  mutate(local_moran = local_moran(.$sum1, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa_before %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 7 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.467277 xmax: 101.9901 ymax: 14.27595\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 5\n       ii     p_ii median    ADM1_EN                                    geometry\n*   &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  3.77   1.28e-21 High-High Samut Prakan  (((100.7306 13.71713, 100.7307 13.71…\n2  0.180  4.64e- 4 High-High Nonthaburi    (((100.3415 14.10079, 100.3415 14.10…\n3  0.303  1.40e- 3 High-High Pathum Thani  (((100.8916 14.24576, 100.8916 14.24…\n4  0.0563 4.63e- 3 High-High Chachoengsao  (((101.0612 13.97613, 101.0625 13.97…\n5  0.0423 4.64e- 3 High-High Nakhon Pathom (((100.2231 14.17725, 100.2262 14.17…\n6 -0.831  2.77e- 5 Low-High  Samut Sakhon  (((100.3091 13.7217, 100.3091 13.721…\n7 -0.0183 4.98e- 2 High-High Krabi         (((99.11329 7.489274, 99.11337 7.489…\n\n\n\nset.seed(1234)\n\nlisa_after &lt;- thailand_drugs_sum %&gt;% \n  mutate(local_moran = local_moran(.$sum2, wm_q$nb, wm_q$wt, nsim = 99, zero.policy = TRUE),\n         .before = 1) %&gt;%\n  unnest(local_moran) %&gt;%\n  select(ii, p_ii, median, ADM1_EN, geometry)\n\nlisa_after %&gt;% filter(p_ii &lt; 0.05)\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 98.6116 ymin: 7.090332 xmax: 100.9639 ymax: 16.19126\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 5\n      ii      p_ii median    ADM1_EN                                    geometry\n*  &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt;                            &lt;MULTIPOLYGON [°]&gt;\n1  1.16  0.0000479 High-High Samut Prakan (((100.7306 13.71713, 100.7307 13.716…\n2  0.413 0.0240    Low-Low   Nakhon Sawan (((100.0266 16.189, 100.0267 16.18889…\n3  0.359 0.0444    Low-Low   Suphan Buri  (((99.37118 15.05073, 99.37454 15.049…\n4 -0.153 0.0136    High-High Krabi        (((99.11329 7.489274, 99.11337 7.4892…\n5 -0.648 0.0125    Low-High  Phatthalung  (((99.96416 7.90199, 99.9642 7.901912…\n\n\nUsing the following code, we can visualise the significant clusters and outliers on a map for each time period.\n\nlisa_before_sig &lt;- lisa_before %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa_before_map &lt;- tm_shape(lisa_before) +\n  tm_polygons() +\ntm_shape(lisa_before_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\nlisa_after_sig &lt;- lisa_after %&gt;%\n  filter(p_ii &lt; 0.05)\n\nlisa_after_map &lt;- tm_shape(lisa_after) +\n  tm_polygons() +\ntm_shape(lisa_after_sig) +\n  tm_fill(\"median\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(lisa_before_map, lisa_after_map)\n\n\n\n\n\n\n\n\n\n\n\nNext, we perform hot and cold spot analysis in the same way as in Part 6. We reuse the distance weight matrix wm_idw obtained in Part 6.\n\nset.seed(1234)\n\nHCSAbefore &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    thailand_drugs_sum$sum1, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSAafter &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    thailand_drugs_sum$sum2, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSAbefore_sig &lt;- HCSAbefore %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSAbefore_map &lt;- tm_shape(HCSAbefore) +\n  tm_polygons() +\ntm_shape(HCSAbefore_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\nHCSAafter_sig &lt;- HCSAafter %&gt;%\n  filter(p_sim &lt; 0.05)\n  \nHCSAafter_map &lt;- tm_shape(HCSAafter) +\n  tm_polygons() +\ntm_shape(HCSAafter_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(HCSAbefore_map, HCSAafter_map)\n\n\n\n\n\n\n\n\nAn interesting finding from these maps is that Samut Prakan province in central Thailand (part of the Bangkok metropolitan area) is a significant hotspot of drug abuse in both time periods, and this is consistent with what is observed in the LISA maps plotted in the previous section.\nIn contrast, and counterintuitively, although neighbouring Bangkok has the highest raw drug-related case counts in both periods (as shown by the output of the following code chunk), it does not appear as a significant hotspot or exhibit statistically significant clustering.\n\nthailand_drugs_sum %&gt;%\n  arrange(desc(sum1)) %&gt;%\n  head(1)\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 100.3279 ymin: 13.49339 xmax: 100.9385 ymax: 13.9552\nGeodetic CRS:  WGS 84\n  ADM1_EN   sum1  sum2                       geometry\n1 Bangkok 192573 93907 MULTIPOLYGON (((100.6139 13...\n\nthailand_drugs_sum %&gt;%\n  arrange(desc(sum2)) %&gt;%\n  head(1)\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 100.3279 ymin: 13.49339 xmax: 100.9385 ymax: 13.9552\nGeodetic CRS:  WGS 84\n  ADM1_EN   sum1  sum2                       geometry\n1 Bangkok 192573 93907 MULTIPOLYGON (((100.6139 13...\n\n\nTo investigate further, we plot a choropleth map showing the distribution of drug-related cases in Thailand by province again, this time for the two time periods 2017-2019 and 2020-2022.\n\ntmap_mode(\"plot\")\n\nthailand_before &lt;- tm_shape(thailand_drugs_sum) +\n  tm_fill(\"sum1\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5,  frame = TRUE) +\n  tm_layout(legend.text.size = 0.5)\n\nthailand_after &lt;- tm_shape(thailand_drugs_sum) +\n  tm_fill(\"sum2\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.height = 0.45, legend.width = 0.5, frame = TRUE) + tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(thailand_before, thailand_after)\n\n\n\n\n\n\n\n\nA possible explanation for this is that Bangkok has 6 neighbouring provinces, one of which is Samut Sakhon, which consistently ranks in the bottom quantile for level of drug-related cases.\nOn the other hand, Samut Prakan only has 2 neighbouring provinces, one of which is Bangkok (as mentioned, the province with the highest level of drug-related cases in both periods) and the other is Chachoengsao (in second-highest quantile in both periods).\nIt is important to remember that the LISA statistics for each observation give an indication of the extent of significant spatial clustering of similar values around that observation (Anselin, L., 1995). In other words, they depend not only on the value of the observation itself, but also the neighbouring observations.\nHence, unlike Samut Prakan, which has high levels of drug-related cases and is only surrounded by neighbours with similarly high or higher levels, Bangkok’s LISA statistics may be “dragged” downwards by a neighbour (Samut Sakhon) with an extremely low level of drug-related cases, despite its own extremely high level of drug-related cases.\nIt seems that the presence outliers can make it difficult for us to identify significant clustering/hotspot and coldspot areas, and we may consider adjusting our analysis accordingly (for example, by relaxing our requirements for statistical significance) in future studies.\nAnother limitation of this study is that the drug abuse indicators used in this analysis (absolute number of drug-related cases) are not normalised by the population size of each province, which means that variations between provinces may reflect differences in population and not just differences in the prevalence of drug abuse."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part2.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_part2.html",
    "title": "Take-Home Exercise 3 (Part 2)",
    "section": "",
    "text": "We create a function map_adm1(). The first argument specifies one of the provinces as the study area. The rest of the arguments specify criteria for filtering point events, namely whether they fall into a given date range, belong to a given event type, involve a given actor, and result in at least a certain number of fatalities.\nst_intersection() of sf is used to obtain the point events that intersect with the study area. We do this instead of filtering points_study by the value in the admin1 field to avoid our results being affected by any naming or boundary changes over time.\nfilter() of dplyr is used to retain only the point events that meet the additional criteria, and these are saved as study_events for plotting.\nThe if and else statements ensure that if there are no point events within the specified study area that meet the specified criteria, only the study area layer is plotted.\n\nmap_adm1 &lt;- function(province, date_range, eventtype, actor, min_fatalities) {\n  \n  study_area &lt;- papua_adm1 %&gt;% filter(WADMPR == province)\n  \n  study_events &lt;- st_intersection(points_study, study_area) %&gt;% filter(dmy(event_date) %within% date_range & event_type == eventtype & (actor1 == actor | actor2 == actor) & fatalities &gt;= min_fatalities)\n  \n  tmap_mode(\"view\")\n  \n  if (nrow(study_events) &gt; 0) {\n    \n    tm_shape(study_area) +\n    tm_polygons(col = \"yellow\", id = \"WADMPR\") +\n    tm_shape(study_events) +\n    tm_dots()\n    \n  }\n  \n  else {\n    \n    tm_shape(study_area) +\n    tm_polygons(col = \"yellow\", id = \"WADMPR\")\n    \n  }\n}\n\nSuppose that a user is interested only in armed conflict events that took place in the province of Papua Tengah in year 2020, are of the type “Violence against civilians”, involved the TPNPB: West Papua National Liberation Army, and had at least one fatality. They would call map_adm1() as in the following code chunk.\n\nint &lt;- interval(ymd(\"2020-01-01\"), ymd(\"2020-12-31\"))\n\nmap_adm1(\"Papua Tengah\", int, \"Violence against civilians\", \"TPNPB: West Papua National Liberation Army\", 1)\n\n\n\n\ntmap_mode(\"plot\")"
  }
]